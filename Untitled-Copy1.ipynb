{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import os\n",
    "import dateutil\n",
    "import time\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical data\n",
    "import calendar\n",
    "\n",
    "def next_weekday(d, weekday):\n",
    "    days_ahead = weekday - d.weekday()\n",
    "    if days_ahead < 0: # Target day already happened this week\n",
    "        days_ahead += 7\n",
    "    return d + datetime.timedelta(days_ahead)\n",
    "\n",
    "def bucketed(df, start_on=\"Sunday\"):\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    \n",
    "    df['created_at'] = pd.to_datetime(df['created_at']).dt.date\n",
    "    min_date = df[\"created_at\"].min()\n",
    "    min_date = next_weekday(min_date, list(calendar.day_name).index(start_on))\n",
    "    max_date = df[\"created_at\"].max()\n",
    "    tweet_counts = df.groupby('created_at').agg('count')[\"text\"]\n",
    "    dates = pd.date_range(min_date, max_date, freq='D')\n",
    "    counts = pd.DataFrame({ \"count\": tweet_counts},index=dates).fillna(0)\n",
    "    counts = counts.resample('7D').sum()\n",
    "    return counts.drop(counts.tail(1).index) # drop last row in case its a count over less than the full time bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_BALANCE = 58\n",
    "N_TWEETS = 0\n",
    "\n",
    "BEARER_TOKEN=\"AAAAAAAAAAAAAAAAAAAAAAXT9gAAAAAAoITLBCf%2B2K7BMSqakqcbsHUSLrk%3DLz95o8CkkhjOTthpcyEEg6BdNav0zphRcrEYdeG4GXXV3Qkftk\"\n",
    "\n",
    "## value functions\n",
    "def expected_value(potential_win, chance_win, potential_loss, chance_loss):\n",
    "    return (potential_win * chance_win) - (potential_loss * chance_loss)\n",
    "\n",
    "def allocation(account_balance, expected_value):\n",
    "    pct_alloc = min(( expected_value * 5 ) / 10, .03)\n",
    "    alloc = account_balance * pct_alloc\n",
    "    #risk_coef = 1 - (1 / (proba * 100) )\n",
    "    #risk_adjusted = alloc * risk_coef\n",
    "    #return risk_adjusted\n",
    "    return alloc\n",
    "def allocation(price_per_share, proba):\n",
    "    payoff_odds = (1 / price_per_share) - 1\n",
    "\n",
    "def recommended_shares(account_balance, expected_value, price_per_share):\n",
    "    return allocation(account_balance, expected_value) / price_per_share;\n",
    "\n",
    "def to_proba(buckets, categories=None):\n",
    "    vals = buckets.value_counts()\n",
    "    # [ (range(0,2), \"0-2\"), range(3-5), \"3-5\" ]\n",
    "    #for c in categories:\n",
    "    #    rnge = c[0]\n",
    "    #    id_str = c[1]\n",
    "    #    for r in range:\n",
    "            \n",
    "    s = vals.sum()\n",
    "    return vals/s\n",
    "\n",
    "## portfolio management\n",
    "TAX_RATE = .1\n",
    "def kelly_criterion(outcomes):\n",
    "    # category, price_per_share, proba\n",
    "    er = []\n",
    "    betas = []\n",
    "    for index, o in outcomes.iterrows():\n",
    "        payoff_odds = (1 / o[\"price_per_share\"]) - 1\n",
    "        beta = 1 / (1 + payoff_odds)\n",
    "        dividend_rate = 1 - TAX_RATE\n",
    "        expected_revenue_rate = (dividend_rate / beta) * o[\"proba\"]\n",
    "        er.append(expected_revenue_rate)\n",
    "        betas.append(beta)\n",
    "        \n",
    "    outcomes[\"expected_revenue_rate\"] = er\n",
    "    outcomes[\"beta\"] = betas\n",
    "    outcomes = outcomes.sort_values(\"expected_revenue_rate\", ascending=False)\n",
    "    \n",
    "    reserve_rate = 1\n",
    "    optimal_set = pd.DataFrame()\n",
    "    for index, o in outcomes.iterrows():\n",
    "        if o[\"expected_revenue_rate\"] > reserve_rate:\n",
    "            optimal_set = optimal_set.append(o)\n",
    "            reserve_rate = (1 - optimal_set[\"proba\"].sum()) / (1 - (optimal_set[\"beta\"] / dividend_rate).sum())\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    pct_alloc = [] \n",
    "    for index, o in optimal_set.iterrows():\n",
    "        pct = (o[\"expected_revenue_rate\"] - reserve_rate) / ( dividend_rate / o[\"beta\"] )\n",
    "        pct_alloc.append(pct)\n",
    "    optimal_set[\"pct_alloc\"] = pct_alloc\n",
    "    return optimal_set\n",
    "\n",
    "def shares_bought(c, yes_or_no, positions):\n",
    "    bought = 0\n",
    "    if c in positions and yes_or_no in positions[c]:\n",
    "        for pos in positions[c][yes_or_no]:\n",
    "            bought += pos[1]\n",
    "    return bought\n",
    "\n",
    "def recommendation_buy(contract, yes_or_no, account_balance, expected_value, price_per_share, positions):\n",
    "    shares = recommended_shares(account_balance, expected_value, price_per_share) - shares_bought(contract, yes_or_no, positions)\n",
    "    shares = int(round(shares))\n",
    "    if shares > 0:\n",
    "        print(\"BUY {yn} shares for contract {n}: {shares} shares @{price} (EV: {ev}, TOTAL: {t})\".format(n=contract,shares=shares, price=price_per_share, ev=expected_value, yn=yes_or_no.upper(), t=shares*price_per_share))\n",
    "\n",
    "def recommendation_sell(contract, yes_or_no, expected_value, price_per_share, n_shares, bought_at):\n",
    "    print(\"SELL {yn} shares for contract {n}_{bought_at}_{n_shares}: ALL shares @{price} (EV: {ev}, TOTAL: {t})\".format(n=contract, price=price_per_share, ev=expected_value, yn=yes_or_no.upper(), t=n_shares*price_per_share, bought_at=bought_at, n_shares=n_shares))\n",
    "    \n",
    "## market evaluation\n",
    "def fetch_market_data(market_id):\n",
    "    url = \"https://www.predictit.org/api/marketdata/markets/{id}\".format(id=market_id)\n",
    "    r = requests.get(url=url)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_twitter_user_timeline(screen_name, max_id=None, since_id=None):\n",
    "    url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n",
    "    headers = { \"Authorization\": \"Bearer {t}\".format(t=BEARER_TOKEN)}\n",
    "    params = {\n",
    "        \"count\": \"200\",\n",
    "        \"trim_user\": \"true\",\n",
    "        \"screen_name\": screen_name\n",
    "    }\n",
    "    if max_id: \n",
    "        params[\"max_id\"] = max_id\n",
    "    if since_id:\n",
    "        params[\"since_id\"] = since_id\n",
    "        \n",
    "    r = requests.get(url=url,headers=headers, params=params)\n",
    "    raw = r.json()\n",
    "    transformed = json.dumps([ { \"id\": tweet[\"id\"], \"created_at\": tweet[\"created_at\"], \"text\": tweet[\"text\"] } for tweet in raw])\n",
    "    return pd.read_json(transformed, orient=\"records\")\n",
    "\n",
    "def get_recent_tweets(screen_name, from_date=None):\n",
    "    df = get_twitter_user_timeline(screen_name)\n",
    "    df[\"created_at\"] = df[\"created_at\"].dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "    if from_date:\n",
    "        df = df[df[\"created_at\"] > from_date]\n",
    "    return df\n",
    "    \n",
    "# the twitter api returns different results for the same request...\n",
    "def _get_twitter_history(screen_name, max_id=None):\n",
    "    get_next = True\n",
    "    df = pd.DataFrame(columns=[\"id\",\"created_at\", \"text\"])\n",
    "    while get_next:\n",
    "        tweets = get_twitter_user_timeline(screen_name, max_id)\n",
    "        print(len(tweets.index))\n",
    "        if len(tweets.index) > 0:\n",
    "            df = tweets if df.empty else pd.concat([df, tweets], axis=0)\n",
    "            last_row = tweets.tail(1).iloc[0]\n",
    "            max_id = last_row[\"id\"] - 1\n",
    "        else:\n",
    "            get_next = False\n",
    "    return df\n",
    "\n",
    "def get_twitter_history(screen_name, cache=True):\n",
    "    fname = \"data/tweets/{sn}.csv\".format(sn=screen_name)\n",
    "    max_id = None\n",
    "    if cache and os.path.isfile(fname):\n",
    "        df = pd.read_csv(fname)\n",
    "        max_id = int(df.tail(1).iloc[0][\"id\"]) -1\n",
    "    df = _get_twitter_history(screen_name, max_id);\n",
    "    if not os.path.isdir(\"data/tweets\"):\n",
    "        os.mkdir(\"data/tweets\")\n",
    "    if len(df) > 0:\n",
    "        df.to_csv(fname, mode='a')\n",
    "\n",
    "def fetch_full_trump_tweet_history(rnge, cache=True):\n",
    "    fname = \"data/tweets/@realDonaldTrump.csv\"\n",
    "    df = None\n",
    "    for year in rnge:\n",
    "        url = None\n",
    "        if year == 2019:\n",
    "            url = \"http://www.trumptwitterarchive.com/data/realdonaldtrump/2019.json\"\n",
    "        else:\n",
    "            url = \"http://d5nxcu7vtzvay.cloudfront.net/data/realdonaldtrump/{y}.json\".format(y=str(year))\n",
    "        _df  = pd.read_json(url)\n",
    "        if df is None:\n",
    "            df = _df\n",
    "        else:\n",
    "            df = pd.concat([df,_df])\n",
    "        time.sleep(1)\n",
    "     \n",
    "    if not os.path.isdir(\"data/tweets\"):\n",
    "        os.mkdir(\"data/tweets\")\n",
    "    if len(df) > 0:\n",
    "        df.to_csv(fname, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\"homieng6@gmail.com\"\n",
    "#\"??\"\n",
    "#\"@homiesaccount\"\n",
    "#\"nY7VUVqcxJ4vmcX\"\n",
    "#\"AAAAAAAAAAAAAAAAAAAAAAXT9gAAAAAAoITLBCf%2B2K7BMSqakqcbsHUSLrk%3DLz95o8CkkhjOTthpcyEEg6BdNav0zphRcrEYdeG4GXXV3Qkft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweet_distributions_per_day(source_df):\n",
    "    df = pd.DataFrame(columns=[\"proba\",\"day\"])\n",
    "    df.index.name = \"n_tweets\"\n",
    "    for x in range(0,7,1):\n",
    "        weekday = calendar.day_name[x]\n",
    "        b = bucketed(source_df, start_on=weekday)\n",
    "        proba = b['count']/b['count'].sum()\n",
    "        _df = pd.DataFrame({ \"proba\": proba.values, \"day\": x }, index=proba.index)\n",
    "        df = pd.concat([df, _df])\n",
    "        df[\"n_tweets\"] = df.index\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for key, _grp in df.groupby(['n_tweets']):\n",
    "        grp = _grp.sort_values(by=\"day\", ascending=False)\n",
    "        ax = grp.plot(ax=ax, kind='line', x=\"day\", y='proba', label=str(grp[\"n_tweets\"].iloc[0]))\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "#_df = pd.read_csv('./data/fake_news_tweets.csv')\n",
    "#plot_tweet_distributions_per_day(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_twitter_market_research(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # number of tweets per week\n",
    "    b=bucketed(df)\n",
    "    b.plot(title=\"Tweets per Week\")\n",
    "    plt.show()\n",
    "    \n",
    "    # distribution of tweets per week\n",
    "    vals = b[\"count\"].value_counts()\n",
    "    bins = vals.size\n",
    "    b[\"count\"].plot(kind=\"hist\",bins=bins, title=\"Tweets per Week Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "    # freq of tweets per day\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    \n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    df['day_of_week'].value_counts().reindex(weekdays).plot(kind='bar', title=\"Tweets per Calendar Day\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_range_str(range):\n",
    "    return str(range.start) + \"-\" + str(range.stop-1)\n",
    "\n",
    "def append_count(series, count, category_range):\n",
    "    return series.append(pd.Series([ count ], index=[ to_range_str(category_range) ]))\n",
    "\n",
    "# takes dataframe with tweet counts bucketed per n days\n",
    "# returns a data frame that returns counts for a category based, excluding coun\n",
    "# this answers: what is the probability that we end in a category, given that we have already seen curr_n values\n",
    "def count_adjusted(df, categories, curr_n):\n",
    "    grouped = pd.Series()\n",
    "    for rnge in categories:\n",
    "        adjusted_range = range(max(rnge.start-curr_n, 0), max(rnge.stop-curr_n, 0 ))\n",
    "        count = df[df[\"count\"].between(adjusted_range.start, adjusted_range.stop-1)].shape[0]\n",
    "        grouped = append_count(grouped, count, rnge)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_start_date(end_date_str):\n",
    "    end_date = parser.parse(end_date_str)\n",
    "    return end_date - datetime.timedelta(days=7)\n",
    "\n",
    "def time_boundaries(market_data, tz):\n",
    "    contracts = market_data[\"contracts\"]\n",
    "    end_date_str = contracts[0][\"dateEnd\"]\n",
    "    end_date = parser.parse(end_date_str)\n",
    "    start_date = end_date - datetime.timedelta(days=7)\n",
    "    return ( tz.localize(start_date), tz.localize(end_date) )\n",
    "    \n",
    "def eval_live_twitter_market(market, path, matching_tweets=None, show_market_research=False):\n",
    "    if show_market_research:\n",
    "        show_twitter_market_research(path)\n",
    "        \n",
    "    market_data = fetch_market_data(market[\"id\"])\n",
    "    timezone = pytz.timezone(\"US/Eastern\")\n",
    "    utc_now = pytz.utc.localize(datetime.datetime.utcnow())\n",
    "    ts = utc_now.astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "    start_date, end_date = time_boundaries(market_data, timezone)\n",
    "    \n",
    "    matching_tweets = get_recent_tweets(market[\"twitter_handle\"], from_date=start_date)\n",
    "    if ( \"filter\" in market.keys() ):\n",
    "        matching_tweets = matching_tweets[matching_tweets[\"text\"].str.contains(market[\"filter\"],case=False)]\n",
    "        #n_matching_tweets = len(matching_tweets[matching_tweets[\"text\"].str.contains(\"fake news|fakenews\",case=False)])\n",
    "    n_matching_tweets = len(matching_tweets)\n",
    "    eval_twitter_market(market, path, data=market_data, ts=ts, n_matching_tweets=n_matching_tweets)\n",
    "\n",
    "def eval_twitter_market(market, path, data=None, ts=None, n_matching_tweets=None, show_market_research=False):\n",
    "    if show_market_research:\n",
    "        show_twitter_market_research(path)\n",
    "        \n",
    "    if data is None:\n",
    "        data = fetch_market_data(market[\"id\"])\n",
    "    \n",
    "    data[\"timezone\"] = pytz.timezone(\"US/Eastern\") # timeStamp field in market data seems to be in US/Eastern \n",
    "    contracts = data[\"contracts\"]\n",
    "    for c in contracts:\n",
    "        c_id = str(c[\"id\"])\n",
    "        annotations = market[\"contract_map\"][c_id]\n",
    "        c[\"range\"] = annotations[\"range\"]\n",
    "        c[\"category\"] = to_range_str(c[\"range\"])\n",
    "    print(data[\"shortName\"])\n",
    "    \n",
    "    start_date, end_date = time_boundaries(data, data[\"timezone\"])\n",
    "    n_days = days_left(end_date, ts) # days left too complicated, can just dp end_date - ts\n",
    "    print(\"Days left:\", n_days)\n",
    "    \n",
    "    if matching_tweets is None:\n",
    "        matching_tweets = get_recent_tweets(market[\"twitter_handle\"], from_date=start_date)\n",
    "    if ( \"filter\" in market.keys() ):\n",
    "        matching_tweets = matching_tweets[matching_tweets[\"text\"].str.contains(market[\"filter\"],case=False)]\n",
    "        #n_matching_tweets = len(matching_tweets[matching_tweets[\"text\"].str.contains(\"fake news|fakenews\",case=False)])\n",
    "    n_matching_tweets = len(matching_tweets)\n",
    "    print(\"Matching tweets:\", n_matching_tweets)\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df['day_of_week'] = pd.to_datetime(df[\"created_at\"]).dt.tz_localize('UTC').dt.tz_convert('US/Eastern').dt.day_name()\n",
    "    weekdays = calendar.day_name\n",
    "    circular_weekdays = np.tile(weekdays, 2)\n",
    "    idx = np.where(circular_weekdays == ts.strftime(\"%A\"))[0][0]\n",
    "    weekdays_left = circular_weekdays[idx:idx+n_days]\n",
    "    \n",
    "    df = df[df[\"day_of_week\"].isin(weekdays_left)]   \n",
    "    b=bucketed(df, start_on=weekdays[idx])\n",
    "    c=count_adjusted(b, [c[\"range\"] for c in contracts], n_matching_tweets )\n",
    "    proba = c/c.sum()\n",
    "    print(\"Category probabilities:\")\n",
    "    pprint.pprint(proba)\n",
    "    \n",
    "    category_stats = pd.DataFrame({ \"price_per_share\": [], \"proba\": [] })\n",
    "    for c in contracts:\n",
    "        s = pd.Series({ \"price_per_share\": c[\"bestBuyYesCost\"], \"proba\": proba[c[\"category\"]] })\n",
    "        s.name = c[\"category\"]\n",
    "        category_stats = category_stats.append(s)\n",
    "    alloc = kelly_criterion(category_stats)\n",
    "    print(alloc)\n",
    "    place_orders(market[\"id\"], contracts, alloc, ACCOUNT_BALANCE * .1)\n",
    "    \n",
    "    #outcomes(positions, [c[\"category\"] for c in contracts])\n",
    "\n",
    "def days_left(end_date, ts):\n",
    "    start_date = end_date - datetime.timedelta(days=7)\n",
    "    delta = ts - start_date\n",
    "    days_left = ((7*24) - (delta.total_seconds()/3600))/24\n",
    "    return max(round(days_left),1)\n",
    "                    \n",
    "def outcomes(positions, categories):\n",
    "    for c in categories:\n",
    "        total = 0\n",
    "        for pp in positions:\n",
    "            if pp == c:\n",
    "                if \"yes\" in positions[pp]:\n",
    "                    for x in positions[pp][\"yes\"]:\n",
    "                        total += (1 - x[0])*x[1]\n",
    "                if \"no\" in positions[pp]:\n",
    "                    for x in positions[pp][\"no\"]:\n",
    "                        total -= x[0]*x[1]\n",
    "            else:\n",
    "                if \"yes\" in positions[pp]:\n",
    "                    for x in positions[pp][\"yes\"]:\n",
    "                        total -= x[0]*x[1]\n",
    "                if \"no\" in positions[pp]:\n",
    "                    for x in positions[pp][\"no\"]:\n",
    "                        total += (1-x[0])*x[1]\n",
    "        print(c, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale EV by risk for final quantity recommendations (to reduce volatility)\n",
    "# take expected tweets for day of week into account given some people dont tweet much on weekends\n",
    "# graph of tweet density per time per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "markets = [\n",
    "    { \n",
    "        \"id\": 5457, \n",
    "        \"twitter_handle\": \"@vp\", \n",
    "        \"contract_map\": {\n",
    "            \"15263\": { \"range\": range(0, 20) }, \n",
    "            \"15267\": { \"range\": range(20, 25) }, \n",
    "            \"15266\": { \"range\": range(25, 30) }, \n",
    "            \"15268\": { \"range\": range(30, 35) },\n",
    "            \"15264\": { \"range\": range(35, 40) },\n",
    "            \"15269\": { \"range\": range(40, 45) },\n",
    "            \"15265\": { \"range\": range(45, 100) }\n",
    "        },\n",
    "        \"positions\":{ \n",
    "        }\n",
    "    },\n",
    "    { \n",
    "        \"id\": 5407, \n",
    "        \"twitter_handle\": \"@whitehouse\", \n",
    "        \"contract_map\": {\n",
    "            \"14983\": { \"range\": range(0, 80) }, \n",
    "            \"14985\": { \"range\": range(80, 85) }, \n",
    "            \"14984\": { \"range\": range(85, 90) },\n",
    "            \"14986\": { \"range\": range(90, 95) },\n",
    "            \"14987\": { \"range\": range(95, 100) },\n",
    "            \"14988\": { \"range\": range(100, 105) }, \n",
    "            \"14989\": { \"range\": range(105, 300) }\n",
    "        },\n",
    "        #\"contract_map\": [ (\"14983\", range(0, 80)), (\"14985\",range(80, 85)), (\"14984\", range(85, 90)), (\"14986\", range(90, 95)), (\"14987\",range(95, 100)), (\"14988\", range(100, 105)), (\"14989\",range(105, 300))],\n",
    "        \"positions\": { \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5404, \n",
    "        \"twitter_handle\": \"@realDonaldTrump\",\n",
    "        \"contract_map\": {\n",
    "            \"14968\": { \"range\": range(0, 60) }, \n",
    "            \"14963\": { \"range\": range(60, 65) }, \n",
    "            \"14967\": { \"range\": range(65, 70) },\n",
    "            \"14965\": { \"range\": range(70, 75) },\n",
    "            \"14964\": { \"range\": range(75, 80) },\n",
    "            \"14966\": { \"range\": range(80, 85) }, \n",
    "            \"14962\": { \"range\": range(85, 200) }\n",
    "        },\n",
    "        #\"contract_map\": [ (\"14968\", range(0, 60)), (\"14963\",range(60, 65)), (\"14967\", range(65, 70)), (\"14965\", range(70, 75)), (\"14964\",range(75, 80)), (\"14966\", range(80, 85)), (\"14962\",range(85, 200))],\n",
    "        \"positions\": {\n",
    "            #\"0-59\": {\n",
    "            #    \"yes\": [(.12, 11)]\n",
    "            #},\n",
    "            #\"60-64\": {\n",
    "            #    \"yes\": [(.11, 12)]\n",
    "            #},\n",
    "            #\"70-74\": {\n",
    "            #    \"yes\": [(.04, 20)]\n",
    "            #},\n",
    "            #\"80-84\": {\n",
    "            #    \"no\": [(.69, 4)]\n",
    "            #},\n",
    "            #\"85-199\": {\n",
    "            #    \"no\": [(.74, 4),(.64,1),(.54,1), (.34, 3)]\n",
    "            #}\n",
    "        }\n",
    "    },\n",
    "    { \n",
    "        \"id\": 5458, \n",
    "        \"twitter_handle\": \"@potus\", \n",
    "        \"contract_map\": {\n",
    "            \"15270\": { \"range\": range(0, 45) }, \n",
    "            \"15274\": { \"range\": range(45, 50) },\n",
    "            \"15275\": { \"range\": range(50, 55) },\n",
    "            \"15271\": { \"range\": range(55, 60) }, \n",
    "            \"15272\": { \"range\": range(60, 65) }, \n",
    "            \"15273\": { \"range\": range(65, 69) },\n",
    "            \"15276\": { \"range\": range(70, 200) }\n",
    "        },\n",
    "        \"positions\": {\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def eval_markets(show_market_research=False):\n",
    "    for market in markets:\n",
    "        eval_twitter_market(market, \"data/tweets/{handle}.csv\".format(handle=market[\"twitter_handle\"]), show_market_research=show_market_research)\n",
    "        print(\"----------------------------------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct = .005\n",
    "# 2 pct = .01\n",
    "# 4 pct = .02\n",
    "# 8 pct = .03\n",
    "def alloc(expected_value, proba): \n",
    "    pct_alloc = min( expected_value / 2, .03)\n",
    "    risk_adjusted = pct_alloc# * ??\n",
    "    return risk_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_orders(market_id, contracts, optimal_set, account_balance):\n",
    "    for contract in contracts:\n",
    "        category = contract[\"category\"]\n",
    "        price_per_share = contract[\"bestBuyYesCost\"]\n",
    "        current_quantity = current_alloc(market_id, contract[\"id\"])\n",
    "        \n",
    "        if category not in optimal_set.index:\n",
    "            # TODO: this doesnt take into consideration sell price, which in this market is usually less than buy price\n",
    "            # could sell at best buy price...\n",
    "            if current_quantity > 0:\n",
    "                place_order({\n",
    "                    \"action\": \"sell\",\n",
    "                    \"category\": category,\n",
    "                    \"type\": \"yes\", \n",
    "                    \"price_per_share\": price_per_share,\n",
    "                    \"quantity\": current_quantity,\n",
    "                    #\"ev\": \"unknown\",\n",
    "                    \"market_id\": market_id,\n",
    "                    \"contract_id\": contract[\"id\"]\n",
    "                })\n",
    "        else:\n",
    "            row = optimal_set.loc[category,:]\n",
    "            optimal_alloc = (row[\"pct_alloc\"] * account_balance)\n",
    "            optimal_quantity = round( abs(optimal_alloc / price_per_share) )\n",
    "            quantity = optimal_quantity - current_quantity\n",
    "\n",
    "            if quantity > 0:\n",
    "                place_order({\n",
    "                    \"action\": \"buy\", \n",
    "                    \"category\": category,\n",
    "                    \"type\": \"yes\", \n",
    "                    \"price_per_share\": price_per_share,\n",
    "                    \"quantity\": quantity,\n",
    "                    #\"ev\": row[\"proba\"] - row[\"price_per_share\"],\n",
    "                    \"market_id\": market_id,\n",
    "                    \"contract_id\": contract[\"id\"]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = psycopg2.connect(database=\"predictit\", host=\"localhost\", port=\"5432\")\n",
    "#conn = create_engine(\"postgresql+psycopg2://@localhost:5432/predictit\"\n",
    "db_string = \"postgresql+psycopg2://@localhost:5432/predictit\"\n",
    "def current_alloc(market_id, contract_id):\n",
    "    contract_orders = psql.read_sql(\"SELECT * from orders WHERE market_id = \\'{m_id}\\' AND contract_id = \\'{c_id}\\'\".format(m_id=market_id, c_id=contract_id), db_string)\n",
    "\n",
    "    quantity = 0\n",
    "    for i,o in contract_orders.iterrows():\n",
    "        multiplier = -1 if o[\"action\"] == \"sell\" else 1\n",
    "        quantity += o[\"quantity\"] * multiplier\n",
    "    return quantity\n",
    "\n",
    "def place_order(order, verbose=True):\n",
    "    df = pd.Series(order).to_frame().transpose()\n",
    "    print(df)\n",
    "    df.to_sql('orders', con=db_string, if_exists='append', index=False)\n",
    "    if verbose:\n",
    "        print(order)\n",
    "        \n",
    "def record_timepoint(market_id=5458):\n",
    "    data = fetch_market_data(market_id)\n",
    "    twitter_handle = re.match(r\".*@(\\w{1,15})\",data[\"shortName\"]).group(0).split(' ')[-1]\n",
    "    df = pd.Series({ \"timestamp\": data[\"timeStamp\"], \"market_id\": data[\"id\"], \"handle\": twitter_handle, \"data\": json.dumps(data) }).to_frame().transpose()\n",
    "    df.to_sql('market_data', con=db_string, if_exists='append', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_timepoint(market_id=5478)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>expected_revenue_rate</th>\n",
       "      <th>price_per_share</th>\n",
       "      <th>proba</th>\n",
       "      <th>pct_alloc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beta  expected_revenue_rate  price_per_share  proba  pct_alloc\n",
       "1   0.1                   2.70              0.1    0.3        0.4\n",
       "2   0.2                   1.35              0.2    0.3        0.5\n",
       "3   0.4                   1.35              0.4    0.6        1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bought_at: .10\n",
    "# EV: .70\n",
    "# price: .75\n",
    "# SELL (not in optimal set)\n",
    "\n",
    "# bought_at: .10\n",
    "# EV: .70\n",
    "# price: .50\n",
    "# BUY (but would have more shares than recommended)\n",
    "\n",
    "# bought_at: .10 \n",
    "# EV: .70\n",
    "# price: .05\n",
    "# BUY (difference over current alloc)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: .70\n",
    "# price: .75\n",
    "# SELL (not in optimal set)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: .70\n",
    "# price: .50\n",
    "# BUY (likely allocation is less than what you have, in which case you sell)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: -.10\n",
    "# price: .50\n",
    "#\n",
    "\n",
    "market = { \n",
    "    \"id\": 5411, \n",
    "    \"twitter_handle\": \"@potus\", \n",
    "    \"contract_map\": [ (\"15008\", range(0, 35)), (\"15010\",range(35, 40)), (\"15011\", range(40, 45)), (\"15012\", range(45, 50)), (\"15013\",range(50, 55)), (\"15009\", range(55, 60)), (\"15014\",range(60, 200))]\n",
    "}\n",
    "df = pd.DataFrame({ \"price_per_share\": [.2, .51, .40, .01, .10], \"proba\": [.30, .10, .60, .02, .7] }, index=[\"0-59\", \"60-64\", \"65-69\", \"70-71\", \"test\"])\n",
    "df = pd.DataFrame({ \"price_per_share\": [.10, .2, .40], \"proba\": [.3, .30, .60] }, index=[\"1\", \"2\", \"3\"])\n",
    "alloc = kelly_criterion(df)\n",
    "alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-03 17:48:47.970490 2019-05-03T17:48:02.9261092\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "2019-05-03 17:48:48.055239 2019-05-03T17:48:03.6942739\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "2019-05-03 17:48:48.127188 2019-05-03T17:48:04.4758205\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "2019-05-03 17:48:48.207926 2019-05-03T17:48:05.3067419\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_markets(show_market_research=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_market(market):\n",
    "    historical_data = psql.read_sql(\"SELECT * from market_data WHERE handle = \\'{handle}\\'\".format(handle=market[\"twitter_handle\"]), db_string)\n",
    "    path = \"data/tweets/{handle}.csv\".format(handle=market[\"twitter_handle\"])\n",
    "    for i, data_point in historical_data.iterrows():\n",
    "        timezone = pytz.timezone(\"US/Eastern\")\n",
    "        ts = timezone.localize( parser.parse(data_point[\"timestamp\"]) )\n",
    "        market_data = json.loads(data_point[\"data\"])\n",
    "        start_date, end_date = time_boundaries(market_data, timezone)\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "        df[\"created_at\"] = df[\"created_at\"].dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "        print(ts, start_date, end_date)\n",
    "        return df[(df[\"created_at\"] >= start_date) & (df[\"created_at\"] <= ts)]\n",
    "        eval_twitter_market(market, path, data=market_data, ts=ts, show_market_research=False)\n",
    "\n",
    "def simulate_markets():\n",
    "    for m in markets:\n",
    "        simulate_market(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-03 14:07:47.444884-04:00 2019-05-03 12:00:00-04:00 2019-05-10 12:00:00-04:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, created_at, id, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_market(markets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-03 17:24:58</td>\n",
       "      <td>1124364235360882689</td>\n",
       "      <td>RT @realDonaldTrump: ....We discussed Trade, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-03 17:24:52</td>\n",
       "      <td>1124364212749336576</td>\n",
       "      <td>RT @realDonaldTrump: Had a long and very good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-05-03 16:23:36</td>\n",
       "      <td>1124348791765774340</td>\n",
       "      <td>RT @realDonaldTrump: We can all agree that AME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-03 16:23:30</td>\n",
       "      <td>1124348769787625472</td>\n",
       "      <td>RT @realDonaldTrump: “The U.S. Created 263,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-03 13:51:26</td>\n",
       "      <td>1124310501104680961</td>\n",
       "      <td>RT @realDonaldTrump: Finally, Mainstream Media...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-03 13:42:36</td>\n",
       "      <td>1124308278886973445</td>\n",
       "      <td>RT @WhiteHouse: It's another historic Jobs Day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-05-03 13:42:35</td>\n",
       "      <td>1124308272196927490</td>\n",
       "      <td>RT @realDonaldTrump: JOBS, JOBS, JOBS!\\n\\n“Job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-05-03 00:12:27</td>\n",
       "      <td>1124104394788823041</td>\n",
       "      <td>RT @realDonaldTrump: Proclamation on Days of R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-05-02 23:52:27</td>\n",
       "      <td>1124099364354445317</td>\n",
       "      <td>RT @realDonaldTrump: On this day of prayer, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2019-05-02 17:02:56</td>\n",
       "      <td>1123996306115059713</td>\n",
       "      <td>RT @realDonaldTrump: ....and deregulation whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-05-02 17:02:53</td>\n",
       "      <td>1123996292445765639</td>\n",
       "      <td>RT @realDonaldTrump: Steve Moore, a great pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2019-05-02 15:10:40</td>\n",
       "      <td>1123968053107208192</td>\n",
       "      <td>RT @WhiteHouse: LIVE: President Trump and The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2019-05-02 03:05:48</td>\n",
       "      <td>1123785634961874949</td>\n",
       "      <td>RT @realDonaldTrump: I am continuing to monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2019-05-02 02:05:29</td>\n",
       "      <td>1123770455012278273</td>\n",
       "      <td>RT @WhiteHouse: \"So tonight we praise God for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2019-05-02 02:05:27</td>\n",
       "      <td>1123770444576903169</td>\n",
       "      <td>RT @WhiteHouse: \"During this holy season when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2019-05-02 02:05:24</td>\n",
       "      <td>1123770434720235520</td>\n",
       "      <td>RT @WhiteHouse: \"Tonight we break bread togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2019-05-02 02:00:27</td>\n",
       "      <td>1123769187661426690</td>\n",
       "      <td>RT @realDonaldTrump: https://t.co/S34Q0NY6Ju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2019-05-02 01:55:56</td>\n",
       "      <td>1123768049960652800</td>\n",
       "      <td>RT @FLOTUS: It was an honor to host so many wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2019-05-01 13:06:00</td>\n",
       "      <td>1123574292002803713</td>\n",
       "      <td>RT @realDonaldTrump: Congress must change the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2019-05-01 13:05:53</td>\n",
       "      <td>1123574259815677953</td>\n",
       "      <td>RT @realDonaldTrump: “No President in history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2019-05-01 13:05:45</td>\n",
       "      <td>1123574225510567937</td>\n",
       "      <td>RT @realDonaldTrump: Gallup Poll: 56% of Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2019-05-01 13:05:38</td>\n",
       "      <td>1123574199166144517</td>\n",
       "      <td>RT @realDonaldTrump: I am overriding the Decom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2019-05-01 13:05:31</td>\n",
       "      <td>1123574168472170496</td>\n",
       "      <td>RT @realDonaldTrump: “The Democrats can’t come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2019-05-01 02:29:16</td>\n",
       "      <td>1123414050858315779</td>\n",
       "      <td>RT @WhiteHouse: To all the patriotic citizens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2019-04-30 23:45:22</td>\n",
       "      <td>1123372805591052289</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2019-04-30 23:45:21</td>\n",
       "      <td>1123372798406213638</td>\n",
       "      <td>RT @WhiteHouse: “NASCAR is not only a thrillin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2019-04-30 23:45:15</td>\n",
       "      <td>1123372776851742720</td>\n",
       "      <td>RT @WhiteHouse: President @realDonaldTrump hos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2019-04-30 21:10:14</td>\n",
       "      <td>1123333763004620801</td>\n",
       "      <td>RT @realDonaldTrump: ....embargo, together wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2019-04-30 21:10:12</td>\n",
       "      <td>1123333757094846465</td>\n",
       "      <td>RT @realDonaldTrump: If Cuban Troops and Milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2019-04-30 20:52:06</td>\n",
       "      <td>1123329199144677377</td>\n",
       "      <td>RT @WhiteHouse: National Security Advisor @Amb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>181</td>\n",
       "      <td>2018-05-03 21:21:25</td>\n",
       "      <td>992152172568641536</td>\n",
       "      <td>RT @WhiteHouse: .@SBALinda: @SBAgov Boosts Wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>182</td>\n",
       "      <td>2018-05-03 21:21:22</td>\n",
       "      <td>992152158647840770</td>\n",
       "      <td>RT @WhiteHouse: President Trump has made it cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>183</td>\n",
       "      <td>2018-05-03 18:22:34</td>\n",
       "      <td>992107161605033984</td>\n",
       "      <td>RT @realDonaldTrump: #NationalDayOfPrayer http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>184</td>\n",
       "      <td>2018-05-03 16:56:28</td>\n",
       "      <td>992085493574782976</td>\n",
       "      <td>RT @WhiteHouse: \"The Faith Initiative will hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>185</td>\n",
       "      <td>2018-05-03 16:56:25</td>\n",
       "      <td>992085481146994688</td>\n",
       "      <td>RT @WhiteHouse: \"Faith has shaped our families...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>186</td>\n",
       "      <td>2018-05-03 16:56:22</td>\n",
       "      <td>992085469876846593</td>\n",
       "      <td>RT @WhiteHouse: \"Rev. Graham’s words remind us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>187</td>\n",
       "      <td>2018-05-03 16:27:42</td>\n",
       "      <td>992078253706874880</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>188</td>\n",
       "      <td>2018-05-03 15:50:35</td>\n",
       "      <td>992068915210653696</td>\n",
       "      <td>RT @WhiteHouse: Today, President Trump signed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-05-03 15:29:35</td>\n",
       "      <td>992063630580633600</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>190</td>\n",
       "      <td>2018-05-03 13:56:32</td>\n",
       "      <td>992040211256430593</td>\n",
       "      <td>RT @WhiteHouse: President Donald J. Trump proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>191</td>\n",
       "      <td>2018-05-02 22:42:00</td>\n",
       "      <td>991810062510379008</td>\n",
       "      <td>RT @WhiteHouse: Gina Haspel has developed outs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>192</td>\n",
       "      <td>2018-05-02 20:39:20</td>\n",
       "      <td>991779192730800135</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>193</td>\n",
       "      <td>2018-05-02 20:31:30</td>\n",
       "      <td>991777222380916736</td>\n",
       "      <td>RT @realDonaldTrump: I have been briefed on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>194</td>\n",
       "      <td>2018-05-02 20:16:42</td>\n",
       "      <td>991773496828203013</td>\n",
       "      <td>RT @WhiteHouse: Gina Haspel has displayed dedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>195</td>\n",
       "      <td>2018-05-02 18:17:05</td>\n",
       "      <td>991743395272982528</td>\n",
       "      <td>RT @realDonaldTrump: Congratulations @SecPompe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>196</td>\n",
       "      <td>2018-05-02 16:45:49</td>\n",
       "      <td>991720426278711296</td>\n",
       "      <td>RT @WhiteHouse: The Wall Street Journal: From ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>197</td>\n",
       "      <td>2018-05-02 16:08:20</td>\n",
       "      <td>991710994480226305</td>\n",
       "      <td>RT @WhiteHouse: \"For nearly 230 years, the men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>198</td>\n",
       "      <td>2018-05-02 15:48:57</td>\n",
       "      <td>991706115313491973</td>\n",
       "      <td>RT @WhiteHouse: A number of public officials h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>199</td>\n",
       "      <td>2018-05-02 15:17:48</td>\n",
       "      <td>991698274347347968</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-02 14:47:07</td>\n",
       "      <td>991690554932187136</td>\n",
       "      <td>RT @WhiteHouse: Today President Trump and Vice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-02 13:55:13</td>\n",
       "      <td>991677493659799552</td>\n",
       "      <td>RT @WhiteHouse: What They Are Saying: Widespre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-01 19:44:47</td>\n",
       "      <td>991403078401347584</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-05-01 18:14:56</td>\n",
       "      <td>991380465067098113</td>\n",
       "      <td>RT @realDonaldTrump: Congratulations @ArmyWP_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-01 16:59:25</td>\n",
       "      <td>991361461812416513</td>\n",
       "      <td>RT @realDonaldTrump: Today I had the great hon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-05-01 16:03:26</td>\n",
       "      <td>991347372033740800</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-05-01 15:24:07</td>\n",
       "      <td>991337476177453058</td>\n",
       "      <td>RT @realDonaldTrump: Yesterday, it was my grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-04-29 04:37:12</td>\n",
       "      <td>990449901812281344</td>\n",
       "      <td>RT @WhiteHouse: Loopholes in our immigration s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-04-29 04:35:42</td>\n",
       "      <td>990449522492018688</td>\n",
       "      <td>RT @sarasotapd: We might be biased but our Off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-04-29 01:18:20</td>\n",
       "      <td>990399855699865601</td>\n",
       "      <td>RT @WhiteHouse: Now nearly a decade and a half...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-04-29 01:17:42</td>\n",
       "      <td>990399692524670976</td>\n",
       "      <td>RT @realDonaldTrump: Secret Service has just i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3211 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           created_at                   id  \\\n",
       "0              0  2019-05-03 17:24:58  1124364235360882689   \n",
       "1              1  2019-05-03 17:24:52  1124364212749336576   \n",
       "2              2  2019-05-03 16:23:36  1124348791765774340   \n",
       "3              3  2019-05-03 16:23:30  1124348769787625472   \n",
       "4              4  2019-05-03 13:51:26  1124310501104680961   \n",
       "5              5  2019-05-03 13:42:36  1124308278886973445   \n",
       "6              6  2019-05-03 13:42:35  1124308272196927490   \n",
       "7              7  2019-05-03 00:12:27  1124104394788823041   \n",
       "8              8  2019-05-02 23:52:27  1124099364354445317   \n",
       "9              9  2019-05-02 17:02:56  1123996306115059713   \n",
       "10            10  2019-05-02 17:02:53  1123996292445765639   \n",
       "11            11  2019-05-02 15:10:40  1123968053107208192   \n",
       "12            12  2019-05-02 03:05:48  1123785634961874949   \n",
       "13            13  2019-05-02 02:05:29  1123770455012278273   \n",
       "14            14  2019-05-02 02:05:27  1123770444576903169   \n",
       "15            15  2019-05-02 02:05:24  1123770434720235520   \n",
       "16            16  2019-05-02 02:00:27  1123769187661426690   \n",
       "17            17  2019-05-02 01:55:56  1123768049960652800   \n",
       "18            18  2019-05-01 13:06:00  1123574292002803713   \n",
       "19            19  2019-05-01 13:05:53  1123574259815677953   \n",
       "20            20  2019-05-01 13:05:45  1123574225510567937   \n",
       "21            21  2019-05-01 13:05:38  1123574199166144517   \n",
       "22            22  2019-05-01 13:05:31  1123574168472170496   \n",
       "23            23  2019-05-01 02:29:16  1123414050858315779   \n",
       "24            24  2019-04-30 23:45:22  1123372805591052289   \n",
       "25            25  2019-04-30 23:45:21  1123372798406213638   \n",
       "26            26  2019-04-30 23:45:15  1123372776851742720   \n",
       "27            27  2019-04-30 21:10:14  1123333763004620801   \n",
       "28            28  2019-04-30 21:10:12  1123333757094846465   \n",
       "29            29  2019-04-30 20:52:06  1123329199144677377   \n",
       "...          ...                  ...                  ...   \n",
       "3181         181  2018-05-03 21:21:25   992152172568641536   \n",
       "3182         182  2018-05-03 21:21:22   992152158647840770   \n",
       "3183         183  2018-05-03 18:22:34   992107161605033984   \n",
       "3184         184  2018-05-03 16:56:28   992085493574782976   \n",
       "3185         185  2018-05-03 16:56:25   992085481146994688   \n",
       "3186         186  2018-05-03 16:56:22   992085469876846593   \n",
       "3187         187  2018-05-03 16:27:42   992078253706874880   \n",
       "3188         188  2018-05-03 15:50:35   992068915210653696   \n",
       "3189         189  2018-05-03 15:29:35   992063630580633600   \n",
       "3190         190  2018-05-03 13:56:32   992040211256430593   \n",
       "3191         191  2018-05-02 22:42:00   991810062510379008   \n",
       "3192         192  2018-05-02 20:39:20   991779192730800135   \n",
       "3193         193  2018-05-02 20:31:30   991777222380916736   \n",
       "3194         194  2018-05-02 20:16:42   991773496828203013   \n",
       "3195         195  2018-05-02 18:17:05   991743395272982528   \n",
       "3196         196  2018-05-02 16:45:49   991720426278711296   \n",
       "3197         197  2018-05-02 16:08:20   991710994480226305   \n",
       "3198         198  2018-05-02 15:48:57   991706115313491973   \n",
       "3199         199  2018-05-02 15:17:48   991698274347347968   \n",
       "3200           0  2018-05-02 14:47:07   991690554932187136   \n",
       "3201           1  2018-05-02 13:55:13   991677493659799552   \n",
       "3202           2  2018-05-01 19:44:47   991403078401347584   \n",
       "3203           3  2018-05-01 18:14:56   991380465067098113   \n",
       "3204           4  2018-05-01 16:59:25   991361461812416513   \n",
       "3205           5  2018-05-01 16:03:26   991347372033740800   \n",
       "3206           6  2018-05-01 15:24:07   991337476177453058   \n",
       "3207           7  2018-04-29 04:37:12   990449901812281344   \n",
       "3208           8  2018-04-29 04:35:42   990449522492018688   \n",
       "3209           9  2018-04-29 01:18:20   990399855699865601   \n",
       "3210          10  2018-04-29 01:17:42   990399692524670976   \n",
       "\n",
       "                                                   text  \n",
       "0     RT @realDonaldTrump: ....We discussed Trade, V...  \n",
       "1     RT @realDonaldTrump: Had a long and very good ...  \n",
       "2     RT @realDonaldTrump: We can all agree that AME...  \n",
       "3     RT @realDonaldTrump: “The U.S. Created 263,000...  \n",
       "4     RT @realDonaldTrump: Finally, Mainstream Media...  \n",
       "5     RT @WhiteHouse: It's another historic Jobs Day...  \n",
       "6     RT @realDonaldTrump: JOBS, JOBS, JOBS!\\n\\n“Job...  \n",
       "7     RT @realDonaldTrump: Proclamation on Days of R...  \n",
       "8     RT @realDonaldTrump: On this day of prayer, we...  \n",
       "9     RT @realDonaldTrump: ....and deregulation whic...  \n",
       "10    RT @realDonaldTrump: Steve Moore, a great pro-...  \n",
       "11    RT @WhiteHouse: LIVE: President Trump and The ...  \n",
       "12    RT @realDonaldTrump: I am continuing to monito...  \n",
       "13    RT @WhiteHouse: \"So tonight we praise God for ...  \n",
       "14    RT @WhiteHouse: \"During this holy season when ...  \n",
       "15    RT @WhiteHouse: \"Tonight we break bread togeth...  \n",
       "16         RT @realDonaldTrump: https://t.co/S34Q0NY6Ju  \n",
       "17    RT @FLOTUS: It was an honor to host so many wo...  \n",
       "18    RT @realDonaldTrump: Congress must change the ...  \n",
       "19    RT @realDonaldTrump: “No President in history ...  \n",
       "20    RT @realDonaldTrump: Gallup Poll: 56% of Ameri...  \n",
       "21    RT @realDonaldTrump: I am overriding the Decom...  \n",
       "22    RT @realDonaldTrump: “The Democrats can’t come...  \n",
       "23    RT @WhiteHouse: To all the patriotic citizens ...  \n",
       "24    RT @realDonaldTrump: Today, it was my great ho...  \n",
       "25    RT @WhiteHouse: “NASCAR is not only a thrillin...  \n",
       "26    RT @WhiteHouse: President @realDonaldTrump hos...  \n",
       "27    RT @realDonaldTrump: ....embargo, together wit...  \n",
       "28    RT @realDonaldTrump: If Cuban Troops and Milit...  \n",
       "29    RT @WhiteHouse: National Security Advisor @Amb...  \n",
       "...                                                 ...  \n",
       "3181  RT @WhiteHouse: .@SBALinda: @SBAgov Boosts Wom...  \n",
       "3182  RT @WhiteHouse: President Trump has made it cl...  \n",
       "3183  RT @realDonaldTrump: #NationalDayOfPrayer http...  \n",
       "3184  RT @WhiteHouse: \"The Faith Initiative will hel...  \n",
       "3185  RT @WhiteHouse: \"Faith has shaped our families...  \n",
       "3186  RT @WhiteHouse: \"Rev. Graham’s words remind us...  \n",
       "3187  RT @realDonaldTrump: Today, it was my great ho...  \n",
       "3188  RT @WhiteHouse: Today, President Trump signed ...  \n",
       "3189  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3190  RT @WhiteHouse: President Donald J. Trump proc...  \n",
       "3191  RT @WhiteHouse: Gina Haspel has developed outs...  \n",
       "3192  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3193  RT @realDonaldTrump: I have been briefed on th...  \n",
       "3194  RT @WhiteHouse: Gina Haspel has displayed dedi...  \n",
       "3195  RT @realDonaldTrump: Congratulations @SecPompe...  \n",
       "3196  RT @WhiteHouse: The Wall Street Journal: From ...  \n",
       "3197  RT @WhiteHouse: \"For nearly 230 years, the men...  \n",
       "3198  RT @WhiteHouse: A number of public officials h...  \n",
       "3199  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3200  RT @WhiteHouse: Today President Trump and Vice...  \n",
       "3201  RT @WhiteHouse: What They Are Saying: Widespre...  \n",
       "3202  RT @realDonaldTrump: Today, it was my great ho...  \n",
       "3203  RT @realDonaldTrump: Congratulations @ArmyWP_F...  \n",
       "3204  RT @realDonaldTrump: Today I had the great hon...  \n",
       "3205  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3206  RT @realDonaldTrump: Yesterday, it was my grea...  \n",
       "3207  RT @WhiteHouse: Loopholes in our immigration s...  \n",
       "3208  RT @sarasotapd: We might be biased but our Off...  \n",
       "3209  RT @WhiteHouse: Now nearly a decade and a half...  \n",
       "3210  RT @realDonaldTrump: Secret Service has just i...  \n",
       "\n",
       "[3211 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/tweets/@potus.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Friday\n",
       "1          Friday\n",
       "2          Friday\n",
       "3          Friday\n",
       "4          Friday\n",
       "5          Friday\n",
       "6          Friday\n",
       "7        Thursday\n",
       "8        Thursday\n",
       "9        Thursday\n",
       "10       Thursday\n",
       "11       Thursday\n",
       "12      Wednesday\n",
       "13      Wednesday\n",
       "14      Wednesday\n",
       "15      Wednesday\n",
       "16      Wednesday\n",
       "17      Wednesday\n",
       "18      Wednesday\n",
       "19      Wednesday\n",
       "20      Wednesday\n",
       "21      Wednesday\n",
       "22      Wednesday\n",
       "23        Tuesday\n",
       "24        Tuesday\n",
       "25        Tuesday\n",
       "26        Tuesday\n",
       "27        Tuesday\n",
       "28        Tuesday\n",
       "29        Tuesday\n",
       "          ...    \n",
       "3181     Thursday\n",
       "3182     Thursday\n",
       "3183     Thursday\n",
       "3184     Thursday\n",
       "3185     Thursday\n",
       "3186     Thursday\n",
       "3187     Thursday\n",
       "3188     Thursday\n",
       "3189     Thursday\n",
       "3190     Thursday\n",
       "3191    Wednesday\n",
       "3192    Wednesday\n",
       "3193    Wednesday\n",
       "3194    Wednesday\n",
       "3195    Wednesday\n",
       "3196    Wednesday\n",
       "3197    Wednesday\n",
       "3198    Wednesday\n",
       "3199    Wednesday\n",
       "3200    Wednesday\n",
       "3201    Wednesday\n",
       "3202      Tuesday\n",
       "3203      Tuesday\n",
       "3204      Tuesday\n",
       "3205      Tuesday\n",
       "3206      Tuesday\n",
       "3207       Sunday\n",
       "3208       Sunday\n",
       "3209     Saturday\n",
       "3210     Saturday\n",
       "Name: created_at, Length: 3211, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df[\"created_at\"]).dt.tz_localize('UTC').dt.tz_convert('US/Eastern').dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Friday\n",
       "1          Friday\n",
       "2          Friday\n",
       "3          Friday\n",
       "4          Friday\n",
       "5          Friday\n",
       "6          Friday\n",
       "7          Friday\n",
       "8        Thursday\n",
       "9        Thursday\n",
       "10       Thursday\n",
       "11       Thursday\n",
       "12       Thursday\n",
       "13       Thursday\n",
       "14       Thursday\n",
       "15       Thursday\n",
       "16       Thursday\n",
       "17       Thursday\n",
       "18      Wednesday\n",
       "19      Wednesday\n",
       "20      Wednesday\n",
       "21      Wednesday\n",
       "22      Wednesday\n",
       "23      Wednesday\n",
       "24        Tuesday\n",
       "25        Tuesday\n",
       "26        Tuesday\n",
       "27        Tuesday\n",
       "28        Tuesday\n",
       "29        Tuesday\n",
       "          ...    \n",
       "3181     Thursday\n",
       "3182     Thursday\n",
       "3183     Thursday\n",
       "3184     Thursday\n",
       "3185     Thursday\n",
       "3186     Thursday\n",
       "3187     Thursday\n",
       "3188     Thursday\n",
       "3189     Thursday\n",
       "3190     Thursday\n",
       "3191    Wednesday\n",
       "3192    Wednesday\n",
       "3193    Wednesday\n",
       "3194    Wednesday\n",
       "3195    Wednesday\n",
       "3196    Wednesday\n",
       "3197    Wednesday\n",
       "3198    Wednesday\n",
       "3199    Wednesday\n",
       "3200    Wednesday\n",
       "3201    Wednesday\n",
       "3202      Tuesday\n",
       "3203      Tuesday\n",
       "3204      Tuesday\n",
       "3205      Tuesday\n",
       "3206      Tuesday\n",
       "3207       Sunday\n",
       "3208       Sunday\n",
       "3209       Sunday\n",
       "3210       Sunday\n",
       "Name: created_at, Length: 3211, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df['created_at']).dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 5478,\n",
       " 'name': 'How many tweets will @vp post from noon 5/3 - noon 5/10?',\n",
       " 'shortName': '@vp tweets noon 5/3 - noon 5/10?',\n",
       " 'image': 'https://az620379.vo.msecnd.net/images/Markets/a9b732f2-de51-47f2-a306-cb0f14f07f17.png',\n",
       " 'url': 'https://www.predictit.org/markets/detail/5478/How-many-tweets-will-@vp-post-from-noon-5-3-noon-5-10',\n",
       " 'contracts': [{'id': 15350,\n",
       "   'dateEnd': '2019-05-10T12:00:00',\n",
       "   'image': 'https://az620379.vo.msecnd.net/images/Contracts/small_3b509298-d8d7-4938-b84f-70b5de800faa.png',\n",
       "   'name': '55 or more',\n",
       "   'longName': 'Will @vp post 55 or more tweets from noon 5/3 - noon 5/10?',\n",
       "   'shortName': '55+',\n",
       "   'status': 'Open',\n",
       "   'lastTradePrice': 0.34,\n",
       "   'bestBuyYesCost': 0.33,\n",
       "   'bestBuyNoCost': 0.72,\n",
       "   'bestSellYesCost': 0.28,\n",
       "   'bestSellNoCost': 0.67,\n",
       "   'lastClosePrice': None,\n",
       "   'displayOrder': 0},\n",
       "  {'id': 15354,\n",
       "   'dateEnd': '2019-05-10T12:00:00',\n",
       "   'image': 'https://az620379.vo.msecnd.net/images/Contracts/small_7a10f981-7d85-473c-9c4f-ce8e4ef37e14.png',\n",
       "   'name': '40 - 44',\n",
       "   'longName': 'Will @vp post 40 - 44 tweets from noon 5/3 - noon 5/10?',\n",
       "   'shortName': '40 - 44',\n",
       "   'status': 'Open',\n",
       "   'lastTradePrice': 0.2,\n",
       "   'bestBuyYesCost': 0.18,\n",
       "   'bestBuyNoCost': 0.85,\n",
       "   'bestSellYesCost': 0.15,\n",
       "   'bestSellNoCost': 0.82,\n",
       "   'lastClosePrice': None,\n",
       "   'displayOrder': 0},\n",
       "  {'id': 15352,\n",
       "   'dateEnd': '2019-05-10T12:00:00',\n",
       "   'image': 'https://az620379.vo.msecnd.net/images/Contracts/small_15e92fc1-f19d-4314-801e-7641afc35a13.png',\n",
       "   'name': '45 - 49',\n",
       "   'longName': 'Will @vp post 45 - 49 tweets from noon 5/3 - noon 5/10?',\n",
       "   'shortName': '45 - 49',\n",
       "   'status': 'Open',\n",
       "   'lastTradePrice': 0.19,\n",
       "   'bestBuyYesCost': 0.19,\n",
       "   'bestBuyNoCost': 0.83,\n",
       "   'bestSellYesCost': 0.17,\n",
       "   'bestSellNoCost': 0.81,\n",
       "   'lastClosePrice': None,\n",
       "   'displayOrder': 0},\n",
       "  {'id': 15351,\n",
       "   'dateEnd': '2019-05-10T12:00:00',\n",
       "   'image': 'https://az620379.vo.msecnd.net/images/Contracts/small_c0d04384-c9dc-4d5b-8563-209feb8dec67.png',\n",
       "   'name': '50 - 54',\n",
       "   'longName': 'Will @vp post 50 - 54 tweets from noon 5/3 - noon 5/10?',\n",
       "   'shortName': '50 - 54',\n",
       "   'status': 'Open',\n",
       "   'lastTradePrice': 0.16,\n",
       "   'bestBuyYesCost': 0.17,\n",
       "   'bestBuyNoCost': 0.85,\n",
       "   'bestSellYesCost': 0.15,\n",
       "   'bestSellNoCost': 0.83,\n",
       "   'lastClosePrice': None,\n",
       "   'displayOrder': 0},\n",
       "  {'id': 15349,\n",
       "   'dateEnd': '2019-05-10T12:00:00',\n",
       "   'image': 'https://az620379.vo.msecnd.net/images/Contracts/small_725ed7f6-d9f5-490d-aacf-86ffb2d49a9f.png',\n",
       "   'name': '35 - 39',\n",
       "   'longName': 'Will @vp post 35 - 39 tweets from noon 5/3 - noon 5/10?',\n",
       "   'shortName': '35 - 39',\n",
       "   'status': 'Open',\n",
       "   'lastTradePrice': 0.09,\n",
       "   'bestBuyYesCost': 0.13,\n",
       "   'bestBuyNoCost': 0.89,\n",
       "   'bestSellYesCost': 0.11,\n",
       "   'bestSellNoCost': 0.87,\n",
       "   'lastClosePrice': None,\n",
       "   'displayOrder': 0},\n",
       "  {'id': 15353,\n",
       "   'dateEnd': '2019-05-10T12:00:00',\n",
       "   'image': 'https://az620379.vo.msecnd.net/images/Contracts/small_77c65927-e5a3-4585-a38d-6fbfcd902bf7.png',\n",
       "   'name': '30 - 34',\n",
       "   'longName': 'Will @vp post 30 - 34 tweets from noon 5/3 - noon 5/10?',\n",
       "   'shortName': '30 - 34',\n",
       "   'status': 'Open',\n",
       "   'lastTradePrice': 0.08,\n",
       "   'bestBuyYesCost': 0.08,\n",
       "   'bestBuyNoCost': 0.93,\n",
       "   'bestSellYesCost': 0.07,\n",
       "   'bestSellNoCost': 0.92,\n",
       "   'lastClosePrice': None,\n",
       "   'displayOrder': 0},\n",
       "  {'id': 15348,\n",
       "   'dateEnd': '2019-05-10T12:00:00',\n",
       "   'image': 'https://az620379.vo.msecnd.net/images/Contracts/small_8ead3b84-57cf-4e1c-94c0-fe21d9fe1a66.png',\n",
       "   'name': '29 or fewer',\n",
       "   'longName': 'Will @vp post 29 or fewer tweets from noon 5/3 - noon 5/10?',\n",
       "   'shortName': '29-',\n",
       "   'status': 'Open',\n",
       "   'lastTradePrice': 0.05,\n",
       "   'bestBuyYesCost': 0.06,\n",
       "   'bestBuyNoCost': 0.95,\n",
       "   'bestSellYesCost': 0.05,\n",
       "   'bestSellNoCost': 0.94,\n",
       "   'lastClosePrice': None,\n",
       "   'displayOrder': 0}],\n",
       " 'timeStamp': '2019-05-03T22:45:02.671738',\n",
       " 'status': 'Open'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_market_data(5478)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = datetime.datetime(2019,5,6,12,0,0)\n",
    "d2 = datetime.datetime(2019,5,4,23,0,0)\n",
    "days_left(d1,d2)\n",
    "#start_date = end_date - datetime.timedelta(days=7)\n",
    "#    delta = ts - start_date\n",
    "#    days_left = ((7*24) - (delta.total_seconds()/3600))/24\n",
    "#    return max(round(days_left),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(1, 46800)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 - d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
