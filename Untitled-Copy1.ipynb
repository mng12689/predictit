{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import os\n",
    "import dateutil\n",
    "import time\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical data\n",
    "import calendar\n",
    "\n",
    "def next_weekday(d, weekday):\n",
    "    days_ahead = weekday - d.weekday()\n",
    "    if days_ahead < 0: # Target day already happened this week\n",
    "        days_ahead += 7\n",
    "    return d + datetime.timedelta(days_ahead)\n",
    "\n",
    "def bucketed(df, start_on=\"Sunday\"):\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    \n",
    "    df['created_at'] = pd.to_datetime(df['created_at']).dt.date\n",
    "    min_date = df[\"created_at\"].min()\n",
    "    min_date = next_weekday(min_date, list(calendar.day_name).index(start_on))\n",
    "    max_date = df[\"created_at\"].max()\n",
    "    tweet_counts = df.groupby('created_at').agg('count')[\"text\"]\n",
    "    dates = pd.date_range(min_date, max_date, freq='D')\n",
    "    counts = pd.DataFrame({ \"count\": tweet_counts},index=dates).fillna(0)\n",
    "    counts = counts.resample('7D').sum()\n",
    "    return counts.drop(counts.tail(1).index) # drop last row in case its a count over less than the full time bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_BALANCE = 58\n",
    "N_TWEETS = 0\n",
    "\n",
    "BEARER_TOKEN=\"AAAAAAAAAAAAAAAAAAAAAAXT9gAAAAAAoITLBCf%2B2K7BMSqakqcbsHUSLrk%3DLz95o8CkkhjOTthpcyEEg6BdNav0zphRcrEYdeG4GXXV3Qkftk\"\n",
    "\n",
    "## value functions\n",
    "def expected_value(potential_win, chance_win, potential_loss, chance_loss):\n",
    "    return (potential_win * chance_win) - (potential_loss * chance_loss)\n",
    "\n",
    "def allocation(account_balance, expected_value):\n",
    "    pct_alloc = min(( expected_value * 5 ) / 10, .03)\n",
    "    alloc = account_balance * pct_alloc\n",
    "    #risk_coef = 1 - (1 / (proba * 100) )\n",
    "    #risk_adjusted = alloc * risk_coef\n",
    "    #return risk_adjusted\n",
    "    return alloc\n",
    "def allocation(price_per_share, proba):\n",
    "    payoff_odds = (1 / price_per_share) - 1\n",
    "\n",
    "def recommended_shares(account_balance, expected_value, price_per_share):\n",
    "    return allocation(account_balance, expected_value) / price_per_share;\n",
    "\n",
    "def to_proba(buckets, categories=None):\n",
    "    vals = buckets.value_counts()\n",
    "    # [ (range(0,2), \"0-2\"), range(3-5), \"3-5\" ]\n",
    "    #for c in categories:\n",
    "    #    rnge = c[0]\n",
    "    #    id_str = c[1]\n",
    "    #    for r in range:\n",
    "            \n",
    "    s = vals.sum()\n",
    "    return vals/s\n",
    "\n",
    "## portfolio management\n",
    "TAX_RATE = .1\n",
    "def kelly_criterion(outcomes):\n",
    "    # category, price_per_share, proba\n",
    "    er = []\n",
    "    betas = []\n",
    "    for index, o in outcomes.iterrows():\n",
    "        payoff_odds = (1 / o[\"price_per_share\"]) - 1\n",
    "        beta = 1 / (1 + payoff_odds)\n",
    "        dividend_rate = 1 - TAX_RATE\n",
    "        expected_revenue_rate = (dividend_rate / beta) * o[\"proba\"]\n",
    "        er.append(expected_revenue_rate)\n",
    "        betas.append(beta)\n",
    "        \n",
    "    outcomes[\"expected_revenue_rate\"] = er\n",
    "    outcomes[\"beta\"] = betas\n",
    "    outcomes = outcomes.sort_values(\"expected_revenue_rate\", ascending=False)\n",
    "    \n",
    "    reserve_rate = 1\n",
    "    optimal_set = pd.DataFrame()\n",
    "    for index, o in outcomes.iterrows():\n",
    "        if o[\"expected_revenue_rate\"] > reserve_rate:\n",
    "            optimal_set = optimal_set.append(o)\n",
    "            reserve_rate = (1 - optimal_set[\"proba\"].sum()) / (1 - (optimal_set[\"beta\"] / dividend_rate).sum())\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    pct_alloc = [] \n",
    "    for index, o in optimal_set.iterrows():\n",
    "        pct = (o[\"expected_revenue_rate\"] - reserve_rate) / ( dividend_rate / o[\"beta\"] )\n",
    "        pct_alloc.append(pct)\n",
    "    optimal_set[\"pct_alloc\"] = pct_alloc\n",
    "    return optimal_set\n",
    "\n",
    "def shares_bought(c, yes_or_no, positions):\n",
    "    bought = 0\n",
    "    if c in positions and yes_or_no in positions[c]:\n",
    "        for pos in positions[c][yes_or_no]:\n",
    "            bought += pos[1]\n",
    "    return bought\n",
    "\n",
    "def recommendation_buy(contract, yes_or_no, account_balance, expected_value, price_per_share, positions):\n",
    "    shares = recommended_shares(account_balance, expected_value, price_per_share) - shares_bought(contract, yes_or_no, positions)\n",
    "    shares = int(round(shares))\n",
    "    if shares > 0:\n",
    "        print(\"BUY {yn} shares for contract {n}: {shares} shares @{price} (EV: {ev}, TOTAL: {t})\".format(n=contract,shares=shares, price=price_per_share, ev=expected_value, yn=yes_or_no.upper(), t=shares*price_per_share))\n",
    "\n",
    "def recommendation_sell(contract, yes_or_no, expected_value, price_per_share, n_shares, bought_at):\n",
    "    print(\"SELL {yn} shares for contract {n}_{bought_at}_{n_shares}: ALL shares @{price} (EV: {ev}, TOTAL: {t})\".format(n=contract, price=price_per_share, ev=expected_value, yn=yes_or_no.upper(), t=n_shares*price_per_share, bought_at=bought_at, n_shares=n_shares))\n",
    "    \n",
    "## market evaluation\n",
    "def fetch_market_data(market_id):\n",
    "    url = \"https://www.predictit.org/api/marketdata/markets/{id}\".format(id=market_id)\n",
    "    r = requests.get(url=url)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_twitter_user_timeline(screen_name, max_id=None, since_id=None):\n",
    "    url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n",
    "    headers = { \"Authorization\": \"Bearer {t}\".format(t=BEARER_TOKEN)}\n",
    "    params = {\n",
    "        \"count\": \"200\",\n",
    "        \"trim_user\": \"true\",\n",
    "        \"screen_name\": screen_name\n",
    "    }\n",
    "    if max_id: \n",
    "        params[\"max_id\"] = max_id\n",
    "    if since_id:\n",
    "        params[\"since_id\"] = since_id\n",
    "        \n",
    "    r = requests.get(url=url,headers=headers, params=params)\n",
    "    raw = r.json()\n",
    "    transformed = json.dumps([ { \"id\": tweet[\"id\"], \"created_at\": tweet[\"created_at\"], \"text\": tweet[\"text\"] } for tweet in raw])\n",
    "    return pd.read_json(transformed, orient=\"records\")\n",
    "\n",
    "def get_recent_tweets(screen_name, from_date=None):\n",
    "    df = get_twitter_user_timeline(screen_name)\n",
    "    df[\"created_at\"] = df[\"created_at\"].dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "    if from_date:\n",
    "        df = df[df[\"created_at\"] > from_date]\n",
    "    return df\n",
    "    \n",
    "# the twitter api returns different results for the same request...\n",
    "def _get_twitter_history(screen_name, max_id=None):\n",
    "    get_next = True\n",
    "    df = pd.DataFrame(columns=[\"id\",\"created_at\", \"text\"])\n",
    "    while get_next:\n",
    "        tweets = get_twitter_user_timeline(screen_name, max_id)\n",
    "        print(len(tweets.index))\n",
    "        if len(tweets.index) > 0:\n",
    "            df = tweets if df.empty else pd.concat([df, tweets], axis=0)\n",
    "            last_row = tweets.tail(1).iloc[0]\n",
    "            max_id = last_row[\"id\"] - 1\n",
    "        else:\n",
    "            get_next = False\n",
    "    return df\n",
    "\n",
    "# the twitter api returns different results for the same request...\n",
    "def get_recent_twitter_history(screen_name, since_id):\n",
    "    get_next = True\n",
    "    df = pd.DataFrame(columns=[\"id\",\"created_at\", \"text\"])\n",
    "    while get_next:\n",
    "        tweets = get_twitter_user_timeline(screen_name, since_id=since_id)\n",
    "        print(len(tweets.index))\n",
    "        if len(tweets.index) > 0:\n",
    "            df = tweets if df.empty else pd.concat([df, tweets], axis=0)\n",
    "            most_recent = tweets.head(1).iloc[0] # TODO: prob should do better than this to ensure most recent\n",
    "            since_id = most_recent[\"id\"]\n",
    "        else:\n",
    "            get_next = False\n",
    "    return df\n",
    "\n",
    "# Gets all tweets before the earliest tweet stored locally for the given screen_name.\n",
    "# If we have nothing stored locally for the screen_name, gets all tweets.\n",
    "# NOTE: Twitter returns us most recent (n?) tweets, anything before that requires premium or enterprise account.\n",
    "def get_twitter_history(screen_name, cache=True):\n",
    "    fname = \"data/tweets/{sn}.csv\".format(sn=screen_name)\n",
    "    max_id = None\n",
    "    if cache and os.path.isfile(fname):\n",
    "        df = pd.read_csv(fname)\n",
    "        max_id = int(df.tail(1).iloc[0][\"id\"]) -1\n",
    "    df = _get_twitter_history(screen_name, max_id);\n",
    "    if not os.path.isdir(\"data/tweets\"):\n",
    "        os.mkdir(\"data/tweets\")\n",
    "    if len(df) > 0:\n",
    "        df.to_csv(fname, mode='a', index=False)\n",
    "\n",
    "# Gets all tweets after the latest tweet stored locally for the given screen_name.\n",
    "# If we have nothing stored locally for the screen_name, gets all tweets.\n",
    "def update_twitter_history(screen_name):\n",
    "    fname = \"data/tweets/{sn}.csv\".format(sn=screen_name)\n",
    "    if not os.path.isfile(fname):\n",
    "        get_twitter_history(screen_name)\n",
    "    else:\n",
    "        # get since_id (most recent entry)\n",
    "        # copy to .bak file\n",
    "        # get most recent tweets starting at since_id\n",
    "        # save df to file\n",
    "        # copy old .bak to file\n",
    "        copyfile(fname, fname + '.bak')\n",
    "        \n",
    "        df = pd.read_csv(fname)\n",
    "        since_id = int(df.head(1).iloc[0][\"id\"])\n",
    "                \n",
    "        recent_tweets = get_recent_twitter_history(screen_name, since_id)\n",
    "        if len(recent_tweets) > 0:\n",
    "            recent_tweets.to_csv(fname, mode='w', index=False)\n",
    "            historical_tweets = pd.read_csv(fname + '.bak')\n",
    "            historical_tweets.to_csv(fname, mode='a', index=False)\n",
    "\n",
    "def fetch_full_trump_tweet_history(rnge, cache=True):\n",
    "    fname = \"data/tweets/@realDonaldTrump.csv\"\n",
    "    df = None\n",
    "    for year in rnge:\n",
    "        url = None\n",
    "        if year == 2019:\n",
    "            url = \"http://www.trumptwitterarchive.com/data/realdonaldtrump/2019.json\"\n",
    "        else:\n",
    "            url = \"http://d5nxcu7vtzvay.cloudfront.net/data/realdonaldtrump/{y}.json\".format(y=str(year))\n",
    "        _df  = pd.read_json(url)\n",
    "        if df is None:\n",
    "            df = _df\n",
    "        else:\n",
    "            df = pd.concat([df,_df])\n",
    "        time.sleep(1)\n",
    "     \n",
    "    if not os.path.isdir(\"data/tweets\"):\n",
    "        os.mkdir(\"data/tweets\")\n",
    "    if len(df) > 0:\n",
    "        df.to_csv(fname, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\"homieng6@gmail.com\"\n",
    "#\"??\"\n",
    "#\"@homiesaccount\"\n",
    "#\"nY7VUVqcxJ4vmcX\"\n",
    "#\"AAAAAAAAAAAAAAAAAAAAAAXT9gAAAAAAoITLBCf%2B2K7BMSqakqcbsHUSLrk%3DLz95o8CkkhjOTthpcyEEg6BdNav0zphRcrEYdeG4GXXV3Qkft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweet_distributions_per_day(source_df):\n",
    "    df = pd.DataFrame(columns=[\"proba\",\"day\"])\n",
    "    df.index.name = \"n_tweets\"\n",
    "    for x in range(0,7,1):\n",
    "        weekday = calendar.day_name[x]\n",
    "        b = bucketed(source_df, start_on=weekday)\n",
    "        proba = b['count']/b['count'].sum()\n",
    "        _df = pd.DataFrame({ \"proba\": proba.values, \"day\": x }, index=proba.index)\n",
    "        df = pd.concat([df, _df])\n",
    "        df[\"n_tweets\"] = df.index\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for key, _grp in df.groupby(['n_tweets']):\n",
    "        grp = _grp.sort_values(by=\"day\", ascending=False)\n",
    "        ax = grp.plot(ax=ax, kind='line', x=\"day\", y='proba', label=str(grp[\"n_tweets\"].iloc[0]))\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "#_df = pd.read_csv('./data/fake_news_tweets.csv')\n",
    "#plot_tweet_distributions_per_day(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_twitter_market_research(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # number of tweets per week\n",
    "    b=bucketed(df)\n",
    "    b.plot(title=\"Tweets per Week\")\n",
    "    plt.show()\n",
    "    \n",
    "    # distribution of tweets per week\n",
    "    vals = b[\"count\"].value_counts()\n",
    "    bins = vals.size\n",
    "    b[\"count\"].plot(kind=\"hist\",bins=bins, title=\"Tweets per Week Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "    # freq of tweets per day\n",
    "    df['day_of_week'] = pd.to_datetime(df[\"created_at\"]).dt.tz_localize('UTC').dt.tz_convert('US/Eastern').dt.day_name()\n",
    "    \n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    df['day_of_week'].value_counts().reindex(weekdays).plot(kind='bar', title=\"Tweets per Calendar Day\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_range_str(range):\n",
    "    return str(range.start) + \"-\" + str(range.stop-1)\n",
    "\n",
    "def append_count(series, count, category_range):\n",
    "    return series.append(pd.Series([ count ], index=[ to_range_str(category_range) ]))\n",
    "\n",
    "# takes dataframe with tweet counts bucketed per n days\n",
    "# returns a data frame that returns counts for a category based, excluding coun\n",
    "# this answers: what is the probability that we end in a category, given that we have already seen curr_n values\n",
    "def count_adjusted(df, categories, curr_n):\n",
    "    grouped = pd.Series()\n",
    "    for rnge in categories:\n",
    "        adjusted_range = range(max(rnge.start-curr_n, 0), max(rnge.stop-curr_n, 0 ))\n",
    "        count = df[df[\"count\"].between(adjusted_range.start, adjusted_range.stop-1)].shape[0]\n",
    "        grouped = append_count(grouped, count, rnge)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_start_date(end_date_str):\n",
    "    end_date = parser.parse(end_date_str)\n",
    "    return end_date - datetime.timedelta(days=7)\n",
    "\n",
    "def time_boundaries(market_data, tz):\n",
    "    contracts = market_data[\"contracts\"]\n",
    "    end_date_str = contracts[0][\"dateEnd\"]\n",
    "    end_date = parser.parse(end_date_str)\n",
    "    start_date = end_date - datetime.timedelta(days=7)\n",
    "    return ( tz.localize(start_date), tz.localize(end_date) )\n",
    "    \n",
    "def eval_live_twitter_market(market, path, matching_tweets=None, show_market_research=False, dry_run=True):\n",
    "    if show_market_research:\n",
    "        show_twitter_market_research(path)\n",
    "        \n",
    "    market_data = fetch_market_data(market[\"id\"])\n",
    "    timezone = pytz.timezone(\"US/Eastern\")\n",
    "    utc_now = pytz.utc.localize(datetime.datetime.utcnow())\n",
    "    ts = utc_now.astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "    start_date, end_date = time_boundaries(market_data, timezone)\n",
    "    \n",
    "    matching_tweets = get_recent_tweets(market[\"twitter_handle\"], from_date=start_date)\n",
    "    if ( \"filter\" in market.keys() ):\n",
    "        matching_tweets = matching_tweets[matching_tweets[\"text\"].str.contains(market[\"filter\"],case=False)]\n",
    "        #n_matching_tweets = len(matching_tweets[matching_tweets[\"text\"].str.contains(\"fake news|fakenews\",case=False)])\n",
    "    n_matching_tweets = len(matching_tweets)\n",
    "    eval_twitter_market(market, path, data=market_data, ts=ts, n_matching_tweets=n_matching_tweets, dry_run=dry_run)\n",
    "\n",
    "def eval_twitter_market(market, path, data=None, ts=None, n_matching_tweets=None, show_market_research=False, dry_run=True):\n",
    "    if show_market_research:\n",
    "        show_twitter_market_research(path)\n",
    "        \n",
    "    if data is None:\n",
    "        data = fetch_market_data(market[\"id\"])\n",
    "    \n",
    "    data[\"timezone\"] = pytz.timezone(\"US/Eastern\") # timeStamp field in market data seems to be in US/Eastern \n",
    "    contracts = data[\"contracts\"]\n",
    "    for c in contracts:\n",
    "        c_id = str(c[\"id\"])\n",
    "        annotations = market[\"contract_map\"][c_id]\n",
    "        c[\"range\"] = annotations[\"range\"]\n",
    "        c[\"category\"] = to_range_str(c[\"range\"])\n",
    "    print(data[\"shortName\"])\n",
    "    \n",
    "    start_date, end_date = time_boundaries(data, data[\"timezone\"])\n",
    "    n_days = days_left(end_date, ts) # days left too complicated, can just do end_date - ts\n",
    "    print(\"Days left:\", n_days)\n",
    "    print(\"Matching tweets:\", n_matching_tweets)\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df['day_of_week'] = pd.to_datetime(df[\"created_at\"]).dt.tz_localize('UTC').dt.tz_convert('US/Eastern').dt.day_name()\n",
    "    weekdays = calendar.day_name\n",
    "    circular_weekdays = np.tile(weekdays, 2)\n",
    "    idx = np.where(circular_weekdays == ts.strftime(\"%A\"))[0][0]\n",
    "    weekdays_left = circular_weekdays[idx:idx+n_days]\n",
    "    \n",
    "    df = df[df[\"day_of_week\"].isin(weekdays_left)]   \n",
    "    b=bucketed(df, start_on=weekdays[idx])\n",
    "    c=count_adjusted(b, [c[\"range\"] for c in contracts], n_matching_tweets )\n",
    "    proba = c/c.sum()\n",
    "    print(\"Category probabilities:\")\n",
    "    pprint.pprint(proba)\n",
    "    \n",
    "    category_stats = pd.DataFrame({ \"price_per_share\": [], \"proba\": [] })\n",
    "    for c in contracts:\n",
    "        s = pd.Series({ \"price_per_share\": c[\"bestBuyYesCost\"], \"proba\": proba[c[\"category\"]] })\n",
    "        s.name = c[\"category\"]\n",
    "        category_stats = category_stats.append(s)\n",
    "    alloc = kelly_criterion(category_stats)\n",
    "    print(alloc)\n",
    "    place_orders(market[\"id\"], contracts, alloc, ACCOUNT_BALANCE * .1, dry_run=dry_run)\n",
    "    \n",
    "    #outcomes(positions, [c[\"category\"] for c in contracts])\n",
    "\n",
    "def days_left(end_date, ts):\n",
    "    start_date = end_date - datetime.timedelta(days=7)\n",
    "    delta = ts - start_date\n",
    "    days_left = ((7*24) - (delta.total_seconds()/3600))/24\n",
    "    return max(round(days_left),1)\n",
    "                    \n",
    "def outcomes(positions, categories):\n",
    "    for c in categories:\n",
    "        total = 0\n",
    "        for pp in positions:\n",
    "            if pp == c:\n",
    "                if \"yes\" in positions[pp]:\n",
    "                    for x in positions[pp][\"yes\"]:\n",
    "                        total += (1 - x[0])*x[1]\n",
    "                if \"no\" in positions[pp]:\n",
    "                    for x in positions[pp][\"no\"]:\n",
    "                        total -= x[0]*x[1]\n",
    "            else:\n",
    "                if \"yes\" in positions[pp]:\n",
    "                    for x in positions[pp][\"yes\"]:\n",
    "                        total -= x[0]*x[1]\n",
    "                if \"no\" in positions[pp]:\n",
    "                    for x in positions[pp][\"no\"]:\n",
    "                        total += (1-x[0])*x[1]\n",
    "        print(c, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale EV by risk for final quantity recommendations (to reduce volatility)\n",
    "# take expected tweets for day of week into account given some people dont tweet much on weekends\n",
    "# graph of tweet density per time per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "markets = [\n",
    "    { \n",
    "        \"id\": 5457, \n",
    "        \"twitter_handle\": \"@vp\", \n",
    "        \"contract_map\": {\n",
    "            \"15263\": { \"range\": range(0, 20) }, \n",
    "            \"15267\": { \"range\": range(20, 25) }, \n",
    "            \"15266\": { \"range\": range(25, 30) }, \n",
    "            \"15268\": { \"range\": range(30, 35) },\n",
    "            \"15264\": { \"range\": range(35, 40) },\n",
    "            \"15269\": { \"range\": range(40, 45) },\n",
    "            \"15265\": { \"range\": range(45, 100) }\n",
    "        },\n",
    "        \"positions\":{ \n",
    "        }\n",
    "    },\n",
    "    { \n",
    "        \"id\": 5407, \n",
    "        \"twitter_handle\": \"@whitehouse\", \n",
    "        \"contract_map\": {\n",
    "            \"14983\": { \"range\": range(0, 80) }, \n",
    "            \"14985\": { \"range\": range(80, 85) }, \n",
    "            \"14984\": { \"range\": range(85, 90) },\n",
    "            \"14986\": { \"range\": range(90, 95) },\n",
    "            \"14987\": { \"range\": range(95, 100) },\n",
    "            \"14988\": { \"range\": range(100, 105) }, \n",
    "            \"14989\": { \"range\": range(105, 300) }\n",
    "        },\n",
    "        #\"contract_map\": [ (\"14983\", range(0, 80)), (\"14985\",range(80, 85)), (\"14984\", range(85, 90)), (\"14986\", range(90, 95)), (\"14987\",range(95, 100)), (\"14988\", range(100, 105)), (\"14989\",range(105, 300))],\n",
    "        \"positions\": { \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5404, \n",
    "        \"twitter_handle\": \"@realDonaldTrump\",\n",
    "        \"contract_map\": {\n",
    "            \"14968\": { \"range\": range(0, 60) }, \n",
    "            \"14963\": { \"range\": range(60, 65) }, \n",
    "            \"14967\": { \"range\": range(65, 70) },\n",
    "            \"14965\": { \"range\": range(70, 75) },\n",
    "            \"14964\": { \"range\": range(75, 80) },\n",
    "            \"14966\": { \"range\": range(80, 85) }, \n",
    "            \"14962\": { \"range\": range(85, 200) }\n",
    "        },\n",
    "        #\"contract_map\": [ (\"14968\", range(0, 60)), (\"14963\",range(60, 65)), (\"14967\", range(65, 70)), (\"14965\", range(70, 75)), (\"14964\",range(75, 80)), (\"14966\", range(80, 85)), (\"14962\",range(85, 200))],\n",
    "        \"positions\": {\n",
    "            #\"0-59\": {\n",
    "            #    \"yes\": [(.12, 11)]\n",
    "            #},\n",
    "            #\"60-64\": {\n",
    "            #    \"yes\": [(.11, 12)]\n",
    "            #},\n",
    "            #\"70-74\": {\n",
    "            #    \"yes\": [(.04, 20)]\n",
    "            #},\n",
    "            #\"80-84\": {\n",
    "            #    \"no\": [(.69, 4)]\n",
    "            #},\n",
    "            #\"85-199\": {\n",
    "            #    \"no\": [(.74, 4),(.64,1),(.54,1), (.34, 3)]\n",
    "            #}\n",
    "        }\n",
    "    },\n",
    "    { \n",
    "        \"id\": 5458, \n",
    "        \"twitter_handle\": \"@potus\", \n",
    "        \"contract_map\": {\n",
    "            \"15270\": { \"range\": range(0, 45) }, \n",
    "            \"15274\": { \"range\": range(45, 50) },\n",
    "            \"15275\": { \"range\": range(50, 55) },\n",
    "            \"15271\": { \"range\": range(55, 60) }, \n",
    "            \"15272\": { \"range\": range(60, 65) }, \n",
    "            \"15273\": { \"range\": range(65, 69) },\n",
    "            \"15276\": { \"range\": range(70, 200) }\n",
    "        },\n",
    "        \"positions\": {\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def eval_live_markets(show_market_research=False, dry_run=True):\n",
    "    for market in markets:\n",
    "        eval_live_twitter_market(\n",
    "            market,\n",
    "            \"data/tweets/{handle}.csv\".format(handle=market[\"twitter_handle\"]),\n",
    "            show_market_research=show_market_research,\n",
    "            dry_run=dry_run\n",
    "        )\n",
    "        print(\"----------------------------------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct = .005\n",
    "# 2 pct = .01\n",
    "# 4 pct = .02\n",
    "# 8 pct = .03\n",
    "def alloc(expected_value, proba): \n",
    "    pct_alloc = min( expected_value / 2, .03)\n",
    "    risk_adjusted = pct_alloc# * ??\n",
    "    return risk_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_orders(market_id, contracts, optimal_set, account_balance, dry_run=True):\n",
    "    for contract in contracts:\n",
    "        category = contract[\"category\"]\n",
    "        price_per_share = contract[\"bestBuyYesCost\"]\n",
    "        current_quantity = current_alloc(market_id, contract[\"id\"])\n",
    "        \n",
    "        if category not in optimal_set.index:\n",
    "            # TODO: this doesnt take into consideration sell price, which in this market is usually less than buy price\n",
    "            # could sell at best buy price...\n",
    "            if current_quantity > 0:\n",
    "                place_order({\n",
    "                    \"action\": \"sell\",\n",
    "                    \"category\": category,\n",
    "                    \"type\": \"yes\", \n",
    "                    \"price_per_share\": price_per_share,\n",
    "                    \"quantity\": current_quantity,\n",
    "                    #\"ev\": \"unknown\",\n",
    "                    \"market_id\": market_id,\n",
    "                    \"contract_id\": contract[\"id\"]\n",
    "                }, dry_run=dry_run)\n",
    "        else:\n",
    "            row = optimal_set.loc[category,:]\n",
    "            optimal_alloc = (row[\"pct_alloc\"] * account_balance)\n",
    "            optimal_quantity = round( abs(optimal_alloc / price_per_share) )\n",
    "            quantity = optimal_quantity - current_quantity\n",
    "\n",
    "            if quantity > 0:\n",
    "                place_order({\n",
    "                    \"action\": \"buy\", \n",
    "                    \"category\": category,\n",
    "                    \"type\": \"yes\", \n",
    "                    \"price_per_share\": price_per_share,\n",
    "                    \"quantity\": quantity,\n",
    "                    #\"ev\": row[\"proba\"] - row[\"price_per_share\"],\n",
    "                    \"market_id\": market_id,\n",
    "                    \"contract_id\": contract[\"id\"]\n",
    "                }, dry_run=dry_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = psycopg2.connect(database=\"predictit\", host=\"localhost\", port=\"5432\")\n",
    "#conn = create_engine(\"postgresql+psycopg2://@localhost:5432/predictit\"\n",
    "db_string = \"postgresql+psycopg2://@localhost:5432/predictit\"\n",
    "def current_alloc(market_id, contract_id):\n",
    "    contract_orders = psql.read_sql(\"SELECT * from orders WHERE market_id = \\'{m_id}\\' AND contract_id = \\'{c_id}\\'\".format(m_id=market_id, c_id=contract_id), db_string)\n",
    "\n",
    "    quantity = 0\n",
    "    for i,o in contract_orders.iterrows():\n",
    "        multiplier = -1 if o[\"action\"] == \"sell\" else 1\n",
    "        quantity += o[\"quantity\"] * multiplier\n",
    "    return quantity\n",
    "\n",
    "def place_order(order, verbose=True, dry_run=True):\n",
    "    df = pd.Series(order).to_frame().transpose()\n",
    "    print(df)\n",
    "    if not dry_run:\n",
    "        df.to_sql('orders', con=db_string, if_exists='append', index=False)\n",
    "    if verbose:\n",
    "        print(order)\n",
    "        \n",
    "def record_timepoint(market_id=5458):\n",
    "    data = fetch_market_data(market_id)\n",
    "    twitter_handle = re.match(r\".*@(\\w{1,15})\",data[\"shortName\"]).group(0).split(' ')[-1]\n",
    "    df = pd.Series({ \"timestamp\": data[\"timeStamp\"], \"market_id\": data[\"id\"], \"handle\": twitter_handle, \"data\": json.dumps(data) }).to_frame().transpose()\n",
    "    df.to_sql('market_data', con=db_string, if_exists='append', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>expected_revenue_rate</th>\n",
       "      <th>price_per_share</th>\n",
       "      <th>proba</th>\n",
       "      <th>pct_alloc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beta  expected_revenue_rate  price_per_share  proba  pct_alloc\n",
       "1   0.1                   2.70              0.1    0.3        0.4\n",
       "2   0.2                   1.35              0.2    0.3        0.5\n",
       "3   0.4                   1.35              0.4    0.6        1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bought_at: .10\n",
    "# EV: .70\n",
    "# price: .75\n",
    "# SELL (not in optimal set)\n",
    "\n",
    "# bought_at: .10\n",
    "# EV: .70\n",
    "# price: .50\n",
    "# BUY (but would have more shares than recommended)\n",
    "\n",
    "# bought_at: .10 \n",
    "# EV: .70\n",
    "# price: .05\n",
    "# BUY (difference over current alloc)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: .70\n",
    "# price: .75\n",
    "# SELL (not in optimal set)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: .70\n",
    "# price: .50\n",
    "# BUY (likely allocation is less than what you have, in which case you sell)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: -.10\n",
    "# price: .50\n",
    "#\n",
    "\n",
    "market = { \n",
    "    \"id\": 5411, \n",
    "    \"twitter_handle\": \"@potus\", \n",
    "    \"contract_map\": [ (\"15008\", range(0, 35)), (\"15010\",range(35, 40)), (\"15011\", range(40, 45)), (\"15012\", range(45, 50)), (\"15013\",range(50, 55)), (\"15009\", range(55, 60)), (\"15014\",range(60, 200))]\n",
    "}\n",
    "df = pd.DataFrame({ \"price_per_share\": [.2, .51, .40, .01, .10], \"proba\": [.30, .10, .60, .02, .7] }, index=[\"0-59\", \"60-64\", \"65-69\", \"70-71\", \"test\"])\n",
    "df = pd.DataFrame({ \"price_per_share\": [.10, .2, .40], \"proba\": [.3, .30, .60] }, index=[\"1\", \"2\", \"3\"])\n",
    "alloc = kelly_criterion(df)\n",
    "alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@vp tweets noon 4/26 - noon 5/3?\n",
      "Days left: 1\n",
      "Matching tweets: 66\n",
      "Category probabilities:\n",
      "45-99    1.0\n",
      "0-19     0.0\n",
      "35-39    0.0\n",
      "25-29    0.0\n",
      "20-24    0.0\n",
      "30-34    0.0\n",
      "40-44    0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@whitehouse tweets 4/4 - 4/11?\n",
      "Days left: 1\n",
      "Matching tweets: 200\n",
      "Category probabilities:\n",
      "105-299    1.0\n",
      "0-79       0.0\n",
      "85-89      0.0\n",
      "80-84      0.0\n",
      "90-94      0.0\n",
      "95-99      0.0\n",
      "100-104    0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@realDonaldTrump tweets 4/3 - 4/10?\n",
      "Days left: 1\n",
      "Matching tweets: 198\n",
      "Category probabilities:\n",
      "85-199    1.0\n",
      "60-64     0.0\n",
      "75-79     0.0\n",
      "70-74     0.0\n",
      "80-84     0.0\n",
      "65-69     0.0\n",
      "0-59      0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@potus tweets noon 4/26 - noon 5/3?\n",
      "Days left: 1\n",
      "Matching tweets: 80\n",
      "Category probabilities:\n",
      "55-59     0.0\n",
      "0-44      0.0\n",
      "60-64     0.0\n",
      "65-68     0.0\n",
      "45-49     0.0\n",
      "50-54     0.0\n",
      "70-199    1.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_live_markets(show_market_research=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_market(market):\n",
    "    historical_data = psql.read_sql(\"SELECT * from market_data WHERE handle = \\'{handle}\\'\".format(handle=market[\"twitter_handle\"]), db_string)\n",
    "    path = \"data/tweets/{handle}.csv\".format(handle=market[\"twitter_handle\"])\n",
    "    for i, data_point in historical_data.iterrows():\n",
    "        timezone = pytz.timezone(\"US/Eastern\")\n",
    "        ts = timezone.localize( parser.parse(data_point[\"timestamp\"]) )\n",
    "        market_data = json.loads(data_point[\"data\"])\n",
    "        start_date, end_date = time_boundaries(market_data, timezone)\n",
    "        \n",
    "        df = get_historical_twitter_data(path)\n",
    "        \n",
    "        if df[df[\"created_at\"] > ts].empty():\n",
    "            print('Updating twitter history for {handle}...'.format(handle=market[\"twitter_handle\"]))\n",
    "            update_twitter_history(market[\"twitter_handle\"])\n",
    "            df = get_historical_twitter_data(path)\n",
    "\n",
    "        print(ts, start_date, end_date)\n",
    "        return df[(df[\"created_at\"] >= start_date) & (df[\"created_at\"] <= ts)]\n",
    "        eval_twitter_market(market, path, data=market_data, ts=ts, show_market_research=False)\n",
    "\n",
    "def get_historical_twitter_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "    df[\"created_at\"] = df[\"created_at\"].dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "    return df\n",
    "\n",
    "def simulate_markets():\n",
    "    for m in markets:\n",
    "        simulate_market(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-03 14:07:47.444884-04:00 2019-05-03 12:00:00-04:00 2019-05-10 12:00:00-04:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, created_at, id, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_market(markets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-03 17:24:58</td>\n",
       "      <td>1124364235360882689</td>\n",
       "      <td>RT @realDonaldTrump: ....We discussed Trade, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-03 17:24:52</td>\n",
       "      <td>1124364212749336576</td>\n",
       "      <td>RT @realDonaldTrump: Had a long and very good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-05-03 16:23:36</td>\n",
       "      <td>1124348791765774340</td>\n",
       "      <td>RT @realDonaldTrump: We can all agree that AME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-03 16:23:30</td>\n",
       "      <td>1124348769787625472</td>\n",
       "      <td>RT @realDonaldTrump: “The U.S. Created 263,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-03 13:51:26</td>\n",
       "      <td>1124310501104680961</td>\n",
       "      <td>RT @realDonaldTrump: Finally, Mainstream Media...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-05-03 13:42:36</td>\n",
       "      <td>1124308278886973445</td>\n",
       "      <td>RT @WhiteHouse: It's another historic Jobs Day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-05-03 13:42:35</td>\n",
       "      <td>1124308272196927490</td>\n",
       "      <td>RT @realDonaldTrump: JOBS, JOBS, JOBS!\\n\\n“Job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2019-05-03 00:12:27</td>\n",
       "      <td>1124104394788823041</td>\n",
       "      <td>RT @realDonaldTrump: Proclamation on Days of R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-05-02 23:52:27</td>\n",
       "      <td>1124099364354445317</td>\n",
       "      <td>RT @realDonaldTrump: On this day of prayer, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2019-05-02 17:02:56</td>\n",
       "      <td>1123996306115059713</td>\n",
       "      <td>RT @realDonaldTrump: ....and deregulation whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-05-02 17:02:53</td>\n",
       "      <td>1123996292445765639</td>\n",
       "      <td>RT @realDonaldTrump: Steve Moore, a great pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2019-05-02 15:10:40</td>\n",
       "      <td>1123968053107208192</td>\n",
       "      <td>RT @WhiteHouse: LIVE: President Trump and The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2019-05-02 03:05:48</td>\n",
       "      <td>1123785634961874949</td>\n",
       "      <td>RT @realDonaldTrump: I am continuing to monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2019-05-02 02:05:29</td>\n",
       "      <td>1123770455012278273</td>\n",
       "      <td>RT @WhiteHouse: \"So tonight we praise God for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2019-05-02 02:05:27</td>\n",
       "      <td>1123770444576903169</td>\n",
       "      <td>RT @WhiteHouse: \"During this holy season when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2019-05-02 02:05:24</td>\n",
       "      <td>1123770434720235520</td>\n",
       "      <td>RT @WhiteHouse: \"Tonight we break bread togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2019-05-02 02:00:27</td>\n",
       "      <td>1123769187661426690</td>\n",
       "      <td>RT @realDonaldTrump: https://t.co/S34Q0NY6Ju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2019-05-02 01:55:56</td>\n",
       "      <td>1123768049960652800</td>\n",
       "      <td>RT @FLOTUS: It was an honor to host so many wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2019-05-01 13:06:00</td>\n",
       "      <td>1123574292002803713</td>\n",
       "      <td>RT @realDonaldTrump: Congress must change the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2019-05-01 13:05:53</td>\n",
       "      <td>1123574259815677953</td>\n",
       "      <td>RT @realDonaldTrump: “No President in history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2019-05-01 13:05:45</td>\n",
       "      <td>1123574225510567937</td>\n",
       "      <td>RT @realDonaldTrump: Gallup Poll: 56% of Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2019-05-01 13:05:38</td>\n",
       "      <td>1123574199166144517</td>\n",
       "      <td>RT @realDonaldTrump: I am overriding the Decom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2019-05-01 13:05:31</td>\n",
       "      <td>1123574168472170496</td>\n",
       "      <td>RT @realDonaldTrump: “The Democrats can’t come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2019-05-01 02:29:16</td>\n",
       "      <td>1123414050858315779</td>\n",
       "      <td>RT @WhiteHouse: To all the patriotic citizens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2019-04-30 23:45:22</td>\n",
       "      <td>1123372805591052289</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2019-04-30 23:45:21</td>\n",
       "      <td>1123372798406213638</td>\n",
       "      <td>RT @WhiteHouse: “NASCAR is not only a thrillin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2019-04-30 23:45:15</td>\n",
       "      <td>1123372776851742720</td>\n",
       "      <td>RT @WhiteHouse: President @realDonaldTrump hos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2019-04-30 21:10:14</td>\n",
       "      <td>1123333763004620801</td>\n",
       "      <td>RT @realDonaldTrump: ....embargo, together wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2019-04-30 21:10:12</td>\n",
       "      <td>1123333757094846465</td>\n",
       "      <td>RT @realDonaldTrump: If Cuban Troops and Milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2019-04-30 20:52:06</td>\n",
       "      <td>1123329199144677377</td>\n",
       "      <td>RT @WhiteHouse: National Security Advisor @Amb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>181</td>\n",
       "      <td>2018-05-03 21:21:25</td>\n",
       "      <td>992152172568641536</td>\n",
       "      <td>RT @WhiteHouse: .@SBALinda: @SBAgov Boosts Wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>182</td>\n",
       "      <td>2018-05-03 21:21:22</td>\n",
       "      <td>992152158647840770</td>\n",
       "      <td>RT @WhiteHouse: President Trump has made it cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>183</td>\n",
       "      <td>2018-05-03 18:22:34</td>\n",
       "      <td>992107161605033984</td>\n",
       "      <td>RT @realDonaldTrump: #NationalDayOfPrayer http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>184</td>\n",
       "      <td>2018-05-03 16:56:28</td>\n",
       "      <td>992085493574782976</td>\n",
       "      <td>RT @WhiteHouse: \"The Faith Initiative will hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>185</td>\n",
       "      <td>2018-05-03 16:56:25</td>\n",
       "      <td>992085481146994688</td>\n",
       "      <td>RT @WhiteHouse: \"Faith has shaped our families...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>186</td>\n",
       "      <td>2018-05-03 16:56:22</td>\n",
       "      <td>992085469876846593</td>\n",
       "      <td>RT @WhiteHouse: \"Rev. Graham’s words remind us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>187</td>\n",
       "      <td>2018-05-03 16:27:42</td>\n",
       "      <td>992078253706874880</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>188</td>\n",
       "      <td>2018-05-03 15:50:35</td>\n",
       "      <td>992068915210653696</td>\n",
       "      <td>RT @WhiteHouse: Today, President Trump signed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-05-03 15:29:35</td>\n",
       "      <td>992063630580633600</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>190</td>\n",
       "      <td>2018-05-03 13:56:32</td>\n",
       "      <td>992040211256430593</td>\n",
       "      <td>RT @WhiteHouse: President Donald J. Trump proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>191</td>\n",
       "      <td>2018-05-02 22:42:00</td>\n",
       "      <td>991810062510379008</td>\n",
       "      <td>RT @WhiteHouse: Gina Haspel has developed outs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>192</td>\n",
       "      <td>2018-05-02 20:39:20</td>\n",
       "      <td>991779192730800135</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>193</td>\n",
       "      <td>2018-05-02 20:31:30</td>\n",
       "      <td>991777222380916736</td>\n",
       "      <td>RT @realDonaldTrump: I have been briefed on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>194</td>\n",
       "      <td>2018-05-02 20:16:42</td>\n",
       "      <td>991773496828203013</td>\n",
       "      <td>RT @WhiteHouse: Gina Haspel has displayed dedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>195</td>\n",
       "      <td>2018-05-02 18:17:05</td>\n",
       "      <td>991743395272982528</td>\n",
       "      <td>RT @realDonaldTrump: Congratulations @SecPompe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>196</td>\n",
       "      <td>2018-05-02 16:45:49</td>\n",
       "      <td>991720426278711296</td>\n",
       "      <td>RT @WhiteHouse: The Wall Street Journal: From ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>197</td>\n",
       "      <td>2018-05-02 16:08:20</td>\n",
       "      <td>991710994480226305</td>\n",
       "      <td>RT @WhiteHouse: \"For nearly 230 years, the men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>198</td>\n",
       "      <td>2018-05-02 15:48:57</td>\n",
       "      <td>991706115313491973</td>\n",
       "      <td>RT @WhiteHouse: A number of public officials h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>199</td>\n",
       "      <td>2018-05-02 15:17:48</td>\n",
       "      <td>991698274347347968</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-02 14:47:07</td>\n",
       "      <td>991690554932187136</td>\n",
       "      <td>RT @WhiteHouse: Today President Trump and Vice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-02 13:55:13</td>\n",
       "      <td>991677493659799552</td>\n",
       "      <td>RT @WhiteHouse: What They Are Saying: Widespre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-01 19:44:47</td>\n",
       "      <td>991403078401347584</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-05-01 18:14:56</td>\n",
       "      <td>991380465067098113</td>\n",
       "      <td>RT @realDonaldTrump: Congratulations @ArmyWP_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-01 16:59:25</td>\n",
       "      <td>991361461812416513</td>\n",
       "      <td>RT @realDonaldTrump: Today I had the great hon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-05-01 16:03:26</td>\n",
       "      <td>991347372033740800</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-05-01 15:24:07</td>\n",
       "      <td>991337476177453058</td>\n",
       "      <td>RT @realDonaldTrump: Yesterday, it was my grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-04-29 04:37:12</td>\n",
       "      <td>990449901812281344</td>\n",
       "      <td>RT @WhiteHouse: Loopholes in our immigration s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-04-29 04:35:42</td>\n",
       "      <td>990449522492018688</td>\n",
       "      <td>RT @sarasotapd: We might be biased but our Off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-04-29 01:18:20</td>\n",
       "      <td>990399855699865601</td>\n",
       "      <td>RT @WhiteHouse: Now nearly a decade and a half...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>10</td>\n",
       "      <td>2018-04-29 01:17:42</td>\n",
       "      <td>990399692524670976</td>\n",
       "      <td>RT @realDonaldTrump: Secret Service has just i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3211 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           created_at                   id  \\\n",
       "0              0  2019-05-03 17:24:58  1124364235360882689   \n",
       "1              1  2019-05-03 17:24:52  1124364212749336576   \n",
       "2              2  2019-05-03 16:23:36  1124348791765774340   \n",
       "3              3  2019-05-03 16:23:30  1124348769787625472   \n",
       "4              4  2019-05-03 13:51:26  1124310501104680961   \n",
       "5              5  2019-05-03 13:42:36  1124308278886973445   \n",
       "6              6  2019-05-03 13:42:35  1124308272196927490   \n",
       "7              7  2019-05-03 00:12:27  1124104394788823041   \n",
       "8              8  2019-05-02 23:52:27  1124099364354445317   \n",
       "9              9  2019-05-02 17:02:56  1123996306115059713   \n",
       "10            10  2019-05-02 17:02:53  1123996292445765639   \n",
       "11            11  2019-05-02 15:10:40  1123968053107208192   \n",
       "12            12  2019-05-02 03:05:48  1123785634961874949   \n",
       "13            13  2019-05-02 02:05:29  1123770455012278273   \n",
       "14            14  2019-05-02 02:05:27  1123770444576903169   \n",
       "15            15  2019-05-02 02:05:24  1123770434720235520   \n",
       "16            16  2019-05-02 02:00:27  1123769187661426690   \n",
       "17            17  2019-05-02 01:55:56  1123768049960652800   \n",
       "18            18  2019-05-01 13:06:00  1123574292002803713   \n",
       "19            19  2019-05-01 13:05:53  1123574259815677953   \n",
       "20            20  2019-05-01 13:05:45  1123574225510567937   \n",
       "21            21  2019-05-01 13:05:38  1123574199166144517   \n",
       "22            22  2019-05-01 13:05:31  1123574168472170496   \n",
       "23            23  2019-05-01 02:29:16  1123414050858315779   \n",
       "24            24  2019-04-30 23:45:22  1123372805591052289   \n",
       "25            25  2019-04-30 23:45:21  1123372798406213638   \n",
       "26            26  2019-04-30 23:45:15  1123372776851742720   \n",
       "27            27  2019-04-30 21:10:14  1123333763004620801   \n",
       "28            28  2019-04-30 21:10:12  1123333757094846465   \n",
       "29            29  2019-04-30 20:52:06  1123329199144677377   \n",
       "...          ...                  ...                  ...   \n",
       "3181         181  2018-05-03 21:21:25   992152172568641536   \n",
       "3182         182  2018-05-03 21:21:22   992152158647840770   \n",
       "3183         183  2018-05-03 18:22:34   992107161605033984   \n",
       "3184         184  2018-05-03 16:56:28   992085493574782976   \n",
       "3185         185  2018-05-03 16:56:25   992085481146994688   \n",
       "3186         186  2018-05-03 16:56:22   992085469876846593   \n",
       "3187         187  2018-05-03 16:27:42   992078253706874880   \n",
       "3188         188  2018-05-03 15:50:35   992068915210653696   \n",
       "3189         189  2018-05-03 15:29:35   992063630580633600   \n",
       "3190         190  2018-05-03 13:56:32   992040211256430593   \n",
       "3191         191  2018-05-02 22:42:00   991810062510379008   \n",
       "3192         192  2018-05-02 20:39:20   991779192730800135   \n",
       "3193         193  2018-05-02 20:31:30   991777222380916736   \n",
       "3194         194  2018-05-02 20:16:42   991773496828203013   \n",
       "3195         195  2018-05-02 18:17:05   991743395272982528   \n",
       "3196         196  2018-05-02 16:45:49   991720426278711296   \n",
       "3197         197  2018-05-02 16:08:20   991710994480226305   \n",
       "3198         198  2018-05-02 15:48:57   991706115313491973   \n",
       "3199         199  2018-05-02 15:17:48   991698274347347968   \n",
       "3200           0  2018-05-02 14:47:07   991690554932187136   \n",
       "3201           1  2018-05-02 13:55:13   991677493659799552   \n",
       "3202           2  2018-05-01 19:44:47   991403078401347584   \n",
       "3203           3  2018-05-01 18:14:56   991380465067098113   \n",
       "3204           4  2018-05-01 16:59:25   991361461812416513   \n",
       "3205           5  2018-05-01 16:03:26   991347372033740800   \n",
       "3206           6  2018-05-01 15:24:07   991337476177453058   \n",
       "3207           7  2018-04-29 04:37:12   990449901812281344   \n",
       "3208           8  2018-04-29 04:35:42   990449522492018688   \n",
       "3209           9  2018-04-29 01:18:20   990399855699865601   \n",
       "3210          10  2018-04-29 01:17:42   990399692524670976   \n",
       "\n",
       "                                                   text  \n",
       "0     RT @realDonaldTrump: ....We discussed Trade, V...  \n",
       "1     RT @realDonaldTrump: Had a long and very good ...  \n",
       "2     RT @realDonaldTrump: We can all agree that AME...  \n",
       "3     RT @realDonaldTrump: “The U.S. Created 263,000...  \n",
       "4     RT @realDonaldTrump: Finally, Mainstream Media...  \n",
       "5     RT @WhiteHouse: It's another historic Jobs Day...  \n",
       "6     RT @realDonaldTrump: JOBS, JOBS, JOBS!\\n\\n“Job...  \n",
       "7     RT @realDonaldTrump: Proclamation on Days of R...  \n",
       "8     RT @realDonaldTrump: On this day of prayer, we...  \n",
       "9     RT @realDonaldTrump: ....and deregulation whic...  \n",
       "10    RT @realDonaldTrump: Steve Moore, a great pro-...  \n",
       "11    RT @WhiteHouse: LIVE: President Trump and The ...  \n",
       "12    RT @realDonaldTrump: I am continuing to monito...  \n",
       "13    RT @WhiteHouse: \"So tonight we praise God for ...  \n",
       "14    RT @WhiteHouse: \"During this holy season when ...  \n",
       "15    RT @WhiteHouse: \"Tonight we break bread togeth...  \n",
       "16         RT @realDonaldTrump: https://t.co/S34Q0NY6Ju  \n",
       "17    RT @FLOTUS: It was an honor to host so many wo...  \n",
       "18    RT @realDonaldTrump: Congress must change the ...  \n",
       "19    RT @realDonaldTrump: “No President in history ...  \n",
       "20    RT @realDonaldTrump: Gallup Poll: 56% of Ameri...  \n",
       "21    RT @realDonaldTrump: I am overriding the Decom...  \n",
       "22    RT @realDonaldTrump: “The Democrats can’t come...  \n",
       "23    RT @WhiteHouse: To all the patriotic citizens ...  \n",
       "24    RT @realDonaldTrump: Today, it was my great ho...  \n",
       "25    RT @WhiteHouse: “NASCAR is not only a thrillin...  \n",
       "26    RT @WhiteHouse: President @realDonaldTrump hos...  \n",
       "27    RT @realDonaldTrump: ....embargo, together wit...  \n",
       "28    RT @realDonaldTrump: If Cuban Troops and Milit...  \n",
       "29    RT @WhiteHouse: National Security Advisor @Amb...  \n",
       "...                                                 ...  \n",
       "3181  RT @WhiteHouse: .@SBALinda: @SBAgov Boosts Wom...  \n",
       "3182  RT @WhiteHouse: President Trump has made it cl...  \n",
       "3183  RT @realDonaldTrump: #NationalDayOfPrayer http...  \n",
       "3184  RT @WhiteHouse: \"The Faith Initiative will hel...  \n",
       "3185  RT @WhiteHouse: \"Faith has shaped our families...  \n",
       "3186  RT @WhiteHouse: \"Rev. Graham’s words remind us...  \n",
       "3187  RT @realDonaldTrump: Today, it was my great ho...  \n",
       "3188  RT @WhiteHouse: Today, President Trump signed ...  \n",
       "3189  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3190  RT @WhiteHouse: President Donald J. Trump proc...  \n",
       "3191  RT @WhiteHouse: Gina Haspel has developed outs...  \n",
       "3192  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3193  RT @realDonaldTrump: I have been briefed on th...  \n",
       "3194  RT @WhiteHouse: Gina Haspel has displayed dedi...  \n",
       "3195  RT @realDonaldTrump: Congratulations @SecPompe...  \n",
       "3196  RT @WhiteHouse: The Wall Street Journal: From ...  \n",
       "3197  RT @WhiteHouse: \"For nearly 230 years, the men...  \n",
       "3198  RT @WhiteHouse: A number of public officials h...  \n",
       "3199  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3200  RT @WhiteHouse: Today President Trump and Vice...  \n",
       "3201  RT @WhiteHouse: What They Are Saying: Widespre...  \n",
       "3202  RT @realDonaldTrump: Today, it was my great ho...  \n",
       "3203  RT @realDonaldTrump: Congratulations @ArmyWP_F...  \n",
       "3204  RT @realDonaldTrump: Today I had the great hon...  \n",
       "3205  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3206  RT @realDonaldTrump: Yesterday, it was my grea...  \n",
       "3207  RT @WhiteHouse: Loopholes in our immigration s...  \n",
       "3208  RT @sarasotapd: We might be biased but our Off...  \n",
       "3209  RT @WhiteHouse: Now nearly a decade and a half...  \n",
       "3210  RT @realDonaldTrump: Secret Service has just i...  \n",
       "\n",
       "[3211 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/tweets/@potus.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Friday\n",
       "1          Friday\n",
       "2          Friday\n",
       "3          Friday\n",
       "4          Friday\n",
       "5          Friday\n",
       "6          Friday\n",
       "7        Thursday\n",
       "8        Thursday\n",
       "9        Thursday\n",
       "10       Thursday\n",
       "11       Thursday\n",
       "12      Wednesday\n",
       "13      Wednesday\n",
       "14      Wednesday\n",
       "15      Wednesday\n",
       "16      Wednesday\n",
       "17      Wednesday\n",
       "18      Wednesday\n",
       "19      Wednesday\n",
       "20      Wednesday\n",
       "21      Wednesday\n",
       "22      Wednesday\n",
       "23        Tuesday\n",
       "24        Tuesday\n",
       "25        Tuesday\n",
       "26        Tuesday\n",
       "27        Tuesday\n",
       "28        Tuesday\n",
       "29        Tuesday\n",
       "          ...    \n",
       "3181     Thursday\n",
       "3182     Thursday\n",
       "3183     Thursday\n",
       "3184     Thursday\n",
       "3185     Thursday\n",
       "3186     Thursday\n",
       "3187     Thursday\n",
       "3188     Thursday\n",
       "3189     Thursday\n",
       "3190     Thursday\n",
       "3191    Wednesday\n",
       "3192    Wednesday\n",
       "3193    Wednesday\n",
       "3194    Wednesday\n",
       "3195    Wednesday\n",
       "3196    Wednesday\n",
       "3197    Wednesday\n",
       "3198    Wednesday\n",
       "3199    Wednesday\n",
       "3200    Wednesday\n",
       "3201    Wednesday\n",
       "3202      Tuesday\n",
       "3203      Tuesday\n",
       "3204      Tuesday\n",
       "3205      Tuesday\n",
       "3206      Tuesday\n",
       "3207       Sunday\n",
       "3208       Sunday\n",
       "3209     Saturday\n",
       "3210     Saturday\n",
       "Name: created_at, Length: 3211, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df[\"created_at\"]).dt.tz_localize('UTC').dt.tz_convert('US/Eastern').dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch_market_data(5478)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = datetime.datetime(2019,5,6,12,0,0)\n",
    "d2 = datetime.datetime(2019,5,4,23,0,0)\n",
    "days_left(d1,d2)\n",
    "#start_date = end_date - datetime.timedelta(days=7)\n",
    "#    delta = ts - start_date\n",
    "#    days_left = ((7*24) - (delta.total_seconds()/3600))/24\n",
    "#    return max(round(days_left),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(1, 46800)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 - d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tweets/@realDonaldTrump.csv')\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df.to_csv('data/tweets/@realDonaldTrump.csv', mode='w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-31 23:43:04</td>\n",
       "      <td>156032</td>\n",
       "      <td>947614110082043904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35394</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>HAPPY NEW YEAR! We are MAKING AMERICA GREAT AG...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-31 22:18:20</td>\n",
       "      <td>158995</td>\n",
       "      <td>947592785519173632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39698</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>As our Country rapidly grows stronger and smar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-31 22:00:21</td>\n",
       "      <td>87677</td>\n",
       "      <td>947588263103139840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28128</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Iran, the Number One State of Sponsored Terror...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-31 19:06:52</td>\n",
       "      <td>101162</td>\n",
       "      <td>947544600918372352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26633</td>\n",
       "      <td>Media Studio</td>\n",
       "      <td>What a year it’s been, and we're just getting ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-31 18:36:28</td>\n",
       "      <td>76080</td>\n",
       "      <td>947536951464333312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17041</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>My deepest condolences to the victims of the t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-12-31 13:36:32</td>\n",
       "      <td>106236</td>\n",
       "      <td>947461470924820480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26035</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Why would smart voters want to put Democrats i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-12-31 13:26:29</td>\n",
       "      <td>63403</td>\n",
       "      <td>947458942719979520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14478</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>If the Dems (Crooked Hillary) got elected, you...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-12-31 13:03:29</td>\n",
       "      <td>108343</td>\n",
       "      <td>947453152806297600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30412</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Big protests in Iran. The people are finally g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-12-31 04:46:21</td>\n",
       "      <td>58549</td>\n",
       "      <td>947328044821336064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13096</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“Trump Rally: Stocks put 2017 in the record bo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-12-30 22:42:09</td>\n",
       "      <td>117013</td>\n",
       "      <td>947236393184628736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24332</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Jobs are kicking in and companies are coming b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-12-30 22:36:41</td>\n",
       "      <td>195754</td>\n",
       "      <td>947235015343202304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50342</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>I use Social Media not because I like to, but ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-12-30 21:12:45</td>\n",
       "      <td>73325</td>\n",
       "      <td>947213895286054912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16703</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>On Taxes: “This is the biggest corporate rate ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-12-30 19:02:53</td>\n",
       "      <td>78932</td>\n",
       "      <td>947181212468203520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23270</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Oppressive regimes cannot endure forever, and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-12-30 19:00:54</td>\n",
       "      <td>77986</td>\n",
       "      <td>947180713236934656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23532</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The entire world understands that the good peo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-12-30 03:42:58</td>\n",
       "      <td>138901</td>\n",
       "      <td>946949708915924992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60821</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Many reports of peaceful protests by Iranian c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-12-29 13:16:11</td>\n",
       "      <td>142106</td>\n",
       "      <td>946731576687235072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35208</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The Democrats have been told, and fully unders...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-12-29 13:04:09</td>\n",
       "      <td>118765</td>\n",
       "      <td>946728546633953280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27652</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Why is the United States Post Office, which is...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-12-29 12:50:17</td>\n",
       "      <td>0</td>\n",
       "      <td>946725057384108032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15548</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @charliekirk11: Incredible video: @CBS does...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-12-29 12:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>946724984218669056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18726</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @charliekirk11: ISIS getting slaughtered: \\...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-12-29 12:48:57</td>\n",
       "      <td>0</td>\n",
       "      <td>946724719956578304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11060</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @FoxBusiness: .@charliekirk11: \"What this p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-12-29 12:48:15</td>\n",
       "      <td>0</td>\n",
       "      <td>946724543774765056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16174</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @charliekirk11: 3 big wins in 2017 you won'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-12-29 12:46:23</td>\n",
       "      <td>98172</td>\n",
       "      <td>946724075157651456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23184</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>While the Fake News loves to talk about my so-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-12-29 00:01:47</td>\n",
       "      <td>204151</td>\n",
       "      <td>946531657229701120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65929</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>In the East, it could be the COLDEST New Year’...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-12-28 23:14:21</td>\n",
       "      <td>67092</td>\n",
       "      <td>946519720450252800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15516</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Together, we are MAKING AMERICA GREAT AGAIN! h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-12-28 22:17:55</td>\n",
       "      <td>0</td>\n",
       "      <td>946505517417095168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21183</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @realDonaldTrump: “Arrests of MS-13 Members...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-12-28 22:17:36</td>\n",
       "      <td>0</td>\n",
       "      <td>946505439939911680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2231</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @DanScavino: Congratulations to the 2017 @P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-12-28 22:17:06</td>\n",
       "      <td>0</td>\n",
       "      <td>946505312164630528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6612</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @EricTrump: #ThrowbackThursdays \\n@realDona...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-12-28 22:16:29</td>\n",
       "      <td>0</td>\n",
       "      <td>946505155809247232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11872</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @IvankaTrump: “The Trump economy is booming...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-12-28 19:20:47</td>\n",
       "      <td>73657</td>\n",
       "      <td>946460939578167296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26402</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>I've been saying it for a long, long time. #No...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-12-28 16:24:08</td>\n",
       "      <td>124997</td>\n",
       "      <td>946416486054285312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31963</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Caught RED HANDED - very disappointed that Chi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>2019-01-03 16:10:31</td>\n",
       "      <td>202291</td>\n",
       "      <td>1080858959404240896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54075</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>https://t.co/JzfXMAPwKP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>2019-01-03 14:52:13</td>\n",
       "      <td>106376</td>\n",
       "      <td>1080839254656405504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22311</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The United States Treasury has taken in MANY b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>2019-01-03 14:44:19</td>\n",
       "      <td>129182</td>\n",
       "      <td>1080837263913832448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30482</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The Shutdown is only because of the 2020 Presi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208</th>\n",
       "      <td>2019-01-03 14:36:57</td>\n",
       "      <td>68602</td>\n",
       "      <td>1080835412271222784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18601</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“MAGA list: 205 ‘historic results’ help Trump ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>2019-01-03 04:09:52</td>\n",
       "      <td>155849</td>\n",
       "      <td>1080677601046347776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31117</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Sadly, there can be no REAL Border Security wi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>2019-01-03 00:07:38</td>\n",
       "      <td>103455</td>\n",
       "      <td>1080616637932421120</td>\n",
       "      <td>25073877.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21693</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>...I remain ready and willing to work with Dem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>2019-01-03 00:07:37</td>\n",
       "      <td>115649</td>\n",
       "      <td>1080616636363743232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23145</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Important meeting today on Border Security wit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>2019-01-02 13:35:30</td>\n",
       "      <td>128491</td>\n",
       "      <td>1080457560291987456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28559</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Mexico is paying for the Wall through the new ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>2019-01-02 12:53:55</td>\n",
       "      <td>175756</td>\n",
       "      <td>1080447092882112512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36818</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Here we go with Mitt Romney, but so fast! Ques...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7214</th>\n",
       "      <td>2019-01-02 00:43:50</td>\n",
       "      <td>127500</td>\n",
       "      <td>1080263362183917568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32078</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>For FAR TOO LONG Senate Democrats have been Ob...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7215</th>\n",
       "      <td>2019-01-01 23:39:32</td>\n",
       "      <td>160975</td>\n",
       "      <td>1080247182186430464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30351</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Do you think it’s just luck that gas prices ar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216</th>\n",
       "      <td>2019-01-01 23:11:12</td>\n",
       "      <td>116495</td>\n",
       "      <td>1080240049780940800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24747</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“Kim Jong Un says North Korea will not make or...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7217</th>\n",
       "      <td>2019-01-01 22:51:12</td>\n",
       "      <td>77877</td>\n",
       "      <td>1080235018310635520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17196</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Washington Examiner - “MAGA list: 205 ‘histori...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>2019-01-01 22:44:03</td>\n",
       "      <td>201811</td>\n",
       "      <td>1080233215615557632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30080</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Gas prices are low and expected to go down thi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7219</th>\n",
       "      <td>2019-01-01 19:02:36</td>\n",
       "      <td>104220</td>\n",
       "      <td>1080177487517233152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20267</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Border Security and the Wall “thing” and Shutd...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7220</th>\n",
       "      <td>2019-01-01 18:12:08</td>\n",
       "      <td>265614</td>\n",
       "      <td>1080164786330132480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59698</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Congratulations to President \\n@JairBolsonaro ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221</th>\n",
       "      <td>2019-01-01 15:51:09</td>\n",
       "      <td>119139</td>\n",
       "      <td>1080129307446513664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26840</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>One thing has now been proven. The Democrats d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7222</th>\n",
       "      <td>2019-01-01 15:32:30</td>\n",
       "      <td>69306</td>\n",
       "      <td>1080124615920373760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16907</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“General” McChrystal got fired like a dog by O...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7223</th>\n",
       "      <td>2019-01-01 14:55:01</td>\n",
       "      <td>0</td>\n",
       "      <td>1080115181831761920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21607</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @realDonaldTrump: ....Senator Schumer, more...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7224</th>\n",
       "      <td>2019-01-01 14:54:32</td>\n",
       "      <td>0</td>\n",
       "      <td>1080115061849575424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25866</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @realDonaldTrump: Heads of countries are ca...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7225</th>\n",
       "      <td>2019-01-01 14:52:33</td>\n",
       "      <td>0</td>\n",
       "      <td>1080114559925567488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12796</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @GOPChairwoman: .@realDonaldTrump made sure...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7226</th>\n",
       "      <td>2019-01-01 14:50:39</td>\n",
       "      <td>0</td>\n",
       "      <td>1080114081795842048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11844</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @GOPChairwoman: Jobless claims fell last we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7227</th>\n",
       "      <td>2019-01-01 14:32:01</td>\n",
       "      <td>101836</td>\n",
       "      <td>1080109395357380608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21201</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The Democrats, much as I suspected, have alloc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>2019-01-01 14:25:32</td>\n",
       "      <td>277623</td>\n",
       "      <td>1080107759755034624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40361</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Happy New Year!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7229</th>\n",
       "      <td>2019-01-01 13:08:29</td>\n",
       "      <td>256114</td>\n",
       "      <td>1080088373451206656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59039</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>HAPPY NEW YEAR TO EVERYONE, INCLUDING THE HATE...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7230</th>\n",
       "      <td>2019-01-01 12:51:34</td>\n",
       "      <td>76622</td>\n",
       "      <td>1080084113762197504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14059</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Dr. Sebastian Gorka, a very good and talented ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7231</th>\n",
       "      <td>2019-01-01 02:01:26</td>\n",
       "      <td>0</td>\n",
       "      <td>1079920504268562432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25861</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>RT @WhiteHouse: 2018 has been a year of histor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7232</th>\n",
       "      <td>2019-01-01 01:05:39</td>\n",
       "      <td>135209</td>\n",
       "      <td>1079906462753869824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28529</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>...Remember this. Throughout the ages some thi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7233</th>\n",
       "      <td>2019-01-01 00:51:43</td>\n",
       "      <td>99239</td>\n",
       "      <td>1079902957938925568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22897</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The Democrats will probably submit a Bill, bei...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7234</th>\n",
       "      <td>2019-01-01 00:40:26</td>\n",
       "      <td>104440</td>\n",
       "      <td>1079900120047603712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23882</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>MEXICO IS PAYING FOR THE WALL through the many...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7235 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at  favorite_count               id_str  \\\n",
       "0     2017-12-31 23:43:04          156032   947614110082043904   \n",
       "1     2017-12-31 22:18:20          158995   947592785519173632   \n",
       "2     2017-12-31 22:00:21           87677   947588263103139840   \n",
       "3     2017-12-31 19:06:52          101162   947544600918372352   \n",
       "4     2017-12-31 18:36:28           76080   947536951464333312   \n",
       "5     2017-12-31 13:36:32          106236   947461470924820480   \n",
       "6     2017-12-31 13:26:29           63403   947458942719979520   \n",
       "7     2017-12-31 13:03:29          108343   947453152806297600   \n",
       "8     2017-12-31 04:46:21           58549   947328044821336064   \n",
       "9     2017-12-30 22:42:09          117013   947236393184628736   \n",
       "10    2017-12-30 22:36:41          195754   947235015343202304   \n",
       "11    2017-12-30 21:12:45           73325   947213895286054912   \n",
       "12    2017-12-30 19:02:53           78932   947181212468203520   \n",
       "13    2017-12-30 19:00:54           77986   947180713236934656   \n",
       "14    2017-12-30 03:42:58          138901   946949708915924992   \n",
       "15    2017-12-29 13:16:11          142106   946731576687235072   \n",
       "16    2017-12-29 13:04:09          118765   946728546633953280   \n",
       "17    2017-12-29 12:50:17               0   946725057384108032   \n",
       "18    2017-12-29 12:50:00               0   946724984218669056   \n",
       "19    2017-12-29 12:48:57               0   946724719956578304   \n",
       "20    2017-12-29 12:48:15               0   946724543774765056   \n",
       "21    2017-12-29 12:46:23           98172   946724075157651456   \n",
       "22    2017-12-29 00:01:47          204151   946531657229701120   \n",
       "23    2017-12-28 23:14:21           67092   946519720450252800   \n",
       "24    2017-12-28 22:17:55               0   946505517417095168   \n",
       "25    2017-12-28 22:17:36               0   946505439939911680   \n",
       "26    2017-12-28 22:17:06               0   946505312164630528   \n",
       "27    2017-12-28 22:16:29               0   946505155809247232   \n",
       "28    2017-12-28 19:20:47           73657   946460939578167296   \n",
       "29    2017-12-28 16:24:08          124997   946416486054285312   \n",
       "...                   ...             ...                  ...   \n",
       "7205  2019-01-03 16:10:31          202291  1080858959404240896   \n",
       "7206  2019-01-03 14:52:13          106376  1080839254656405504   \n",
       "7207  2019-01-03 14:44:19          129182  1080837263913832448   \n",
       "7208  2019-01-03 14:36:57           68602  1080835412271222784   \n",
       "7209  2019-01-03 04:09:52          155849  1080677601046347776   \n",
       "7210  2019-01-03 00:07:38          103455  1080616637932421120   \n",
       "7211  2019-01-03 00:07:37          115649  1080616636363743232   \n",
       "7212  2019-01-02 13:35:30          128491  1080457560291987456   \n",
       "7213  2019-01-02 12:53:55          175756  1080447092882112512   \n",
       "7214  2019-01-02 00:43:50          127500  1080263362183917568   \n",
       "7215  2019-01-01 23:39:32          160975  1080247182186430464   \n",
       "7216  2019-01-01 23:11:12          116495  1080240049780940800   \n",
       "7217  2019-01-01 22:51:12           77877  1080235018310635520   \n",
       "7218  2019-01-01 22:44:03          201811  1080233215615557632   \n",
       "7219  2019-01-01 19:02:36          104220  1080177487517233152   \n",
       "7220  2019-01-01 18:12:08          265614  1080164786330132480   \n",
       "7221  2019-01-01 15:51:09          119139  1080129307446513664   \n",
       "7222  2019-01-01 15:32:30           69306  1080124615920373760   \n",
       "7223  2019-01-01 14:55:01               0  1080115181831761920   \n",
       "7224  2019-01-01 14:54:32               0  1080115061849575424   \n",
       "7225  2019-01-01 14:52:33               0  1080114559925567488   \n",
       "7226  2019-01-01 14:50:39               0  1080114081795842048   \n",
       "7227  2019-01-01 14:32:01          101836  1080109395357380608   \n",
       "7228  2019-01-01 14:25:32          277623  1080107759755034624   \n",
       "7229  2019-01-01 13:08:29          256114  1080088373451206656   \n",
       "7230  2019-01-01 12:51:34           76622  1080084113762197504   \n",
       "7231  2019-01-01 02:01:26               0  1079920504268562432   \n",
       "7232  2019-01-01 01:05:39          135209  1079906462753869824   \n",
       "7233  2019-01-01 00:51:43           99239  1079902957938925568   \n",
       "7234  2019-01-01 00:40:26          104440  1079900120047603712   \n",
       "\n",
       "      in_reply_to_user_id_str  is_retweet  retweet_count              source  \\\n",
       "0                         NaN         0.0          35394  Twitter for iPhone   \n",
       "1                         NaN         0.0          39698  Twitter for iPhone   \n",
       "2                         NaN         0.0          28128  Twitter for iPhone   \n",
       "3                         NaN         0.0          26633        Media Studio   \n",
       "4                         NaN         0.0          17041  Twitter for iPhone   \n",
       "5                         NaN         0.0          26035  Twitter for iPhone   \n",
       "6                         NaN         0.0          14478  Twitter for iPhone   \n",
       "7                         NaN         0.0          30412  Twitter for iPhone   \n",
       "8                         NaN         0.0          13096  Twitter for iPhone   \n",
       "9                         NaN         0.0          24332  Twitter for iPhone   \n",
       "10                        NaN         0.0          50342  Twitter for iPhone   \n",
       "11                        NaN         0.0          16703  Twitter for iPhone   \n",
       "12                        NaN         0.0          23270  Twitter for iPhone   \n",
       "13                        NaN         0.0          23532  Twitter for iPhone   \n",
       "14                        NaN         0.0          60821  Twitter for iPhone   \n",
       "15                        NaN         0.0          35208  Twitter for iPhone   \n",
       "16                        NaN         0.0          27652  Twitter for iPhone   \n",
       "17                        NaN         1.0          15548  Twitter for iPhone   \n",
       "18                        NaN         1.0          18726  Twitter for iPhone   \n",
       "19                        NaN         1.0          11060  Twitter for iPhone   \n",
       "20                        NaN         1.0          16174  Twitter for iPhone   \n",
       "21                        NaN         0.0          23184  Twitter for iPhone   \n",
       "22                        NaN         0.0          65929  Twitter for iPhone   \n",
       "23                        NaN         0.0          15516  Twitter for iPhone   \n",
       "24                        NaN         1.0          21183  Twitter for iPhone   \n",
       "25                        NaN         1.0           2231  Twitter for iPhone   \n",
       "26                        NaN         1.0           6612  Twitter for iPhone   \n",
       "27                        NaN         1.0          11872  Twitter for iPhone   \n",
       "28                        NaN         0.0          26402    Twitter for iPad   \n",
       "29                        NaN         0.0          31963  Twitter for iPhone   \n",
       "...                       ...         ...            ...                 ...   \n",
       "7205                      NaN         0.0          54075  Twitter for iPhone   \n",
       "7206                      NaN         0.0          22311  Twitter for iPhone   \n",
       "7207                      NaN         0.0          30482  Twitter for iPhone   \n",
       "7208                      NaN         0.0          18601  Twitter for iPhone   \n",
       "7209                      NaN         0.0          31117  Twitter for iPhone   \n",
       "7210               25073877.0         0.0          21693  Twitter for iPhone   \n",
       "7211                      NaN         0.0          23145  Twitter for iPhone   \n",
       "7212                      NaN         0.0          28559  Twitter for iPhone   \n",
       "7213                      NaN         0.0          36818  Twitter for iPhone   \n",
       "7214                      NaN         0.0          32078  Twitter for iPhone   \n",
       "7215                      NaN         0.0          30351  Twitter for iPhone   \n",
       "7216                      NaN         0.0          24747  Twitter for iPhone   \n",
       "7217                      NaN         0.0          17196  Twitter for iPhone   \n",
       "7218                      NaN         0.0          30080  Twitter for iPhone   \n",
       "7219                      NaN         0.0          20267  Twitter for iPhone   \n",
       "7220                      NaN         0.0          59698  Twitter for iPhone   \n",
       "7221                      NaN         0.0          26840  Twitter for iPhone   \n",
       "7222                      NaN         0.0          16907  Twitter for iPhone   \n",
       "7223                      NaN         1.0          21607  Twitter for iPhone   \n",
       "7224                      NaN         1.0          25866  Twitter for iPhone   \n",
       "7225                      NaN         1.0          12796  Twitter for iPhone   \n",
       "7226                      NaN         1.0          11844  Twitter for iPhone   \n",
       "7227                      NaN         0.0          21201  Twitter for iPhone   \n",
       "7228                      NaN         0.0          40361  Twitter for iPhone   \n",
       "7229                      NaN         0.0          59039  Twitter for iPhone   \n",
       "7230                      NaN         0.0          14059  Twitter for iPhone   \n",
       "7231                      NaN         1.0          25861  Twitter for iPhone   \n",
       "7232                      NaN         0.0          28529  Twitter for iPhone   \n",
       "7233                      NaN         0.0          22897  Twitter for iPhone   \n",
       "7234                      NaN         0.0          23882  Twitter for iPhone   \n",
       "\n",
       "                                                   text  year  \n",
       "0     HAPPY NEW YEAR! We are MAKING AMERICA GREAT AG...   NaN  \n",
       "1     As our Country rapidly grows stronger and smar...   NaN  \n",
       "2     Iran, the Number One State of Sponsored Terror...   NaN  \n",
       "3     What a year it’s been, and we're just getting ...   NaN  \n",
       "4     My deepest condolences to the victims of the t...   NaN  \n",
       "5     Why would smart voters want to put Democrats i...   NaN  \n",
       "6     If the Dems (Crooked Hillary) got elected, you...   NaN  \n",
       "7     Big protests in Iran. The people are finally g...   NaN  \n",
       "8     “Trump Rally: Stocks put 2017 in the record bo...   NaN  \n",
       "9     Jobs are kicking in and companies are coming b...   NaN  \n",
       "10    I use Social Media not because I like to, but ...   NaN  \n",
       "11    On Taxes: “This is the biggest corporate rate ...   NaN  \n",
       "12    Oppressive regimes cannot endure forever, and ...   NaN  \n",
       "13    The entire world understands that the good peo...   NaN  \n",
       "14    Many reports of peaceful protests by Iranian c...   NaN  \n",
       "15    The Democrats have been told, and fully unders...   NaN  \n",
       "16    Why is the United States Post Office, which is...   NaN  \n",
       "17    RT @charliekirk11: Incredible video: @CBS does...   NaN  \n",
       "18    RT @charliekirk11: ISIS getting slaughtered: \\...   NaN  \n",
       "19    RT @FoxBusiness: .@charliekirk11: \"What this p...   NaN  \n",
       "20    RT @charliekirk11: 3 big wins in 2017 you won'...   NaN  \n",
       "21    While the Fake News loves to talk about my so-...   NaN  \n",
       "22    In the East, it could be the COLDEST New Year’...   NaN  \n",
       "23    Together, we are MAKING AMERICA GREAT AGAIN! h...   NaN  \n",
       "24    RT @realDonaldTrump: “Arrests of MS-13 Members...   NaN  \n",
       "25    RT @DanScavino: Congratulations to the 2017 @P...   NaN  \n",
       "26    RT @EricTrump: #ThrowbackThursdays \\n@realDona...   NaN  \n",
       "27    RT @IvankaTrump: “The Trump economy is booming...   NaN  \n",
       "28    I've been saying it for a long, long time. #No...   NaN  \n",
       "29    Caught RED HANDED - very disappointed that Chi...   NaN  \n",
       "...                                                 ...   ...  \n",
       "7205                            https://t.co/JzfXMAPwKP   NaN  \n",
       "7206  The United States Treasury has taken in MANY b...   NaN  \n",
       "7207  The Shutdown is only because of the 2020 Presi...   NaN  \n",
       "7208  “MAGA list: 205 ‘historic results’ help Trump ...   NaN  \n",
       "7209  Sadly, there can be no REAL Border Security wi...   NaN  \n",
       "7210  ...I remain ready and willing to work with Dem...   NaN  \n",
       "7211  Important meeting today on Border Security wit...   NaN  \n",
       "7212  Mexico is paying for the Wall through the new ...   NaN  \n",
       "7213  Here we go with Mitt Romney, but so fast! Ques...   NaN  \n",
       "7214  For FAR TOO LONG Senate Democrats have been Ob...   NaN  \n",
       "7215  Do you think it’s just luck that gas prices ar...   NaN  \n",
       "7216  “Kim Jong Un says North Korea will not make or...   NaN  \n",
       "7217  Washington Examiner - “MAGA list: 205 ‘histori...   NaN  \n",
       "7218  Gas prices are low and expected to go down thi...   NaN  \n",
       "7219  Border Security and the Wall “thing” and Shutd...   NaN  \n",
       "7220  Congratulations to President \\n@JairBolsonaro ...   NaN  \n",
       "7221  One thing has now been proven. The Democrats d...   NaN  \n",
       "7222  “General” McChrystal got fired like a dog by O...   NaN  \n",
       "7223  RT @realDonaldTrump: ....Senator Schumer, more...   NaN  \n",
       "7224  RT @realDonaldTrump: Heads of countries are ca...   NaN  \n",
       "7225  RT @GOPChairwoman: .@realDonaldTrump made sure...   NaN  \n",
       "7226  RT @GOPChairwoman: Jobless claims fell last we...   NaN  \n",
       "7227  The Democrats, much as I suspected, have alloc...   NaN  \n",
       "7228                                    Happy New Year!   NaN  \n",
       "7229  HAPPY NEW YEAR TO EVERYONE, INCLUDING THE HATE...   NaN  \n",
       "7230  Dr. Sebastian Gorka, a very good and talented ...   NaN  \n",
       "7231  RT @WhiteHouse: 2018 has been a year of histor...   NaN  \n",
       "7232  ...Remember this. Throughout the ages some thi...   NaN  \n",
       "7233  The Democrats will probably submit a Bill, bei...   NaN  \n",
       "7234  MEXICO IS PAYING FOR THE WALL through the many...   NaN  \n",
       "\n",
       "[7235 rows x 9 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/tweets/@realDonaldTrump.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "update_twitter_history('@vp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
