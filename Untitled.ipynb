{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import os\n",
    "import dateutil\n",
    "import time\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical data\n",
    "import calendar\n",
    "\n",
    "def next_weekday(d, weekday):\n",
    "    days_ahead = weekday - d.weekday()\n",
    "    if days_ahead < 0: # Target day already happened this week\n",
    "        days_ahead += 7\n",
    "    return d + datetime.timedelta(days_ahead)\n",
    "\n",
    "def bucketed(df, start_on=\"Sunday\"):\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    \n",
    "    df['created_at'] = pd.to_datetime(df['created_at']).dt.date\n",
    "    min_date = df[\"created_at\"].min()\n",
    "    min_date = next_weekday(min_date, list(calendar.day_name).index(start_on))\n",
    "    max_date = df[\"created_at\"].max()\n",
    "    tweet_counts = df.groupby('created_at').agg('count')[\"text\"]\n",
    "    dates = pd.date_range(min_date, max_date, freq='D')\n",
    "    counts = pd.DataFrame({ \"count\": tweet_counts},index=dates).fillna(0)\n",
    "    counts = counts.resample('7D').sum()\n",
    "    return counts.drop(counts.tail(1).index) # drop last row in case its a count over less than the full time bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_BALANCE = 58\n",
    "N_TWEETS = 0\n",
    "\n",
    "BEARER_TOKEN=\"AAAAAAAAAAAAAAAAAAAAAAXT9gAAAAAAoITLBCf%2B2K7BMSqakqcbsHUSLrk%3DLz95o8CkkhjOTthpcyEEg6BdNav0zphRcrEYdeG4GXXV3Qkftk\"\n",
    "\n",
    "## value functions\n",
    "def expected_value(potential_win, chance_win, potential_loss, chance_loss):\n",
    "    return (potential_win * chance_win) - (potential_loss * chance_loss)\n",
    "\n",
    "def allocation(account_balance, expected_value):\n",
    "    pct_alloc = min(( expected_value * 5 ) / 10, .03)\n",
    "    alloc = account_balance * pct_alloc\n",
    "    #risk_coef = 1 - (1 / (proba * 100) )\n",
    "    #risk_adjusted = alloc * risk_coef\n",
    "    #return risk_adjusted\n",
    "    return alloc\n",
    "def allocation(price_per_share, proba):\n",
    "    payoff_odds = (1 / price_per_share) - 1\n",
    "\n",
    "def recommended_shares(account_balance, expected_value, price_per_share):\n",
    "    return allocation(account_balance, expected_value) / price_per_share;\n",
    "\n",
    "def to_proba(buckets, categories=None):\n",
    "    vals = buckets.value_counts()\n",
    "    # [ (range(0,2), \"0-2\"), range(3-5), \"3-5\" ]\n",
    "    #for c in categories:\n",
    "    #    rnge = c[0]\n",
    "    #    id_str = c[1]\n",
    "    #    for r in range:\n",
    "            \n",
    "    s = vals.sum()\n",
    "    return vals/s\n",
    "\n",
    "## portfolio management\n",
    "TAX_RATE = .1\n",
    "def kelly_criterion(outcomes):\n",
    "    # category, price_per_share, proba\n",
    "    er = []\n",
    "    betas = []\n",
    "    for index, o in outcomes.iterrows():\n",
    "        payoff_odds = (1 / o[\"price_per_share\"]) - 1\n",
    "        beta = 1 / (1 + payoff_odds)\n",
    "        dividend_rate = 1 - TAX_RATE\n",
    "        expected_revenue_rate = (dividend_rate / beta) * o[\"proba\"]\n",
    "        er.append(expected_revenue_rate)\n",
    "        betas.append(beta)\n",
    "        \n",
    "    outcomes[\"expected_revenue_rate\"] = er\n",
    "    outcomes[\"beta\"] = betas\n",
    "    outcomes = outcomes.sort_values(\"expected_revenue_rate\", ascending=False)\n",
    "    \n",
    "    reserve_rate = 1\n",
    "    optimal_set = pd.DataFrame()\n",
    "    for index, o in outcomes.iterrows():\n",
    "        if o[\"expected_revenue_rate\"] > reserve_rate:\n",
    "            optimal_set = optimal_set.append(o)\n",
    "            reserve_rate = (1 - optimal_set[\"proba\"].sum()) / (1 - (optimal_set[\"beta\"] / dividend_rate).sum())\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    pct_alloc = [] \n",
    "    for index, o in optimal_set.iterrows():\n",
    "        pct = (o[\"expected_revenue_rate\"] - reserve_rate) / ( dividend_rate / o[\"beta\"] )\n",
    "        pct_alloc.append(pct)\n",
    "    optimal_set[\"pct_alloc\"] = pct_alloc\n",
    "    return optimal_set\n",
    "\n",
    "def shares_bought(c, yes_or_no, positions):\n",
    "    bought = 0\n",
    "    if c in positions and yes_or_no in positions[c]:\n",
    "        for pos in positions[c][yes_or_no]:\n",
    "            bought += pos[1]\n",
    "    return bought\n",
    "\n",
    "def recommendation_buy(contract, yes_or_no, account_balance, expected_value, price_per_share, positions):\n",
    "    shares = recommended_shares(account_balance, expected_value, price_per_share) - shares_bought(contract, yes_or_no, positions)\n",
    "    shares = int(round(shares))\n",
    "    if shares > 0:\n",
    "        print(\"BUY {yn} shares for contract {n}: {shares} shares @{price} (EV: {ev}, TOTAL: {t})\".format(n=contract,shares=shares, price=price_per_share, ev=expected_value, yn=yes_or_no.upper(), t=shares*price_per_share))\n",
    "\n",
    "def recommendation_sell(contract, yes_or_no, expected_value, price_per_share, n_shares, bought_at):\n",
    "    print(\"SELL {yn} shares for contract {n}_{bought_at}_{n_shares}: ALL shares @{price} (EV: {ev}, TOTAL: {t})\".format(n=contract, price=price_per_share, ev=expected_value, yn=yes_or_no.upper(), t=n_shares*price_per_share, bought_at=bought_at, n_shares=n_shares))\n",
    "    \n",
    "## market evaluation\n",
    "def fetch_market_data(market_id):\n",
    "    url = \"https://www.predictit.org/api/marketdata/markets/{id}\".format(id=market_id)\n",
    "    r = requests.get(url=url)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_twitter_user_timeline(screen_name, max_id=None, since_id=None):\n",
    "    url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n",
    "    headers = { \"Authorization\": \"Bearer {t}\".format(t=BEARER_TOKEN)}\n",
    "    params = {\n",
    "        \"count\": \"200\",\n",
    "        \"trim_user\": \"true\",\n",
    "        \"screen_name\": screen_name\n",
    "    }\n",
    "    if max_id: \n",
    "        params[\"max_id\"] = max_id\n",
    "    if since_id:\n",
    "        params[\"since_id\"] = since_id\n",
    "        \n",
    "    r = requests.get(url=url,headers=headers, params=params)\n",
    "    raw = r.json()\n",
    "    transformed = json.dumps([ { \"id\": tweet[\"id\"], \"created_at\": tweet[\"created_at\"], \"text\": tweet[\"text\"] } for tweet in raw])\n",
    "    return pd.read_json(transformed, orient=\"records\")\n",
    "\n",
    "def get_recent_tweets(screen_name, from_date=None):\n",
    "    df = get_twitter_user_timeline(screen_name)\n",
    "    df[\"created_at\"] = df[\"created_at\"].dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "    if from_date:\n",
    "        df = df[df[\"created_at\"] > from_date]\n",
    "    return df\n",
    "    \n",
    "# the twitter api returns different results for the same request...\n",
    "def _get_twitter_history(screen_name, max_id=None):\n",
    "    get_next = True\n",
    "    df = pd.DataFrame(columns=[\"id\",\"created_at\", \"text\"])\n",
    "    while get_next:\n",
    "        tweets = get_twitter_user_timeline(screen_name, max_id)\n",
    "        print(len(tweets.index))\n",
    "        if len(tweets.index) > 0:\n",
    "            df = tweets if df.empty else pd.concat([df, tweets], axis=0)\n",
    "            last_row = tweets.tail(1).iloc[0]\n",
    "            max_id = last_row[\"id\"] - 1\n",
    "        else:\n",
    "            get_next = False\n",
    "    return df\n",
    "\n",
    "def get_twitter_history(screen_name, cache=True):\n",
    "    fname = \"data/tweets/{sn}.csv\".format(sn=screen_name)\n",
    "    max_id = None\n",
    "    if cache and os.path.isfile(fname):\n",
    "        df = pd.read_csv(fname)\n",
    "        max_id = int(df.tail(1).iloc[0][\"id\"]) -1\n",
    "    df = _get_twitter_history(screen_name, max_id);\n",
    "    if not os.path.isdir(\"data/tweets\"):\n",
    "        os.mkdir(\"data/tweets\")\n",
    "    if len(df) > 0:\n",
    "        df.to_csv(fname, mode='a')\n",
    "\n",
    "def fetch_full_trump_tweet_history(rnge, cache=True):\n",
    "    fname = \"data/tweets/@realDonaldTrump.csv\"\n",
    "    df = None\n",
    "    for year in rnge:\n",
    "        url = None\n",
    "        if year == 2019:\n",
    "            url = \"http://www.trumptwitterarchive.com/data/realdonaldtrump/2019.json\"\n",
    "        else:\n",
    "            url = \"http://d5nxcu7vtzvay.cloudfront.net/data/realdonaldtrump/{y}.json\".format(y=str(year))\n",
    "        _df  = pd.read_json(url)\n",
    "        if df is None:\n",
    "            df = _df\n",
    "        else:\n",
    "            df = pd.concat([df,_df])\n",
    "        time.sleep(1)\n",
    "     \n",
    "    if not os.path.isdir(\"data/tweets\"):\n",
    "        os.mkdir(\"data/tweets\")\n",
    "    if len(df) > 0:\n",
    "        df.to_csv(fname, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\"homieng6@gmail.com\"\n",
    "#\"??\"\n",
    "#\"@homiesaccount\"\n",
    "#\"nY7VUVqcxJ4vmcX\"\n",
    "#\"AAAAAAAAAAAAAAAAAAAAAAXT9gAAAAAAoITLBCf%2B2K7BMSqakqcbsHUSLrk%3DLz95o8CkkhjOTthpcyEEg6BdNav0zphRcrEYdeG4GXXV3Qkft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweet_distributions_per_day(source_df):\n",
    "    df = pd.DataFrame(columns=[\"proba\",\"day\"])\n",
    "    df.index.name = \"n_tweets\"\n",
    "    for x in range(0,7,1):\n",
    "        weekday = calendar.day_name[x]\n",
    "        b = bucketed(source_df, start_on=weekday)\n",
    "        proba = b['count']/b['count'].sum()\n",
    "        _df = pd.DataFrame({ \"proba\": proba.values, \"day\": x }, index=proba.index)\n",
    "        df = pd.concat([df, _df])\n",
    "        df[\"n_tweets\"] = df.index\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for key, _grp in df.groupby(['n_tweets']):\n",
    "        grp = _grp.sort_values(by=\"day\", ascending=False)\n",
    "        ax = grp.plot(ax=ax, kind='line', x=\"day\", y='proba', label=str(grp[\"n_tweets\"].iloc[0]))\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "#_df = pd.read_csv('./data/fake_news_tweets.csv')\n",
    "#plot_tweet_distributions_per_day(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_twitter_market_research(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # number of tweets per week\n",
    "    b=bucketed(df)\n",
    "    b.plot(title=\"Tweets per Week\")\n",
    "    plt.show()\n",
    "    \n",
    "    # distribution of tweets per week\n",
    "    vals = b[\"count\"].value_counts()\n",
    "    bins = vals.size\n",
    "    b[\"count\"].plot(kind=\"hist\",bins=bins, title=\"Tweets per Week Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "    # freq of tweets per day\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    \n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    df['day_of_week'].value_counts().reindex(weekdays).plot(kind='bar', title=\"Tweets per Calendar Day\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_range_str(range):\n",
    "    return str(range.start) + \"-\" + str(range.stop-1)\n",
    "\n",
    "def append_count(series, count, category_range):\n",
    "    return series.append(pd.Series([ count ], index=[ to_range_str(category_range) ]))\n",
    "\n",
    "# takes dataframe with tweet counts bucketed per n days\n",
    "# returns a data frame that returns counts for a category based, excluding coun\n",
    "# this answers: what is the probability that we end in a category, given that we have already seen curr_n values\n",
    "def count_adjusted(df, categories, curr_n):\n",
    "    grouped = pd.Series()\n",
    "    for rnge in categories:\n",
    "        adjusted_range = range(max(rnge.start-curr_n, 0), max(rnge.stop-curr_n, 0 ))\n",
    "        count = df[df[\"count\"].between(adjusted_range.start, adjusted_range.stop-1)].shape[0]\n",
    "        grouped = append_count(grouped, count, rnge)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_twitter_market(market, path, data=None, ts=None, show_market_research=False):\n",
    "    if show_market_research:\n",
    "        show_twitter_market_research(path)\n",
    "        \n",
    "    if data is None:\n",
    "        data = fetch_market_data(market[\"id\"])\n",
    "        \n",
    "    contracts = data[\"contracts\"]\n",
    "    for c in contracts:\n",
    "        c_id = str(c[\"id\"])\n",
    "        annotations = market[\"contract_map\"][c_id]\n",
    "        c[\"range\"] = annotations[\"range\"]\n",
    "        c[\"category\"] = to_range_str(c[\"range\"])\n",
    "    print(data[\"shortName\"])\n",
    "    \n",
    "    end_date_str = contracts[0][\"dateEnd\"]\n",
    "    end_date = parser.parse(end_date_str)\n",
    "    start_date = end_date - datetime.timedelta(days=7)\n",
    "    n_days = days_left(end_date, ts)\n",
    "    print(\"Days left:\", n_days)\n",
    "    \n",
    "    timezone = pytz.timezone(\"US/Eastern\")\n",
    "    from_date = timezone.localize(start_date)\n",
    "    recent = get_recent_tweets(market[\"twitter_handle\"], from_date=from_date)\n",
    "    if ( \"filter\" in market.keys() ):\n",
    "        recent = recent[recent[\"text\"].str.contains(market[\"filter\"],case=False)]\n",
    "        #n_matching_tweets = len(recent[recent[\"text\"].str.contains(\"fake news|fakenews\",case=False)])\n",
    "    n_matching_tweets = len(recent)\n",
    "    print(\"Matching tweets:\", n_matching_tweets)\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    weekdays = calendar.day_name\n",
    "    timezone = pytz.timezone(\"US/Eastern\")\n",
    "    from_date = timezone.localize(datetime.datetime.utcnow())\n",
    "    circular_weekdays = np.tile(weekdays, 2)\n",
    "    idx = np.where(circular_weekdays == from_date.strftime(\"%A\"))[0][0]\n",
    "    weekdays_left = circular_weekdays[idx:idx+n_days]\n",
    "    \n",
    "    df = df[df[\"day_of_week\"].isin(weekdays_left)]   \n",
    "    b=bucketed(df, start_on=weekdays[idx])\n",
    "    c=count_adjusted(b, [c[\"range\"] for c in contracts], n_matching_tweets )\n",
    "    proba = c/c.sum()\n",
    "    print(\"Category probabilities:\")\n",
    "    pprint.pprint(proba)\n",
    "    \n",
    "#    for c in contracts: \n",
    "#        #print(\"Contract\", c[\"name\"])\n",
    "#        category = c[\"category\"]\n",
    "#        expected_values = eval_trade_variations(c, proba, category, positions)\n",
    "#        #print(json.dumps(expected_values, indent=4))\n",
    "#        for k, v in expected_values.items():\n",
    "#            ev = v[0]\n",
    "#            price = v[1]\n",
    "#            yes_or_no = \"yes\" if \"yes\" in k else \"no\"\n",
    "#            action = \"buy\" if \"buy\" in k else \"sell\"\n",
    "#            if ev > 0:\n",
    "#                # transaction - action (b/s), type (y/n), price, quantity, ev\n",
    "#                \n",
    "#                #place_order({\n",
    "#                #    \"action\": action, \n",
    "#                #    \"type\": yes_or_no, \n",
    "#                #    \"price\": price,\n",
    "#                #    \"quantity\": quantity,\n",
    "#                #    \"ev\": ev,\n",
    "#                #    \"market_id\": market[\"id\"],\n",
    "#                #    \"contract_id\": c[\"id\"]\n",
    "#                #})\n",
    "#                if \"buy\" in k:\n",
    "#                    recommendation_buy(category, yes_or_no, ACCOUNT_BALANCE, ev, price, positions)\n",
    "#                else:\n",
    "#                    # is a sell\n",
    "#                    p = k.split('_')\n",
    "#                    bought_at = float(p[2])\n",
    "#                    quantity = float(p[3])\n",
    "#                    recommendation_sell(category, yes_or_no, ev, price, quantity, bought_at)\n",
    "    \n",
    "    category_stats = pd.DataFrame({ \"price_per_share\": [], \"proba\": [] })\n",
    "    for c in contracts:\n",
    "        s = pd.Series({ \"price_per_share\": c[\"bestBuyYesCost\"], \"proba\": proba[c[\"category\"]] })\n",
    "        s.name = c[\"category\"]\n",
    "        category_stats = category_stats.append(s)\n",
    "    alloc = kelly_criterion(category_stats)\n",
    "    print(alloc)\n",
    "    place_orders(market[\"id\"], contracts, alloc, ACCOUNT_BALANCE * .1)\n",
    "    \n",
    "    #outcomes(positions, [c[\"category\"] for c in contracts])\n",
    "\n",
    "def eval_trade_variations(contract, proba, category, positions):\n",
    "    proba_yes = proba[category]\n",
    "    \n",
    "    buy_yes = contract[\"bestBuyYesCost\"]\n",
    "    buy_no = contract[\"bestBuyNoCost\"]\n",
    "    sell_yes = contract[\"bestSellYesCost\"]\n",
    "    sell_no = contract[\"bestSellNoCost\"]\n",
    "    \n",
    "    if buy_yes and buy_no and 1 - buy_yes - buy_no > 0:\n",
    "            print(\"Arbitrage opportunity BUY:\", category, \"contract, \", buy_yes, buy_no)\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    if buy_yes:\n",
    "        d[\"buy_yes\"] = (expected_value(1-buy_yes, proba_yes, buy_yes, 1-proba_yes), buy_yes)\n",
    "        \n",
    "    if buy_no:\n",
    "        d[\"buy_no\"] = (expected_value(1-buy_no, 1-proba_yes, buy_no, proba_yes), buy_no)\n",
    "\n",
    "    if category in positions and \"yes\" in positions[category]:\n",
    "        yes_positions = positions[category][\"yes\"]\n",
    "        if not sell_yes:\n",
    "            # if there are no buyers on market, calculate EV of a sell at 99 cents so we may determine if we should list at all\n",
    "            sell_yes = .99\n",
    "        for pos in yes_positions:\n",
    "            strike_price = pos[0]\n",
    "            quantity = pos[1]\n",
    "            ev = (sell_yes - strike_price) - expected_value(1-strike_price, proba_yes, strike_price, 1-proba_yes)\n",
    "            key = \"sell_yes_\"+str(strike_price)+\"_\"+str(quantity)\n",
    "            d[key] = (ev, sell_yes)\n",
    "            \n",
    "    if category in positions and \"no\" in positions[category]:\n",
    "        no_positions = positions[category][\"no\"]\n",
    "        if not sell_no:\n",
    "            # if there are no buyers on market, calculate EV of a sell at 99 cents so we may determine if we should list at all\n",
    "            sell_no = .99\n",
    "        for pos in no_positions:\n",
    "            strike_price = pos[0]\n",
    "            quantity = pos[1]\n",
    "            ev = (sell_no - strike_price) - expected_value(1-strike_price, 1-proba_yes, strike_price, proba_yes)\n",
    "            key = \"sell_no_\"+str(strike_price)+\"_\"+str(quantity)\n",
    "            d[key] = (ev, sell_no)\n",
    "    return d\n",
    "\n",
    "def days_left(end_date, ts=None):\n",
    "    if not ts:\n",
    "        ts = datetime.datetime.now()\n",
    "    start_date = end_date - datetime.timedelta(days=7)\n",
    "    delta = ts - start_date\n",
    "    days_left = ((7*24) - (delta.total_seconds()/3600))/24\n",
    "    return max(round(days_left),1)\n",
    "                    \n",
    "def outcomes(positions, categories):\n",
    "    for c in categories:\n",
    "        total = 0\n",
    "        for pp in positions:\n",
    "            if pp == c:\n",
    "                if \"yes\" in positions[pp]:\n",
    "                    for x in positions[pp][\"yes\"]:\n",
    "                        total += (1 - x[0])*x[1]\n",
    "                if \"no\" in positions[pp]:\n",
    "                    for x in positions[pp][\"no\"]:\n",
    "                        total -= x[0]*x[1]\n",
    "            else:\n",
    "                if \"yes\" in positions[pp]:\n",
    "                    for x in positions[pp][\"yes\"]:\n",
    "                        total -= x[0]*x[1]\n",
    "                if \"no\" in positions[pp]:\n",
    "                    for x in positions[pp][\"no\"]:\n",
    "                        total += (1-x[0])*x[1]\n",
    "        print(c, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale EV by risk for final quantity recommendations (to reduce volatility)\n",
    "# take expected tweets for day of week into account given some people dont tweet much on weekends\n",
    "# graph of tweet density per time per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "markets = [\n",
    "    { \n",
    "        \"id\": 5457, \n",
    "        \"twitter_handle\": \"@vp\", \n",
    "        \"contract_map\": {\n",
    "            \"15263\": { \"range\": range(0, 20) }, \n",
    "            \"15267\": { \"range\": range(20, 25) }, \n",
    "            \"15266\": { \"range\": range(25, 30) }, \n",
    "            \"15268\": { \"range\": range(30, 35) },\n",
    "            \"15264\": { \"range\": range(35, 40) },\n",
    "            \"15269\": { \"range\": range(40, 45) },\n",
    "            \"15265\": { \"range\": range(45, 100) }\n",
    "        },\n",
    "        \"positions\":{ \n",
    "        }\n",
    "    },\n",
    "    { \n",
    "        \"id\": 5407, \n",
    "        \"twitter_handle\": \"@whitehouse\", \n",
    "        \"contract_map\": {\n",
    "            \"14983\": { \"range\": range(0, 80) }, \n",
    "            \"14985\": { \"range\": range(80, 85) }, \n",
    "            \"14984\": { \"range\": range(85, 90) },\n",
    "            \"14986\": { \"range\": range(90, 95) },\n",
    "            \"14987\": { \"range\": range(95, 100) },\n",
    "            \"14988\": { \"range\": range(100, 105) }, \n",
    "            \"14989\": { \"range\": range(105, 300) }\n",
    "        },\n",
    "        #\"contract_map\": [ (\"14983\", range(0, 80)), (\"14985\",range(80, 85)), (\"14984\", range(85, 90)), (\"14986\", range(90, 95)), (\"14987\",range(95, 100)), (\"14988\", range(100, 105)), (\"14989\",range(105, 300))],\n",
    "        \"positions\": { \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5404, \n",
    "        \"twitter_handle\": \"@realDonaldTrump\",\n",
    "        \"contract_map\": {\n",
    "            \"14968\": { \"range\": range(0, 60) }, \n",
    "            \"14963\": { \"range\": range(60, 65) }, \n",
    "            \"14967\": { \"range\": range(65, 70) },\n",
    "            \"14965\": { \"range\": range(70, 75) },\n",
    "            \"14964\": { \"range\": range(75, 80) },\n",
    "            \"14966\": { \"range\": range(80, 85) }, \n",
    "            \"14962\": { \"range\": range(85, 200) }\n",
    "        },\n",
    "        #\"contract_map\": [ (\"14968\", range(0, 60)), (\"14963\",range(60, 65)), (\"14967\", range(65, 70)), (\"14965\", range(70, 75)), (\"14964\",range(75, 80)), (\"14966\", range(80, 85)), (\"14962\",range(85, 200))],\n",
    "        \"positions\": {\n",
    "            #\"0-59\": {\n",
    "            #    \"yes\": [(.12, 11)]\n",
    "            #},\n",
    "            #\"60-64\": {\n",
    "            #    \"yes\": [(.11, 12)]\n",
    "            #},\n",
    "            #\"70-74\": {\n",
    "            #    \"yes\": [(.04, 20)]\n",
    "            #},\n",
    "            #\"80-84\": {\n",
    "            #    \"no\": [(.69, 4)]\n",
    "            #},\n",
    "            #\"85-199\": {\n",
    "            #    \"no\": [(.74, 4),(.64,1),(.54,1), (.34, 3)]\n",
    "            #}\n",
    "        }\n",
    "    },\n",
    "    { \n",
    "        \"id\": 5458, \n",
    "        \"twitter_handle\": \"@potus\", \n",
    "        \"contract_map\": {\n",
    "            \"15270\": { \"range\": range(0, 45) }, \n",
    "            \"15274\": { \"range\": range(45, 50) },\n",
    "            \"15275\": { \"range\": range(50, 55) },\n",
    "            \"15271\": { \"range\": range(55, 60) }, \n",
    "            \"15272\": { \"range\": range(60, 65) }, \n",
    "            \"15273\": { \"range\": range(65, 69) },\n",
    "            \"15276\": { \"range\": range(70, 200) }\n",
    "        },\n",
    "        \"positions\": {\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def eval_markets(show_market_research=False):\n",
    "    for market in markets:\n",
    "        eval_twitter_market(market, \"data/tweets/{handle}.csv\".format(handle=market[\"twitter_handle\"]), show_market_research=show_market_research)\n",
    "        print(\"----------------------------------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct = .005\n",
    "# 2 pct = .01\n",
    "# 4 pct = .02\n",
    "# 8 pct = .03\n",
    "def alloc(expected_value, proba): \n",
    "    pct_alloc = min( expected_value / 2, .03)\n",
    "    risk_adjusted = pct_alloc# * ??\n",
    "    return risk_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_orders(market_id, contracts, optimal_set, account_balance):\n",
    "    for contract in contracts:\n",
    "        category = contract[\"category\"]\n",
    "        price_per_share = contract[\"bestBuyYesCost\"]\n",
    "        current_quantity = current_alloc(market_id, contract[\"id\"])\n",
    "        \n",
    "        if category not in optimal_set.index:\n",
    "            # TODO: this doesnt take into consideration sell price, which in this market is usually less than buy price\n",
    "            # could sell at best buy price...\n",
    "            if current_quantity > 0:\n",
    "                place_order({\n",
    "                    \"action\": \"sell\",\n",
    "                    \"category\": category,\n",
    "                    \"type\": \"yes\", \n",
    "                    \"price_per_share\": price_per_share,\n",
    "                    \"quantity\": current_quantity,\n",
    "                    #\"ev\": \"unknown\",\n",
    "                    \"market_id\": market_id,\n",
    "                    \"contract_id\": contract[\"id\"]\n",
    "                })\n",
    "        else:\n",
    "            row = optimal_set.loc[category,:]\n",
    "            optimal_alloc = (row[\"pct_alloc\"] * account_balance)\n",
    "            optimal_quantity = round( abs(optimal_alloc / price_per_share) )\n",
    "            quantity = optimal_quantity - current_quantity\n",
    "\n",
    "            if quantity > 0:\n",
    "                place_order({\n",
    "                    \"action\": \"buy\", \n",
    "                    \"category\": category,\n",
    "                    \"type\": \"yes\", \n",
    "                    \"price_per_share\": price_per_share,\n",
    "                    \"quantity\": quantity,\n",
    "                    #\"ev\": row[\"proba\"] - row[\"price_per_share\"],\n",
    "                    \"market_id\": market_id,\n",
    "                    \"contract_id\": contract[\"id\"]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = psycopg2.connect(database=\"predictit\", host=\"localhost\", port=\"5432\")\n",
    "#conn = create_engine(\"postgresql+psycopg2://@localhost:5432/predictit\"\n",
    "db_string = \"postgresql+psycopg2://@localhost:5432/predictit\"\n",
    "def current_alloc(market_id, contract_id):\n",
    "    contract_orders = psql.read_sql(\"SELECT * from orders WHERE market_id = \\'{m_id}\\' AND contract_id = \\'{c_id}\\'\".format(m_id=market_id, c_id=contract_id), db_string)\n",
    "\n",
    "    quantity = 0\n",
    "    for i,o in contract_orders.iterrows():\n",
    "        multiplier = -1 if o[\"action\"] == \"sell\" else 1\n",
    "        quantity += o[\"quantity\"] * multiplier\n",
    "    return quantity\n",
    "\n",
    "def place_order(order, verbose=True):\n",
    "    df = pd.Series(order).to_frame().transpose()\n",
    "    print(df)\n",
    "    df.to_sql('orders', con=db_string, if_exists='append', index=False)\n",
    "    if verbose:\n",
    "        print(order)\n",
    "        \n",
    "def record_timepoint(market_id=5458):\n",
    "    data = fetch_market_data(market_id)\n",
    "    twitter_handle = re.match(r\".*@(\\w{1,15})\",data[\"shortName\"]).group(0).split(' ')[-1]\n",
    "    df = pd.Series({ \"timestamp\": data[\"timeStamp\"], \"market_id\": data[\"id\"], \"handle\": twitter_handle, \"data\": json.dumps(data) }).to_frame().transpose()\n",
    "    df.to_sql('market_data', con=db_string, if_exists='append', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_timepoint(market_id=5478)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>expected_revenue_rate</th>\n",
       "      <th>price_per_share</th>\n",
       "      <th>proba</th>\n",
       "      <th>pct_alloc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beta  expected_revenue_rate  price_per_share  proba  pct_alloc\n",
       "1   0.1                   2.70              0.1    0.3        0.4\n",
       "2   0.2                   1.35              0.2    0.3        0.5\n",
       "3   0.4                   1.35              0.4    0.6        1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bought_at: .10\n",
    "# EV: .70\n",
    "# price: .75\n",
    "# SELL (not in optimal set)\n",
    "\n",
    "# bought_at: .10\n",
    "# EV: .70\n",
    "# price: .50\n",
    "# BUY (but would have more shares than recommended)\n",
    "\n",
    "# bought_at: .10 \n",
    "# EV: .70\n",
    "# price: .05\n",
    "# BUY (difference over current alloc)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: .70\n",
    "# price: .75\n",
    "# SELL (not in optimal set)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: .70\n",
    "# price: .50\n",
    "# BUY (likely allocation is less than what you have, in which case you sell)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: -.10\n",
    "# price: .50\n",
    "#\n",
    "\n",
    "market = { \n",
    "    \"id\": 5411, \n",
    "    \"twitter_handle\": \"@potus\", \n",
    "    \"contract_map\": [ (\"15008\", range(0, 35)), (\"15010\",range(35, 40)), (\"15011\", range(40, 45)), (\"15012\", range(45, 50)), (\"15013\",range(50, 55)), (\"15009\", range(55, 60)), (\"15014\",range(60, 200))]\n",
    "}\n",
    "df = pd.DataFrame({ \"price_per_share\": [.2, .51, .40, .01, .10], \"proba\": [.30, .10, .60, .02, .7] }, index=[\"0-59\", \"60-64\", \"65-69\", \"70-71\", \"test\"])\n",
    "df = pd.DataFrame({ \"price_per_share\": [.10, .2, .40], \"proba\": [.3, .30, .60] }, index=[\"1\", \"2\", \"3\"])\n",
    "alloc = kelly_criterion(df)\n",
    "alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@vp tweets noon 4/26 - noon 5/3?\n",
      "Days left: 1\n",
      "Matching tweets: 57\n",
      "Category probabilities:\n",
      "45-99    1.0\n",
      "0-19     0.0\n",
      "35-39    0.0\n",
      "25-29    0.0\n",
      "20-24    0.0\n",
      "30-34    0.0\n",
      "40-44    0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@whitehouse tweets 4/4 - 4/11?\n",
      "Days left: 1\n",
      "Matching tweets: 200\n",
      "Category probabilities:\n",
      "105-299    1.0\n",
      "0-79       0.0\n",
      "85-89      0.0\n",
      "80-84      0.0\n",
      "90-94      0.0\n",
      "95-99      0.0\n",
      "100-104    0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@realDonaldTrump tweets 4/3 - 4/10?\n",
      "Days left: 1\n",
      "Matching tweets: 199\n",
      "Category probabilities:\n",
      "85-199    1.0\n",
      "60-64     0.0\n",
      "75-79     0.0\n",
      "70-74     0.0\n",
      "80-84     0.0\n",
      "65-69     0.0\n",
      "0-59      0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@potus tweets noon 4/26 - noon 5/3?\n",
      "Days left: 1\n",
      "Matching tweets: 59\n",
      "Category probabilities:\n",
      "55-59     0.021277\n",
      "0-44      0.000000\n",
      "60-64     0.234043\n",
      "65-68     0.191489\n",
      "45-49     0.000000\n",
      "50-54     0.000000\n",
      "70-199    0.553191\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_markets(show_market_research=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_market(market):\n",
    "    historical_data = psql.read_sql(\"SELECT * from market_data WHERE handle = \\'{handle}\\'\".format(handle=market[\"twitter_handle\"]), db_string)\n",
    "    path = \"data/tweets/{handle}.csv\".format(handle=market[\"twitter_handle\"])\n",
    "    for i, data_point in historical_data.iterrows():\n",
    "        ts = parser.parse(data_point[\"timestamp\"])\n",
    "        eval_twitter_market(market, path, data=json.loads(data_point[\"data\"]), ts=ts, show_market_research=False)\n",
    "\n",
    "def simulate_markets():\n",
    "    for m in markets:\n",
    "        simulate_market(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "timezone = pytz.timezone(\"US/Eastern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 5, 3, 22, 40, 1, 414530, tzinfo=<DstTzInfo 'US/Eastern' EDT-1 day, 20:00:00 DST>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utc_now = pytz.utc.localize(datetime.datetime.utcnow())\n",
    "est_now = utc_now.astimezone(pytz.timezone(\"US/Eastern\"))\n",
    "est_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 5, 4, 2, 40, 37, 473190, tzinfo=<UTC>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytz.utc.localize(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 5, 4, 2, 41, 13, 627652, tzinfo=<DstTzInfo 'US/Eastern' EDT-1 day, 20:00:00 DST>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timezone.localize(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
