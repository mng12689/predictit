{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import os\n",
    "import dateutil\n",
    "import time\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas.io.sql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical data\n",
    "import calendar\n",
    "\n",
    "def next_weekday(d, weekday):\n",
    "    days_ahead = weekday - d.weekday()\n",
    "    if days_ahead < 0: # Target day already happened this week\n",
    "        days_ahead += 7\n",
    "    return d + datetime.timedelta(days_ahead)\n",
    "\n",
    "def bucketed(df, start_on=\"Sunday\"):\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    \n",
    "    df['created_at'] = pd.to_datetime(df['created_at']).dt.date\n",
    "    min_date = df[\"created_at\"].min()\n",
    "    min_date = next_weekday(min_date, list(calendar.day_name).index(start_on))\n",
    "    max_date = df[\"created_at\"].max()\n",
    "    tweet_counts = df.groupby('created_at').agg('count')[\"text\"]\n",
    "    dates = pd.date_range(min_date, max_date, freq='D')\n",
    "    counts = pd.DataFrame({ \"count\": tweet_counts},index=dates).fillna(0)\n",
    "    counts = counts.resample('7D').sum()\n",
    "    return counts.drop(counts.tail(1).index) # drop last row in case its a count over less than the full time bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_BALANCE = 58\n",
    "N_TWEETS = 0\n",
    "\n",
    "BEARER_TOKEN=\"AAAAAAAAAAAAAAAAAAAAAAXT9gAAAAAAoITLBCf%2B2K7BMSqakqcbsHUSLrk%3DLz95o8CkkhjOTthpcyEEg6BdNav0zphRcrEYdeG4GXXV3Qkftk\"\n",
    "\n",
    "## value functions\n",
    "def expected_value(potential_win, chance_win, potential_loss, chance_loss):\n",
    "    return (potential_win * chance_win) - (potential_loss * chance_loss)\n",
    "\n",
    "def allocation(account_balance, expected_value):\n",
    "    pct_alloc = min(( expected_value * 5 ) / 10, .03)\n",
    "    alloc = account_balance * pct_alloc\n",
    "    #risk_coef = 1 - (1 / (proba * 100) )\n",
    "    #risk_adjusted = alloc * risk_coef\n",
    "    #return risk_adjusted\n",
    "    return alloc\n",
    "def allocation(price_per_share, proba):\n",
    "    payoff_odds = (1 / price_per_share) - 1\n",
    "\n",
    "def recommended_shares(account_balance, expected_value, price_per_share):\n",
    "    return allocation(account_balance, expected_value) / price_per_share;\n",
    "\n",
    "def to_proba(buckets, categories=None):\n",
    "    vals = buckets.value_counts()\n",
    "    # [ (range(0,2), \"0-2\"), range(3-5), \"3-5\" ]\n",
    "    #for c in categories:\n",
    "    #    rnge = c[0]\n",
    "    #    id_str = c[1]\n",
    "    #    for r in range:\n",
    "            \n",
    "    s = vals.sum()\n",
    "    return vals/s\n",
    "\n",
    "## portfolio management\n",
    "TAX_RATE = .1\n",
    "def kelly_criterion(outcomes):\n",
    "    # category, price_per_share, proba\n",
    "    er = []\n",
    "    betas = []\n",
    "    for index, o in outcomes.iterrows():\n",
    "        payoff_odds = (1 / o[\"price_per_share\"]) - 1\n",
    "        beta = 1 / (1 + payoff_odds)\n",
    "        dividend_rate = 1 - TAX_RATE\n",
    "        expected_revenue_rate = (dividend_rate / beta) * o[\"proba\"]\n",
    "        er.append(expected_revenue_rate)\n",
    "        betas.append(beta)\n",
    "        \n",
    "    outcomes[\"expected_revenue_rate\"] = er\n",
    "    outcomes[\"beta\"] = betas\n",
    "    outcomes = outcomes.sort_values(\"expected_revenue_rate\", ascending=False)\n",
    "    \n",
    "    reserve_rate = 1\n",
    "    optimal_set = pd.DataFrame()\n",
    "    for index, o in outcomes.iterrows():\n",
    "        if o[\"expected_revenue_rate\"] > reserve_rate:\n",
    "            optimal_set = optimal_set.append(o)\n",
    "            reserve_rate = (1 - optimal_set[\"proba\"].sum()) / (1 - (optimal_set[\"beta\"] / dividend_rate).sum())\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    pct_alloc = [] \n",
    "    for index, o in optimal_set.iterrows():\n",
    "        pct = (o[\"expected_revenue_rate\"] - reserve_rate) / ( dividend_rate / o[\"beta\"] )\n",
    "        pct_alloc.append(pct)\n",
    "    optimal_set[\"pct_alloc\"] = pct_alloc\n",
    "    return optimal_set\n",
    "\n",
    "def shares_bought(c, yes_or_no, positions):\n",
    "    bought = 0\n",
    "    if c in positions and yes_or_no in positions[c]:\n",
    "        for pos in positions[c][yes_or_no]:\n",
    "            bought += pos[1]\n",
    "    return bought\n",
    "\n",
    "def recommendation_buy(contract, yes_or_no, account_balance, expected_value, price_per_share, positions):\n",
    "    shares = recommended_shares(account_balance, expected_value, price_per_share) - shares_bought(contract, yes_or_no, positions)\n",
    "    shares = int(round(shares))\n",
    "    if shares > 0:\n",
    "        print(\"BUY {yn} shares for contract {n}: {shares} shares @{price} (EV: {ev}, TOTAL: {t})\".format(n=contract,shares=shares, price=price_per_share, ev=expected_value, yn=yes_or_no.upper(), t=shares*price_per_share))\n",
    "\n",
    "def recommendation_sell(contract, yes_or_no, expected_value, price_per_share, n_shares, bought_at):\n",
    "    print(\"SELL {yn} shares for contract {n}_{bought_at}_{n_shares}: ALL shares @{price} (EV: {ev}, TOTAL: {t})\".format(n=contract, price=price_per_share, ev=expected_value, yn=yes_or_no.upper(), t=n_shares*price_per_share, bought_at=bought_at, n_shares=n_shares))\n",
    "    \n",
    "## market evaluation\n",
    "def fetch_market_data(market_id):\n",
    "    url = \"https://www.predictit.org/api/marketdata/markets/{id}\".format(id=market_id)\n",
    "    r = requests.get(url=url)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_twitter_user_timeline(screen_name, max_id=None, since_id=None):\n",
    "    url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n",
    "    headers = { \"Authorization\": \"Bearer {t}\".format(t=BEARER_TOKEN)}\n",
    "    params = {\n",
    "        \"count\": \"200\",\n",
    "        \"trim_user\": \"true\",\n",
    "        \"screen_name\": screen_name\n",
    "    }\n",
    "    if max_id: \n",
    "        params[\"max_id\"] = max_id\n",
    "    if since_id:\n",
    "        params[\"since_id\"] = since_id\n",
    "        \n",
    "    r = requests.get(url=url,headers=headers, params=params)\n",
    "    raw = r.json()\n",
    "    transformed = json.dumps([ { \"id\": tweet[\"id\"], \"created_at\": tweet[\"created_at\"], \"text\": tweet[\"text\"] } for tweet in raw])\n",
    "    return pd.read_json(transformed, orient=\"records\")\n",
    "\n",
    "def get_recent_tweets(screen_name, from_date=None):\n",
    "    df = get_twitter_user_timeline(screen_name)\n",
    "    df[\"created_at\"] = df[\"created_at\"].dt.tz_localize('UTC').dt.tz_convert('US/Eastern')\n",
    "    if from_date:\n",
    "        df = df[df[\"created_at\"] > from_date]\n",
    "    return df\n",
    "    \n",
    "# the twitter api returns different results for the same request...\n",
    "def _get_twitter_history(screen_name, max_id=None):\n",
    "    get_next = True\n",
    "    df = pd.DataFrame(columns=[\"id\",\"created_at\", \"text\"])\n",
    "    while get_next:\n",
    "        tweets = get_twitter_user_timeline(screen_name, max_id)\n",
    "        print(len(tweets.index))\n",
    "        if len(tweets.index) > 0:\n",
    "            df = tweets if df.empty else pd.concat([df, tweets], axis=0)\n",
    "            last_row = tweets.tail(1).iloc[0]\n",
    "            max_id = last_row[\"id\"] - 1\n",
    "        else:\n",
    "            get_next = False\n",
    "    return df\n",
    "\n",
    "def get_twitter_history(screen_name, cache=True):\n",
    "    fname = \"data/tweets/{sn}.csv\".format(sn=screen_name)\n",
    "    max_id = None\n",
    "    if cache and os.path.isfile(fname):\n",
    "        df = pd.read_csv(fname)\n",
    "        max_id = int(df.tail(1).iloc[0][\"id\"]) -1\n",
    "    df = _get_twitter_history(screen_name, max_id);\n",
    "    if not os.path.isdir(\"data/tweets\"):\n",
    "        os.mkdir(\"data/tweets\")\n",
    "    if len(df) > 0:\n",
    "        df.to_csv(fname, mode='a')\n",
    "\n",
    "def fetch_full_trump_tweet_history(rnge, cache=True):\n",
    "    fname = \"data/tweets/@realDonaldTrump.csv\"\n",
    "    df = None\n",
    "    for year in rnge:\n",
    "        url = None\n",
    "        if year == 2019:\n",
    "            url = \"http://www.trumptwitterarchive.com/data/realdonaldtrump/2019.json\"\n",
    "        else:\n",
    "            url = \"http://d5nxcu7vtzvay.cloudfront.net/data/realdonaldtrump/{y}.json\".format(y=str(year))\n",
    "        _df  = pd.read_json(url)\n",
    "        if df is None:\n",
    "            df = _df\n",
    "        else:\n",
    "            df = pd.concat([df,_df])\n",
    "        time.sleep(1)\n",
    "     \n",
    "    if not os.path.isdir(\"data/tweets\"):\n",
    "        os.mkdir(\"data/tweets\")\n",
    "    if len(df) > 0:\n",
    "        df.to_csv(fname, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\"homieng6@gmail.com\"\n",
    "#\"??\"\n",
    "#\"@homiesaccount\"\n",
    "#\"nY7VUVqcxJ4vmcX\"\n",
    "#\"AAAAAAAAAAAAAAAAAAAAAAXT9gAAAAAAoITLBCf%2B2K7BMSqakqcbsHUSLrk%3DLz95o8CkkhjOTthpcyEEg6BdNav0zphRcrEYdeG4GXXV3Qkft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweet_distributions_per_day(source_df):\n",
    "    df = pd.DataFrame(columns=[\"proba\",\"day\"])\n",
    "    df.index.name = \"n_tweets\"\n",
    "    for x in range(0,7,1):\n",
    "        weekday = calendar.day_name[x]\n",
    "        b = bucketed(source_df, start_on=weekday)\n",
    "        proba = b['count']/b['count'].sum()\n",
    "        _df = pd.DataFrame({ \"proba\": proba.values, \"day\": x }, index=proba.index)\n",
    "        df = pd.concat([df, _df])\n",
    "        df[\"n_tweets\"] = df.index\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    for key, _grp in df.groupby(['n_tweets']):\n",
    "        grp = _grp.sort_values(by=\"day\", ascending=False)\n",
    "        ax = grp.plot(ax=ax, kind='line', x=\"day\", y='proba', label=str(grp[\"n_tweets\"].iloc[0]))\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "#_df = pd.read_csv('./data/fake_news_tweets.csv')\n",
    "#plot_tweet_distributions_per_day(_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_twitter_market_research(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # number of tweets per week\n",
    "    b=bucketed(df)\n",
    "    b.plot(title=\"Tweets per Week\")\n",
    "    plt.show()\n",
    "    \n",
    "    # distribution of tweets per week\n",
    "    vals = b[\"count\"].value_counts()\n",
    "    bins = vals.size\n",
    "    b[\"count\"].plot(kind=\"hist\",bins=bins, title=\"Tweets per Week Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "    # freq of tweets per day\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    \n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    df['day_of_week'].value_counts().reindex(weekdays).plot(kind='bar', title=\"Tweets per Calendar Day\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_range_str(range):\n",
    "    return str(range.start) + \"-\" + str(range.stop-1)\n",
    "\n",
    "def append_count(series, count, category_range):\n",
    "    return series.append(pd.Series([ count ], index=[ to_range_str(category_range) ]))\n",
    "\n",
    "# takes dataframe with tweet counts bucketed per n days\n",
    "# returns a data frame that returns counts for a category based, excluding coun\n",
    "# this answers: what is the probability that we end in a category, given that we have already seen curr_n values\n",
    "def count_adjusted(df, categories, curr_n):\n",
    "    grouped = pd.Series()\n",
    "    for rnge in categories:\n",
    "        adjusted_range = range(max(rnge.start-curr_n, 0), max(rnge.stop-curr_n, 0 ))\n",
    "        count = df[df[\"count\"].between(adjusted_range.start, adjusted_range.stop-1)].shape[0]\n",
    "        grouped = append_count(grouped, count, rnge)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_twitter_market(market, path, data=None, ts=None, show_market_research=False):\n",
    "    if show_market_research:\n",
    "        show_twitter_market_research(path)\n",
    "        \n",
    "    if data is None:\n",
    "        data = fetch_market_data(market[\"id\"])\n",
    "        \n",
    "    contracts = data[\"contracts\"]\n",
    "    for c in contracts:\n",
    "        c_id = str(c[\"id\"])\n",
    "        annotations = market[\"contract_map\"][c_id]\n",
    "        c[\"range\"] = annotations[\"range\"]\n",
    "        c[\"category\"] = to_range_str(c[\"range\"])\n",
    "    print(data[\"shortName\"])\n",
    "    \n",
    "    end_date_str = contracts[0][\"dateEnd\"]\n",
    "    end_date = parser.parse(end_date_str)\n",
    "    start_date = end_date - datetime.timedelta(days=7)\n",
    "    n_days = days_left(end_date, ts)\n",
    "    print(\"Days left:\", n_days)\n",
    "    \n",
    "    timezone = pytz.timezone(\"US/Eastern\")\n",
    "    from_date = timezone.localize(start_date)\n",
    "    recent = get_recent_tweets(market[\"twitter_handle\"], from_date=from_date)\n",
    "    if ( \"filter\" in market.keys() ):\n",
    "        recent = recent[recent[\"text\"].str.contains(market[\"filter\"],case=False)]\n",
    "        #n_matching_tweets = len(recent[recent[\"text\"].str.contains(\"fake news|fakenews\",case=False)])\n",
    "    n_matching_tweets = len(recent)\n",
    "    print(\"Matching tweets:\", n_matching_tweets)\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df['day_of_week'] = pd.to_datetime(df['created_at']).dt.day_name()\n",
    "    weekdays = calendar.day_name\n",
    "    timezone = pytz.timezone(\"US/Eastern\")\n",
    "    from_date = timezone.localize(datetime.datetime.now())\n",
    "    circular_weekdays = np.tile(weekdays, 2)\n",
    "    idx = np.where(circular_weekdays == from_date.strftime(\"%A\"))[0][0]\n",
    "    weekdays_left = circular_weekdays[idx:idx+n_days]\n",
    "    \n",
    "    df = df[df[\"day_of_week\"].isin(weekdays_left)]   \n",
    "    b=bucketed(df, start_on=weekdays[idx])\n",
    "    c=count_adjusted(b, [c[\"range\"] for c in contracts], n_matching_tweets )\n",
    "    proba = c/c.sum()\n",
    "    print(\"Category probabilities:\")\n",
    "    pprint.pprint(proba)\n",
    "    \n",
    "#    for c in contracts: \n",
    "#        #print(\"Contract\", c[\"name\"])\n",
    "#        category = c[\"category\"]\n",
    "#        expected_values = eval_trade_variations(c, proba, category, positions)\n",
    "#        #print(json.dumps(expected_values, indent=4))\n",
    "#        for k, v in expected_values.items():\n",
    "#            ev = v[0]\n",
    "#            price = v[1]\n",
    "#            yes_or_no = \"yes\" if \"yes\" in k else \"no\"\n",
    "#            action = \"buy\" if \"buy\" in k else \"sell\"\n",
    "#            if ev > 0:\n",
    "#                # transaction - action (b/s), type (y/n), price, quantity, ev\n",
    "#                \n",
    "#                #place_order({\n",
    "#                #    \"action\": action, \n",
    "#                #    \"type\": yes_or_no, \n",
    "#                #    \"price\": price,\n",
    "#                #    \"quantity\": quantity,\n",
    "#                #    \"ev\": ev,\n",
    "#                #    \"market_id\": market[\"id\"],\n",
    "#                #    \"contract_id\": c[\"id\"]\n",
    "#                #})\n",
    "#                if \"buy\" in k:\n",
    "#                    recommendation_buy(category, yes_or_no, ACCOUNT_BALANCE, ev, price, positions)\n",
    "#                else:\n",
    "#                    # is a sell\n",
    "#                    p = k.split('_')\n",
    "#                    bought_at = float(p[2])\n",
    "#                    quantity = float(p[3])\n",
    "#                    recommendation_sell(category, yes_or_no, ev, price, quantity, bought_at)\n",
    "    \n",
    "    category_stats = pd.DataFrame({ \"price_per_share\": [], \"proba\": [] })\n",
    "    for c in contracts:\n",
    "        s = pd.Series({ \"price_per_share\": c[\"bestBuyYesCost\"], \"proba\": proba[c[\"category\"]] })\n",
    "        s.name = c[\"category\"]\n",
    "        category_stats = category_stats.append(s)\n",
    "    alloc = kelly_criterion(category_stats)\n",
    "    print(alloc)\n",
    "    place_orders(market[\"id\"], contracts, alloc, ACCOUNT_BALANCE * .1)\n",
    "    \n",
    "    #outcomes(positions, [c[\"category\"] for c in contracts])\n",
    "\n",
    "def eval_trade_variations(contract, proba, category, positions):\n",
    "    proba_yes = proba[category]\n",
    "    \n",
    "    buy_yes = contract[\"bestBuyYesCost\"]\n",
    "    buy_no = contract[\"bestBuyNoCost\"]\n",
    "    sell_yes = contract[\"bestSellYesCost\"]\n",
    "    sell_no = contract[\"bestSellNoCost\"]\n",
    "    \n",
    "    if buy_yes and buy_no and 1 - buy_yes - buy_no > 0:\n",
    "            print(\"Arbitrage opportunity BUY:\", category, \"contract, \", buy_yes, buy_no)\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    if buy_yes:\n",
    "        d[\"buy_yes\"] = (expected_value(1-buy_yes, proba_yes, buy_yes, 1-proba_yes), buy_yes)\n",
    "        \n",
    "    if buy_no:\n",
    "        d[\"buy_no\"] = (expected_value(1-buy_no, 1-proba_yes, buy_no, proba_yes), buy_no)\n",
    "\n",
    "    if category in positions and \"yes\" in positions[category]:\n",
    "        yes_positions = positions[category][\"yes\"]\n",
    "        if not sell_yes:\n",
    "            # if there are no buyers on market, calculate EV of a sell at 99 cents so we may determine if we should list at all\n",
    "            sell_yes = .99\n",
    "        for pos in yes_positions:\n",
    "            strike_price = pos[0]\n",
    "            quantity = pos[1]\n",
    "            ev = (sell_yes - strike_price) - expected_value(1-strike_price, proba_yes, strike_price, 1-proba_yes)\n",
    "            key = \"sell_yes_\"+str(strike_price)+\"_\"+str(quantity)\n",
    "            d[key] = (ev, sell_yes)\n",
    "            \n",
    "    if category in positions and \"no\" in positions[category]:\n",
    "        no_positions = positions[category][\"no\"]\n",
    "        if not sell_no:\n",
    "            # if there are no buyers on market, calculate EV of a sell at 99 cents so we may determine if we should list at all\n",
    "            sell_no = .99\n",
    "        for pos in no_positions:\n",
    "            strike_price = pos[0]\n",
    "            quantity = pos[1]\n",
    "            ev = (sell_no - strike_price) - expected_value(1-strike_price, 1-proba_yes, strike_price, proba_yes)\n",
    "            key = \"sell_no_\"+str(strike_price)+\"_\"+str(quantity)\n",
    "            d[key] = (ev, sell_no)\n",
    "    return d\n",
    "\n",
    "def days_left(end_date, ts=None):\n",
    "    if not ts:\n",
    "        ts = datetime.datetime.now()\n",
    "    start_date = end_date - datetime.timedelta(days=7)\n",
    "    delta = ts - start_date\n",
    "    days_left = ((7*24) - (delta.total_seconds()/3600))/24\n",
    "    return max(round(days_left),1)\n",
    "                    \n",
    "def outcomes(positions, categories):\n",
    "    for c in categories:\n",
    "        total = 0\n",
    "        for pp in positions:\n",
    "            if pp == c:\n",
    "                if \"yes\" in positions[pp]:\n",
    "                    for x in positions[pp][\"yes\"]:\n",
    "                        total += (1 - x[0])*x[1]\n",
    "                if \"no\" in positions[pp]:\n",
    "                    for x in positions[pp][\"no\"]:\n",
    "                        total -= x[0]*x[1]\n",
    "            else:\n",
    "                if \"yes\" in positions[pp]:\n",
    "                    for x in positions[pp][\"yes\"]:\n",
    "                        total -= x[0]*x[1]\n",
    "                if \"no\" in positions[pp]:\n",
    "                    for x in positions[pp][\"no\"]:\n",
    "                        total += (1-x[0])*x[1]\n",
    "        print(c, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale EV by risk for final quantity recommendations (to reduce volatility)\n",
    "# take expected tweets for day of week into account given some people dont tweet much on weekends\n",
    "# graph of tweet density per time per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "markets = [\n",
    "    { \n",
    "        \"id\": 5457, \n",
    "        \"twitter_handle\": \"@vp\", \n",
    "        \"contract_map\": {\n",
    "            \"15263\": { \"range\": range(0, 20) }, \n",
    "            \"15267\": { \"range\": range(20, 25) }, \n",
    "            \"15266\": { \"range\": range(25, 30) }, \n",
    "            \"15268\": { \"range\": range(30, 35) },\n",
    "            \"15264\": { \"range\": range(35, 40) },\n",
    "            \"15269\": { \"range\": range(40, 45) },\n",
    "            \"15265\": { \"range\": range(45, 100) }\n",
    "        },\n",
    "        \"positions\":{ \n",
    "        }\n",
    "    },\n",
    "    { \n",
    "        \"id\": 5407, \n",
    "        \"twitter_handle\": \"@whitehouse\", \n",
    "        \"contract_map\": {\n",
    "            \"14983\": { \"range\": range(0, 80) }, \n",
    "            \"14985\": { \"range\": range(80, 85) }, \n",
    "            \"14984\": { \"range\": range(85, 90) },\n",
    "            \"14986\": { \"range\": range(90, 95) },\n",
    "            \"14987\": { \"range\": range(95, 100) },\n",
    "            \"14988\": { \"range\": range(100, 105) }, \n",
    "            \"14989\": { \"range\": range(105, 300) }\n",
    "        },\n",
    "        #\"contract_map\": [ (\"14983\", range(0, 80)), (\"14985\",range(80, 85)), (\"14984\", range(85, 90)), (\"14986\", range(90, 95)), (\"14987\",range(95, 100)), (\"14988\", range(100, 105)), (\"14989\",range(105, 300))],\n",
    "        \"positions\": { \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5404, \n",
    "        \"twitter_handle\": \"@realDonaldTrump\",\n",
    "        \"contract_map\": {\n",
    "            \"14968\": { \"range\": range(0, 60) }, \n",
    "            \"14963\": { \"range\": range(60, 65) }, \n",
    "            \"14967\": { \"range\": range(65, 70) },\n",
    "            \"14965\": { \"range\": range(70, 75) },\n",
    "            \"14964\": { \"range\": range(75, 80) },\n",
    "            \"14966\": { \"range\": range(80, 85) }, \n",
    "            \"14962\": { \"range\": range(85, 200) }\n",
    "        },\n",
    "        #\"contract_map\": [ (\"14968\", range(0, 60)), (\"14963\",range(60, 65)), (\"14967\", range(65, 70)), (\"14965\", range(70, 75)), (\"14964\",range(75, 80)), (\"14966\", range(80, 85)), (\"14962\",range(85, 200))],\n",
    "        \"positions\": {\n",
    "            #\"0-59\": {\n",
    "            #    \"yes\": [(.12, 11)]\n",
    "            #},\n",
    "            #\"60-64\": {\n",
    "            #    \"yes\": [(.11, 12)]\n",
    "            #},\n",
    "            #\"70-74\": {\n",
    "            #    \"yes\": [(.04, 20)]\n",
    "            #},\n",
    "            #\"80-84\": {\n",
    "            #    \"no\": [(.69, 4)]\n",
    "            #},\n",
    "            #\"85-199\": {\n",
    "            #    \"no\": [(.74, 4),(.64,1),(.54,1), (.34, 3)]\n",
    "            #}\n",
    "        }\n",
    "    },\n",
    "    { \n",
    "        \"id\": 5458, \n",
    "        \"twitter_handle\": \"@potus\", \n",
    "        \"contract_map\": {\n",
    "            \"15270\": { \"range\": range(0, 45) }, \n",
    "            \"15274\": { \"range\": range(45, 50) },\n",
    "            \"15275\": { \"range\": range(50, 55) },\n",
    "            \"15271\": { \"range\": range(55, 60) }, \n",
    "            \"15272\": { \"range\": range(60, 65) }, \n",
    "            \"15273\": { \"range\": range(65, 69) },\n",
    "            \"15276\": { \"range\": range(70, 200) }\n",
    "        },\n",
    "        \"positions\": {\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def eval_markets(show_market_research=False):\n",
    "    for market in markets:\n",
    "        eval_twitter_market(market, \"data/tweets/{handle}.csv\".format(handle=market[\"twitter_handle\"]), show_market_research=show_market_research)\n",
    "        print(\"----------------------------------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 pct = .005\n",
    "# 2 pct = .01\n",
    "# 4 pct = .02\n",
    "# 8 pct = .03\n",
    "def alloc(expected_value, proba): \n",
    "    pct_alloc = min( expected_value / 2, .03)\n",
    "    risk_adjusted = pct_alloc# * ??\n",
    "    return risk_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_orders(market_id, contracts, optimal_set, account_balance):\n",
    "    for contract in contracts:\n",
    "        category = contract[\"category\"]\n",
    "        price_per_share = contract[\"bestBuyYesCost\"]\n",
    "        current_quantity = current_alloc(market_id, contract[\"id\"])\n",
    "        \n",
    "        if category not in optimal_set.index:\n",
    "            # TODO: this doesnt take into consideration sell price, which in this market is usually less than buy price\n",
    "            # could sell at best buy price...\n",
    "            if current_quantity > 0:\n",
    "                place_order({\n",
    "                    \"action\": \"sell\",\n",
    "                    \"category\": category,\n",
    "                    \"type\": \"yes\", \n",
    "                    \"price_per_share\": price_per_share,\n",
    "                    \"quantity\": current_quantity,\n",
    "                    #\"ev\": \"unknown\",\n",
    "                    \"market_id\": market_id,\n",
    "                    \"contract_id\": contract[\"id\"]\n",
    "                })\n",
    "        else:\n",
    "            row = optimal_set.loc[category,:]\n",
    "            optimal_alloc = (row[\"pct_alloc\"] * account_balance)\n",
    "            optimal_quantity = round( abs(optimal_alloc / price_per_share) )\n",
    "            quantity = optimal_quantity - current_quantity\n",
    "\n",
    "            if quantity > 0:\n",
    "                place_order({\n",
    "                    \"action\": \"buy\", \n",
    "                    \"category\": category,\n",
    "                    \"type\": \"yes\", \n",
    "                    \"price_per_share\": price_per_share,\n",
    "                    \"quantity\": quantity,\n",
    "                    #\"ev\": row[\"proba\"] - row[\"price_per_share\"],\n",
    "                    \"market_id\": market_id,\n",
    "                    \"contract_id\": contract[\"id\"]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = psycopg2.connect(database=\"predictit\", host=\"localhost\", port=\"5432\")\n",
    "#conn = create_engine(\"postgresql+psycopg2://@localhost:5432/predictit\"\n",
    "db_string = \"postgresql+psycopg2://@localhost:5432/predictit\"\n",
    "def current_alloc(market_id, contract_id):\n",
    "    contract_orders = psql.read_sql(\"SELECT * from orders WHERE market_id = \\'{m_id}\\' AND contract_id = \\'{c_id}\\'\".format(m_id=market_id, c_id=contract_id), db_string)\n",
    "\n",
    "    quantity = 0\n",
    "    for i,o in contract_orders.iterrows():\n",
    "        multiplier = -1 if o[\"action\"] == \"sell\" else 1\n",
    "        quantity += o[\"quantity\"] * multiplier\n",
    "    return quantity\n",
    "\n",
    "def place_order(order, verbose=True):\n",
    "    df = pd.Series(order).to_frame().transpose()\n",
    "    print(df)\n",
    "    df.to_sql('orders', con=db_string, if_exists='append', index=False)\n",
    "    if verbose:\n",
    "        print(order)\n",
    "        \n",
    "def record_timepoint(market_id=5458):\n",
    "    data = fetch_market_data(market_id)\n",
    "    twitter_handle = re.match(r\".*@(\\w{1,15})\",data[\"shortName\"]).group(0).split(' ')[-1]\n",
    "    df = pd.Series({ \"timestamp\": data[\"timeStamp\"], \"market_id\": data[\"id\"], \"handle\": twitter_handle, \"data\": json.dumps(data) }).to_frame().transpose()\n",
    "    df.to_sql('market_data', con=db_string, if_exists='append', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta</th>\n",
       "      <th>expected_revenue_rate</th>\n",
       "      <th>price_per_share</th>\n",
       "      <th>proba</th>\n",
       "      <th>pct_alloc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beta  expected_revenue_rate  price_per_share  proba  pct_alloc\n",
       "1   0.1                   2.70              0.1    0.3        0.4\n",
       "2   0.2                   1.35              0.2    0.3        0.5\n",
       "3   0.4                   1.35              0.4    0.6        1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bought_at: .10\n",
    "# EV: .70\n",
    "# price: .75\n",
    "# SELL (not in optimal set)\n",
    "\n",
    "# bought_at: .10\n",
    "# EV: .70\n",
    "# price: .50\n",
    "# BUY (but would have more shares than recommended)\n",
    "\n",
    "# bought_at: .10 \n",
    "# EV: .70\n",
    "# price: .05\n",
    "# BUY (difference over current alloc)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: .70\n",
    "# price: .75\n",
    "# SELL (not in optimal set)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: .70\n",
    "# price: .50\n",
    "# BUY (likely allocation is less than what you have, in which case you sell)\n",
    "\n",
    "# bought_at: .90\n",
    "# EV: -.10\n",
    "# price: .50\n",
    "#\n",
    "\n",
    "market = { \n",
    "    \"id\": 5411, \n",
    "    \"twitter_handle\": \"@potus\", \n",
    "    \"contract_map\": [ (\"15008\", range(0, 35)), (\"15010\",range(35, 40)), (\"15011\", range(40, 45)), (\"15012\", range(45, 50)), (\"15013\",range(50, 55)), (\"15009\", range(55, 60)), (\"15014\",range(60, 200))]\n",
    "}\n",
    "df = pd.DataFrame({ \"price_per_share\": [.2, .51, .40, .01, .10], \"proba\": [.30, .10, .60, .02, .7] }, index=[\"0-59\", \"60-64\", \"65-69\", \"70-71\", \"test\"])\n",
    "df = pd.DataFrame({ \"price_per_share\": [.10, .2, .40], \"proba\": [.3, .30, .60] }, index=[\"1\", \"2\", \"3\"])\n",
    "alloc = kelly_criterion(df)\n",
    "alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@vp tweets noon 4/26 - noon 5/3?\n",
      "Days left: 1\n",
      "Matching tweets: 57\n",
      "Category probabilities:\n",
      "45-99    1.0\n",
      "0-19     0.0\n",
      "35-39    0.0\n",
      "25-29    0.0\n",
      "20-24    0.0\n",
      "30-34    0.0\n",
      "40-44    0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@whitehouse tweets 4/4 - 4/11?\n",
      "Days left: 1\n",
      "Matching tweets: 200\n",
      "Category probabilities:\n",
      "105-299    1.0\n",
      "0-79       0.0\n",
      "85-89      0.0\n",
      "80-84      0.0\n",
      "90-94      0.0\n",
      "95-99      0.0\n",
      "100-104    0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@realDonaldTrump tweets 4/3 - 4/10?\n",
      "Days left: 1\n",
      "Matching tweets: 199\n",
      "Category probabilities:\n",
      "85-199    1.0\n",
      "60-64     0.0\n",
      "75-79     0.0\n",
      "70-74     0.0\n",
      "80-84     0.0\n",
      "65-69     0.0\n",
      "0-59      0.0\n",
      "dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [pct_alloc]\n",
      "Index: []\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "@potus tweets noon 4/26 - noon 5/3?\n",
      "Days left: 1\n",
      "Matching tweets: 59\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Unknown string format:', 'id')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c27d65c9c393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_markets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_market_research\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-aae1099dee4b>\u001b[0m in \u001b[0;36meval_markets\u001b[0;34m(show_market_research)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_markets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_market_research\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmarket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarkets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0meval_twitter_market\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/tweets/{handle}.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"twitter_handle\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_market_research\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_market_research\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------------------------------------\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-3122f281e93e>\u001b[0m in \u001b[0;36meval_twitter_market\u001b[0;34m(market, path, data, ts, show_market_research)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day_of_week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mweekdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtimezone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimezone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"US/Eastern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0myearfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myearfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                     \u001b[0mrequire_iso8601\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequire_iso8601\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m                 )\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown string format:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Unknown string format:', 'id')"
     ]
    }
   ],
   "source": [
    "eval_markets(show_market_research=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_market(market):\n",
    "    historical_data = psql.read_sql(\"SELECT * from market_data WHERE handle = \\'{handle}\\'\".format(handle=market[\"twitter_handle\"]), db_string)\n",
    "    path = \"data/tweets/{handle}.csv\".format(handle=market[\"twitter_handle\"])\n",
    "    for i, data_point in historical_data.iterrows():\n",
    "        ts = parser.parse(data_point[\"timestamp\"])\n",
    "        eval_twitter_market(market, path, data=json.loads(data_point[\"data\"]), ts=ts, show_market_research=False)\n",
    "\n",
    "def simulate_markets():\n",
    "    for m in markets:\n",
    "        simulate_market(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = { \n",
    "    \"id\": 5458, \n",
    "    \"twitter_handle\": \"@potus\", \n",
    "    \"contract_map\": {\n",
    "        \"15270\": { \"range\": range(0, 45) }, \n",
    "        \"15274\": { \"range\": range(45, 50) },\n",
    "        \"15275\": { \"range\": range(50, 55) },\n",
    "        \"15271\": { \"range\": range(55, 60) }, \n",
    "        \"15272\": { \"range\": range(60, 65) }, \n",
    "        \"15273\": { \"range\": range(65, 69) },\n",
    "        \"15276\": { \"range\": range(70, 200) }\n",
    "    }\n",
    "}\n",
    "\n",
    "simulate_markets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-05-03 17:24:58</td>\n",
       "      <td>1124364235360882689</td>\n",
       "      <td>RT @realDonaldTrump: ....We discussed Trade, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-05-03 17:24:52</td>\n",
       "      <td>1124364212749336576</td>\n",
       "      <td>RT @realDonaldTrump: Had a long and very good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-05-03 16:23:36</td>\n",
       "      <td>1124348791765774340</td>\n",
       "      <td>RT @realDonaldTrump: We can all agree that AME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-05-03 16:23:30</td>\n",
       "      <td>1124348769787625472</td>\n",
       "      <td>RT @realDonaldTrump: The U.S. Created 263,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2019-05-03 13:51:26</td>\n",
       "      <td>1124310501104680961</td>\n",
       "      <td>RT @realDonaldTrump: Finally, Mainstream Media...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-05-03 13:42:36</td>\n",
       "      <td>1124308278886973445</td>\n",
       "      <td>RT @WhiteHouse: It's another historic Jobs Day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-05-03 13:42:35</td>\n",
       "      <td>1124308272196927490</td>\n",
       "      <td>RT @realDonaldTrump: JOBS, JOBS, JOBS!\\n\\nJob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2019-05-03 00:12:27</td>\n",
       "      <td>1124104394788823041</td>\n",
       "      <td>RT @realDonaldTrump: Proclamation on Days of R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2019-05-02 23:52:27</td>\n",
       "      <td>1124099364354445317</td>\n",
       "      <td>RT @realDonaldTrump: On this day of prayer, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2019-05-02 17:02:56</td>\n",
       "      <td>1123996306115059713</td>\n",
       "      <td>RT @realDonaldTrump: ....and deregulation whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-05-02 17:02:53</td>\n",
       "      <td>1123996292445765639</td>\n",
       "      <td>RT @realDonaldTrump: Steve Moore, a great pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-05-02 15:10:40</td>\n",
       "      <td>1123968053107208192</td>\n",
       "      <td>RT @WhiteHouse: LIVE: President Trump and The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2019-05-02 03:05:48</td>\n",
       "      <td>1123785634961874949</td>\n",
       "      <td>RT @realDonaldTrump: I am continuing to monito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2019-05-02 02:05:29</td>\n",
       "      <td>1123770455012278273</td>\n",
       "      <td>RT @WhiteHouse: \"So tonight we praise God for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2019-05-02 02:05:27</td>\n",
       "      <td>1123770444576903169</td>\n",
       "      <td>RT @WhiteHouse: \"During this holy season when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2019-05-02 02:05:24</td>\n",
       "      <td>1123770434720235520</td>\n",
       "      <td>RT @WhiteHouse: \"Tonight we break bread togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2019-05-02 02:00:27</td>\n",
       "      <td>1123769187661426690</td>\n",
       "      <td>RT @realDonaldTrump: https://t.co/S34Q0NY6Ju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2019-05-02 01:55:56</td>\n",
       "      <td>1123768049960652800</td>\n",
       "      <td>RT @FLOTUS: It was an honor to host so many wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-05-01 13:06:00</td>\n",
       "      <td>1123574292002803713</td>\n",
       "      <td>RT @realDonaldTrump: Congress must change the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2019-05-01 13:05:53</td>\n",
       "      <td>1123574259815677953</td>\n",
       "      <td>RT @realDonaldTrump: No President in history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2019-05-01 13:05:45</td>\n",
       "      <td>1123574225510567937</td>\n",
       "      <td>RT @realDonaldTrump: Gallup Poll: 56% of Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2019-05-01 13:05:38</td>\n",
       "      <td>1123574199166144517</td>\n",
       "      <td>RT @realDonaldTrump: I am overriding the Decom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2019-05-01 13:05:31</td>\n",
       "      <td>1123574168472170496</td>\n",
       "      <td>RT @realDonaldTrump: The Democrats cant come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>2019-05-01 02:29:16</td>\n",
       "      <td>1123414050858315779</td>\n",
       "      <td>RT @WhiteHouse: To all the patriotic citizens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2019-04-30 23:45:22</td>\n",
       "      <td>1123372805591052289</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2019-04-30 23:45:21</td>\n",
       "      <td>1123372798406213638</td>\n",
       "      <td>RT @WhiteHouse: NASCAR is not only a thrillin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-04-30 23:45:15</td>\n",
       "      <td>1123372776851742720</td>\n",
       "      <td>RT @WhiteHouse: President @realDonaldTrump hos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2019-04-30 21:10:14</td>\n",
       "      <td>1123333763004620801</td>\n",
       "      <td>RT @realDonaldTrump: ....embargo, together wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2019-04-30 21:10:12</td>\n",
       "      <td>1123333757094846465</td>\n",
       "      <td>RT @realDonaldTrump: If Cuban Troops and Milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>2019-04-30 20:52:06</td>\n",
       "      <td>1123329199144677377</td>\n",
       "      <td>RT @WhiteHouse: National Security Advisor @Amb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>182.0</td>\n",
       "      <td>2018-05-03 21:21:22</td>\n",
       "      <td>992152158647840770</td>\n",
       "      <td>RT @WhiteHouse: President Trump has made it cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>183.0</td>\n",
       "      <td>2018-05-03 18:22:34</td>\n",
       "      <td>992107161605033984</td>\n",
       "      <td>RT @realDonaldTrump: #NationalDayOfPrayer http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>184.0</td>\n",
       "      <td>2018-05-03 16:56:28</td>\n",
       "      <td>992085493574782976</td>\n",
       "      <td>RT @WhiteHouse: \"The Faith Initiative will hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>185.0</td>\n",
       "      <td>2018-05-03 16:56:25</td>\n",
       "      <td>992085481146994688</td>\n",
       "      <td>RT @WhiteHouse: \"Faith has shaped our families...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>186.0</td>\n",
       "      <td>2018-05-03 16:56:22</td>\n",
       "      <td>992085469876846593</td>\n",
       "      <td>RT @WhiteHouse: \"Rev. Grahams words remind us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>187.0</td>\n",
       "      <td>2018-05-03 16:27:42</td>\n",
       "      <td>992078253706874880</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>188.0</td>\n",
       "      <td>2018-05-03 15:50:35</td>\n",
       "      <td>992068915210653696</td>\n",
       "      <td>RT @WhiteHouse: Today, President Trump signed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>189.0</td>\n",
       "      <td>2018-05-03 15:29:35</td>\n",
       "      <td>992063630580633600</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>190.0</td>\n",
       "      <td>2018-05-03 13:56:32</td>\n",
       "      <td>992040211256430593</td>\n",
       "      <td>RT @WhiteHouse: President Donald J. Trump proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>191.0</td>\n",
       "      <td>2018-05-02 22:42:00</td>\n",
       "      <td>991810062510379008</td>\n",
       "      <td>RT @WhiteHouse: Gina Haspel has developed outs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>192.0</td>\n",
       "      <td>2018-05-02 20:39:20</td>\n",
       "      <td>991779192730800135</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>193.0</td>\n",
       "      <td>2018-05-02 20:31:30</td>\n",
       "      <td>991777222380916736</td>\n",
       "      <td>RT @realDonaldTrump: I have been briefed on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>194.0</td>\n",
       "      <td>2018-05-02 20:16:42</td>\n",
       "      <td>991773496828203013</td>\n",
       "      <td>RT @WhiteHouse: Gina Haspel has displayed dedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>195.0</td>\n",
       "      <td>2018-05-02 18:17:05</td>\n",
       "      <td>991743395272982528</td>\n",
       "      <td>RT @realDonaldTrump: Congratulations @SecPompe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>196.0</td>\n",
       "      <td>2018-05-02 16:45:49</td>\n",
       "      <td>991720426278711296</td>\n",
       "      <td>RT @WhiteHouse: The Wall Street Journal: From ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>197.0</td>\n",
       "      <td>2018-05-02 16:08:20</td>\n",
       "      <td>991710994480226305</td>\n",
       "      <td>RT @WhiteHouse: \"For nearly 230 years, the men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>198.0</td>\n",
       "      <td>2018-05-02 15:48:57</td>\n",
       "      <td>991706115313491973</td>\n",
       "      <td>RT @WhiteHouse: A number of public officials h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>199.0</td>\n",
       "      <td>2018-05-02 15:17:48</td>\n",
       "      <td>991698274347347968</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-05-02 14:47:07</td>\n",
       "      <td>991690554932187136</td>\n",
       "      <td>RT @WhiteHouse: Today President Trump and Vice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-05-02 13:55:13</td>\n",
       "      <td>991677493659799552</td>\n",
       "      <td>RT @WhiteHouse: What They Are Saying: Widespre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-05-01 19:44:47</td>\n",
       "      <td>991403078401347584</td>\n",
       "      <td>RT @realDonaldTrump: Today, it was my great ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-05-01 18:14:56</td>\n",
       "      <td>991380465067098113</td>\n",
       "      <td>RT @realDonaldTrump: Congratulations @ArmyWP_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-05-01 16:59:25</td>\n",
       "      <td>991361461812416513</td>\n",
       "      <td>RT @realDonaldTrump: Today I had the great hon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-05-01 16:03:26</td>\n",
       "      <td>991347372033740800</td>\n",
       "      <td>RT @WhiteHouse: Watch LIVE as President Trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2018-05-01 15:24:07</td>\n",
       "      <td>991337476177453058</td>\n",
       "      <td>RT @realDonaldTrump: Yesterday, it was my grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2018-04-29 04:37:12</td>\n",
       "      <td>990449901812281344</td>\n",
       "      <td>RT @WhiteHouse: Loopholes in our immigration s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2018-04-29 04:35:42</td>\n",
       "      <td>990449522492018688</td>\n",
       "      <td>RT @sarasotapd: We might be biased but our Off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2018-04-29 01:18:20</td>\n",
       "      <td>990399855699865601</td>\n",
       "      <td>RT @WhiteHouse: Now nearly a decade and a half...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2018-04-29 01:17:42</td>\n",
       "      <td>990399692524670976</td>\n",
       "      <td>RT @realDonaldTrump: Secret Service has just i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>id</td>\n",
       "      <td>created_at</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3212 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           created_at                   id  \\\n",
       "0            0.0  2019-05-03 17:24:58  1124364235360882689   \n",
       "1            1.0  2019-05-03 17:24:52  1124364212749336576   \n",
       "2            2.0  2019-05-03 16:23:36  1124348791765774340   \n",
       "3            3.0  2019-05-03 16:23:30  1124348769787625472   \n",
       "4            4.0  2019-05-03 13:51:26  1124310501104680961   \n",
       "5            5.0  2019-05-03 13:42:36  1124308278886973445   \n",
       "6            6.0  2019-05-03 13:42:35  1124308272196927490   \n",
       "7            7.0  2019-05-03 00:12:27  1124104394788823041   \n",
       "8            8.0  2019-05-02 23:52:27  1124099364354445317   \n",
       "9            9.0  2019-05-02 17:02:56  1123996306115059713   \n",
       "10          10.0  2019-05-02 17:02:53  1123996292445765639   \n",
       "11          11.0  2019-05-02 15:10:40  1123968053107208192   \n",
       "12          12.0  2019-05-02 03:05:48  1123785634961874949   \n",
       "13          13.0  2019-05-02 02:05:29  1123770455012278273   \n",
       "14          14.0  2019-05-02 02:05:27  1123770444576903169   \n",
       "15          15.0  2019-05-02 02:05:24  1123770434720235520   \n",
       "16          16.0  2019-05-02 02:00:27  1123769187661426690   \n",
       "17          17.0  2019-05-02 01:55:56  1123768049960652800   \n",
       "18          18.0  2019-05-01 13:06:00  1123574292002803713   \n",
       "19          19.0  2019-05-01 13:05:53  1123574259815677953   \n",
       "20          20.0  2019-05-01 13:05:45  1123574225510567937   \n",
       "21          21.0  2019-05-01 13:05:38  1123574199166144517   \n",
       "22          22.0  2019-05-01 13:05:31  1123574168472170496   \n",
       "23          23.0  2019-05-01 02:29:16  1123414050858315779   \n",
       "24          24.0  2019-04-30 23:45:22  1123372805591052289   \n",
       "25          25.0  2019-04-30 23:45:21  1123372798406213638   \n",
       "26          26.0  2019-04-30 23:45:15  1123372776851742720   \n",
       "27          27.0  2019-04-30 21:10:14  1123333763004620801   \n",
       "28          28.0  2019-04-30 21:10:12  1123333757094846465   \n",
       "29          29.0  2019-04-30 20:52:06  1123329199144677377   \n",
       "...          ...                  ...                  ...   \n",
       "3182       182.0  2018-05-03 21:21:22   992152158647840770   \n",
       "3183       183.0  2018-05-03 18:22:34   992107161605033984   \n",
       "3184       184.0  2018-05-03 16:56:28   992085493574782976   \n",
       "3185       185.0  2018-05-03 16:56:25   992085481146994688   \n",
       "3186       186.0  2018-05-03 16:56:22   992085469876846593   \n",
       "3187       187.0  2018-05-03 16:27:42   992078253706874880   \n",
       "3188       188.0  2018-05-03 15:50:35   992068915210653696   \n",
       "3189       189.0  2018-05-03 15:29:35   992063630580633600   \n",
       "3190       190.0  2018-05-03 13:56:32   992040211256430593   \n",
       "3191       191.0  2018-05-02 22:42:00   991810062510379008   \n",
       "3192       192.0  2018-05-02 20:39:20   991779192730800135   \n",
       "3193       193.0  2018-05-02 20:31:30   991777222380916736   \n",
       "3194       194.0  2018-05-02 20:16:42   991773496828203013   \n",
       "3195       195.0  2018-05-02 18:17:05   991743395272982528   \n",
       "3196       196.0  2018-05-02 16:45:49   991720426278711296   \n",
       "3197       197.0  2018-05-02 16:08:20   991710994480226305   \n",
       "3198       198.0  2018-05-02 15:48:57   991706115313491973   \n",
       "3199       199.0  2018-05-02 15:17:48   991698274347347968   \n",
       "3200         0.0  2018-05-02 14:47:07   991690554932187136   \n",
       "3201         1.0  2018-05-02 13:55:13   991677493659799552   \n",
       "3202         2.0  2018-05-01 19:44:47   991403078401347584   \n",
       "3203         3.0  2018-05-01 18:14:56   991380465067098113   \n",
       "3204         4.0  2018-05-01 16:59:25   991361461812416513   \n",
       "3205         5.0  2018-05-01 16:03:26   991347372033740800   \n",
       "3206         6.0  2018-05-01 15:24:07   991337476177453058   \n",
       "3207         7.0  2018-04-29 04:37:12   990449901812281344   \n",
       "3208         8.0  2018-04-29 04:35:42   990449522492018688   \n",
       "3209         9.0  2018-04-29 01:18:20   990399855699865601   \n",
       "3210        10.0  2018-04-29 01:17:42   990399692524670976   \n",
       "3211         NaN                   id           created_at   \n",
       "\n",
       "                                                   text  \n",
       "0     RT @realDonaldTrump: ....We discussed Trade, V...  \n",
       "1     RT @realDonaldTrump: Had a long and very good ...  \n",
       "2     RT @realDonaldTrump: We can all agree that AME...  \n",
       "3     RT @realDonaldTrump: The U.S. Created 263,000...  \n",
       "4     RT @realDonaldTrump: Finally, Mainstream Media...  \n",
       "5     RT @WhiteHouse: It's another historic Jobs Day...  \n",
       "6     RT @realDonaldTrump: JOBS, JOBS, JOBS!\\n\\nJob...  \n",
       "7     RT @realDonaldTrump: Proclamation on Days of R...  \n",
       "8     RT @realDonaldTrump: On this day of prayer, we...  \n",
       "9     RT @realDonaldTrump: ....and deregulation whic...  \n",
       "10    RT @realDonaldTrump: Steve Moore, a great pro-...  \n",
       "11    RT @WhiteHouse: LIVE: President Trump and The ...  \n",
       "12    RT @realDonaldTrump: I am continuing to monito...  \n",
       "13    RT @WhiteHouse: \"So tonight we praise God for ...  \n",
       "14    RT @WhiteHouse: \"During this holy season when ...  \n",
       "15    RT @WhiteHouse: \"Tonight we break bread togeth...  \n",
       "16         RT @realDonaldTrump: https://t.co/S34Q0NY6Ju  \n",
       "17    RT @FLOTUS: It was an honor to host so many wo...  \n",
       "18    RT @realDonaldTrump: Congress must change the ...  \n",
       "19    RT @realDonaldTrump: No President in history ...  \n",
       "20    RT @realDonaldTrump: Gallup Poll: 56% of Ameri...  \n",
       "21    RT @realDonaldTrump: I am overriding the Decom...  \n",
       "22    RT @realDonaldTrump: The Democrats cant come...  \n",
       "23    RT @WhiteHouse: To all the patriotic citizens ...  \n",
       "24    RT @realDonaldTrump: Today, it was my great ho...  \n",
       "25    RT @WhiteHouse: NASCAR is not only a thrillin...  \n",
       "26    RT @WhiteHouse: President @realDonaldTrump hos...  \n",
       "27    RT @realDonaldTrump: ....embargo, together wit...  \n",
       "28    RT @realDonaldTrump: If Cuban Troops and Milit...  \n",
       "29    RT @WhiteHouse: National Security Advisor @Amb...  \n",
       "...                                                 ...  \n",
       "3182  RT @WhiteHouse: President Trump has made it cl...  \n",
       "3183  RT @realDonaldTrump: #NationalDayOfPrayer http...  \n",
       "3184  RT @WhiteHouse: \"The Faith Initiative will hel...  \n",
       "3185  RT @WhiteHouse: \"Faith has shaped our families...  \n",
       "3186  RT @WhiteHouse: \"Rev. Grahams words remind us...  \n",
       "3187  RT @realDonaldTrump: Today, it was my great ho...  \n",
       "3188  RT @WhiteHouse: Today, President Trump signed ...  \n",
       "3189  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3190  RT @WhiteHouse: President Donald J. Trump proc...  \n",
       "3191  RT @WhiteHouse: Gina Haspel has developed outs...  \n",
       "3192  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3193  RT @realDonaldTrump: I have been briefed on th...  \n",
       "3194  RT @WhiteHouse: Gina Haspel has displayed dedi...  \n",
       "3195  RT @realDonaldTrump: Congratulations @SecPompe...  \n",
       "3196  RT @WhiteHouse: The Wall Street Journal: From ...  \n",
       "3197  RT @WhiteHouse: \"For nearly 230 years, the men...  \n",
       "3198  RT @WhiteHouse: A number of public officials h...  \n",
       "3199  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3200  RT @WhiteHouse: Today President Trump and Vice...  \n",
       "3201  RT @WhiteHouse: What They Are Saying: Widespre...  \n",
       "3202  RT @realDonaldTrump: Today, it was my great ho...  \n",
       "3203  RT @realDonaldTrump: Congratulations @ArmyWP_F...  \n",
       "3204  RT @realDonaldTrump: Today I had the great hon...  \n",
       "3205  RT @WhiteHouse: Watch LIVE as President Trump ...  \n",
       "3206  RT @realDonaldTrump: Yesterday, it was my grea...  \n",
       "3207  RT @WhiteHouse: Loopholes in our immigration s...  \n",
       "3208  RT @sarasotapd: We might be biased but our Off...  \n",
       "3209  RT @WhiteHouse: Now nearly a decade and a half...  \n",
       "3210  RT @realDonaldTrump: Secret Service has just i...  \n",
       "3211                                               text  \n",
       "\n",
       "[3212 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/tweets/@potus.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head(3212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Unknown string format:', 'id')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-13ef386ef0d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3212\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[0;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0myearfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myearfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                     \u001b[0mrequire_iso8601\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequire_iso8601\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m                 )\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown string format:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Unknown string format:', 'id')"
     ]
    }
   ],
   "source": [
    "pd.to_datetime(df['created_at'].head(3212))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
